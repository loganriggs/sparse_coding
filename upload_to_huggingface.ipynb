{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models\n",
    "Be careful not to overwrite!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_repo_name = \"Benw8888/pythia-6.9b-sae\"\n",
    "model_id = \"Benw8888/pythia-6.9b-sae\"\n",
    "mode = \"bias\"\n",
    "chkpt = 0\n",
    "local_file = f\"/root/sparse_coding/trained_models/sft_sae_70m.pt\"\n",
    "file_in_repo = f\"sft_sae_70m.pt\" # \"sft_sae_6b.pt\" \"transfer_sft_ppo_6b.pt\" f\"transfer_sft_base_6b_{mode}.pt\"\n",
    "# each checkpoint was 8mil tokens, so chkpt 6 was 56mil tokens (0 indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=local_file,\n",
    "    path_in_repo=file_in_repo,\n",
    "    repo_id=model_id,\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "l1_alphas=[0, 1e-4, 2e-4, 4e-4, 8e-4, 1e-3, 2e-3, 4e-3, 8e-3]\n",
    "#[0, 1e-5, 2e-5, 4e-5, 8e-5, 1e-4, 2e-4, 4e-4, 8e-4, 1e-3, 2e-3, 4e-3, 8e-3]\n",
    "layers=[0,1,2,3,4,5]\n",
    "model_repo_name = \"Benw8888/pythia-6.9b-sae\"\n",
    "model_id = \"Benw8888/pythia-6.9b-sae\"\n",
    "modes = [\"scale\", \"rotation\", \"bias\", \"free\"]\n",
    "\n",
    "for l1_alpha in l1_alphas:\n",
    "    for layer in layers:\n",
    "    # for chkpt in [0,1,2,3,4,5,6]:\n",
    "        for mode in modes:\n",
    "        \n",
    "            file_name = f\"base_sae_70m_{layer}_{l1_alpha}\"\n",
    "            local_file = f\"/root/sparse_coding/trained_models/{file_name}.pt\"\n",
    "            file_in_repo = f\"{file_name}.pt\" # \"sft_sae_6b.pt\" \"transfer_sft_ppo_6b.pt\" f\"transfer_sft_base_6b_{mode}.pt\"\n",
    "            # each checkpoint was 8mil tokens, so chkpt 6 was 56mil tokens (0 indexed)\n",
    "\n",
    "            api = HfApi()\n",
    "            api.upload_file(\n",
    "                path_or_fileobj=local_file,\n",
    "                path_in_repo=file_in_repo,\n",
    "                repo_id=model_id,\n",
    "                repo_type=\"model\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVE FILES\n",
    "import shutil\n",
    "\n",
    "l1_alphas=[0, 1e-5, 2e-5, 4e-5, 8e-5, 1e-4, 2e-4, 4e-4, 8e-4, 1e-3, 2e-3, 4e-3, 8e-3]\n",
    "layers=[0,1,2,3,4,5]\n",
    "model_repo_name = \"Benw8888/pythia-6.9b-sae\"\n",
    "model_id = \"Benw8888/pythia-6.9b-sae\"\n",
    "modes = [\"scale\", \"rotation\", \"bias\", \"free\"]\n",
    "\n",
    "# for l1_alpha in l1_alphas:\n",
    "#     for layer in layers:\n",
    "#         for mode in modes:\n",
    "#             file_name = f\"transfer_base_sft_70m_{mode}_{layer}_{l1_alpha}_ckpt5.pt\"\n",
    "#             local_file = f\"/root/sparse_coding/trained_models/{file_name}\"\n",
    "#             target_file_name = f\"transfer_base_sft_70m_{mode}_{layer}_{l1_alpha}.pt\"\n",
    "#             move_to = f\"/root/sparse_coding/trained_models/transfer_base_sft_70m/{target_file_name}\"\n",
    "#             try:\n",
    "#                 shutil.copy(local_file, move_to)\n",
    "#             except:\n",
    "#                 pass\n",
    "            \n",
    "# for l1_alpha in l1_alphas:\n",
    "#     for layer in layers:        \n",
    "#             file_name = f\"pythia-70m_autoTED_{layer}_{l1_alpha}.pt\"\n",
    "#             local_file = f\"/root/sparse_coding/trained_models/{file_name}\"\n",
    "#             move_to = f\"/root/sparse_coding/trained_models/base_autoTED_70m/base_autoTED_70m_{layer}_{l1_alpha}.pt\"\n",
    "            \n",
    "#             shutil.move(local_file, move_to)\n",
    "\n",
    "# for l1_alpha in l1_alphas:\n",
    "#     for layer in layers:        \n",
    "#             file_name = f\"dead_features_pythia-70m_{layer}_{l1_alpha}.pt\"\n",
    "#             local_file = f\"/root/sparse_coding/trained_models/{file_name}\"\n",
    "#             move_to = f\"/root/sparse_coding/trained_models/base_dead_features_70m/base_dead_features_70m_{layer}_{l1_alpha}.pt\"\n",
    "            \n",
    "#             shutil.copy(local_file, move_to)\n",
    "            \n",
    "for l1_alpha in l1_alphas:\n",
    "    for layer in layers:        \n",
    "            file_name = f\"base_sae_70m_{layer}_{l1_alpha}.pt\"\n",
    "            local_file = f\"/root/sparse_coding/trained_models/{file_name}\"\n",
    "            move_to = f\"/root/sparse_coding/trained_models/base_sae_70m/{file_name}\"\n",
    "            \n",
    "            shutil.copy(local_file, move_to)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete files in local folder\n",
    "import os\n",
    "l1_alphas=[0, 1e-5, 2e-5, 4e-5, 8e-5, 1e-4, 2e-4, 4e-4, 8e-4, 1e-3, 2e-3, 4e-3, 8e-3]\n",
    "layers=[0,1,2,3,4,5]\n",
    "modes = [\"scale\", \"rotation\", \"bias\", \"free\"]\n",
    "for l1_alpha in l1_alphas:\n",
    "    for layer in layers:\n",
    "    # for chkpt in [0,1,2,3,4,5,6]:\n",
    "        for mode in modes:\n",
    "        \n",
    "            file_name = f\"transfer_base_sft_70m_{mode}_{layer}_{l1_alpha}_ckpt0\" #\"base_sae_70m_{layer}_{l1_alpha}\"\n",
    "            local_file = f\"/root/sparse_coding/trained_models/new_transfer/{file_name}.pt\"\n",
    "            # file_in_repo = f\"{file_name}.pt\" # \"sft_sae_6b.pt\" \"transfer_sft_ppo_6b.pt\" f\"transfer_sft_base_6b_{mode}.pt\"\n",
    "            \n",
    "            try:\n",
    "                os.remove(local_file)\n",
    "            except:\n",
    "                pass\n",
    "            # each checkpoint was 8mil tokens, so chkpt 6 was 56mil tokens (0 indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbce2ab83ec247bc838219853bd275a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "base_autoTED_70m_scale_3_0.002.pt:   0%|          | 0.00/8.41M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b460a364d9e4402c8cbb2e7a3e9bfa75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "base_autoTED_70m_scale_0_0.002.pt:   0%|          | 0.00/8.41M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5bd0a152ac44380a0ccf9ff9a57527e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "base_autoTED_70m_scale_2_0.002.pt:   0%|          | 0.00/8.41M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63aa60ff1fda420e9d7e9f2c79298538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "base_autoTED_70m_scale_1_0.002.pt:   0%|          | 0.00/8.41M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f28c8345c5446e9be9ec382cd9ec162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "base_autoTED_70m_scale_4_0.002.pt:   0%|          | 0.00/8.41M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719ab6632c6442049c33484d8bdb9a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 12 LFS files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7f4c7507d34b78aa87443e37668b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "base_autoTED_70m_scale_5_0.002.pt:   0%|          | 0.00/8.41M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff633f75e574da591e0932a90d20a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "base_sae_70m_0_0.002.pt:   0%|          | 0.00/8.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfb27484fd64e17adb595c04470aaae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "base_sae_70m_1_0.002.pt:   0%|          | 0.00/8.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ae5511339246eeb040f62f2a1a113b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "base_sae_70m_2_0.002.pt:   0%|          | 0.00/8.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a0b90845b940beb6ebd7d942eb24f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "base_sae_70m_3_0.002.pt:   0%|          | 0.00/8.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e57e37671e44eba4e761f0670d0b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "base_sae_70m_4_0.002.pt:   0%|          | 0.00/8.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f2737e9e2348cabf994c955933d5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "base_sae_70m_5_0.002.pt:   0%|          | 0.00/8.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/Benw8888/pythia-6.9b-sae/tree/main/base_retrain_70m'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "l1_alphas=[0, 1e-5, 2e-5, 4e-5, 8e-5, 1e-4, 2e-4, 4e-4, 8e-4, 1e-3, 2e-3, 4e-3, 8e-3]\n",
    "layers=[0,1,2,3,4,5]\n",
    "model_repo_name = \"Benw8888/pythia-6.9b-sae\"\n",
    "model_id = \"Benw8888/pythia-6.9b-sae\"\n",
    "# modes = [\"scale\", \"rotation\", \"bias\", \"free\"]\n",
    "\n",
    "# for l1_alpha in l1_alphas:\n",
    "#     for layer in layers:\n",
    "#     # for chkpt in [0,1,2,3,4,5,6]:\n",
    "        \n",
    "#         file_name = f\"dead_features_pythia-70m_{layer}_{l1_alpha}.pt\"\n",
    "#         local_file = f\"/root/sparse_coding/trained_models/{file_name}\"\n",
    "#         file_in_repo = f\"base_dead_features_70m_{layer}_{l1_alpha}.pt\"\n",
    "#         # each checkpoint was 8mil tokens, so chkpt 6 was 56mil tokens (0 indexed)\n",
    "\n",
    "#         api = HfApi()\n",
    "#         api.upload_file(\n",
    "#             path_or_fileobj=local_file,\n",
    "#             path_in_repo=file_in_repo,\n",
    "#             repo_id=model_id,\n",
    "#             repo_type=\"model\",\n",
    "#         )\n",
    "\n",
    "folder = f\"base_retrain_70m\"\n",
    "api = HfApi()\n",
    "api.upload_folder(\n",
    "    folder_path=f\"/root/sparse_coding/trained_models/base_retrain_70m\", #{folder}\",\n",
    "    path_in_repo=folder,\n",
    "    repo_id=model_id,\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_repo_name = \"Benw8888/pythia-6.9b-sae\"\n",
    "model_id = \"Benw8888/pythia-6.9b-sae\"\n",
    "modes = [\"scale\", \"rotation\", \"bias\", \"free\"]\n",
    "\n",
    "for mode in modes:\n",
    "    # for chkpt in [0,1,2,3,4,5,6]:\n",
    "        \n",
    "        local_file = f\"/root/sparse_coding/trained_models/pythia-70m_eleuther-pythia70m-hh-sft_{mode}_r4_gpt_neox.layers.4.pt\"\n",
    "        file_in_repo = f\"transfer_base_sft_70m_{mode}.pt\" # \"sft_sae_6b.pt\" \"transfer_sft_ppo_6b.pt\" f\"transfer_sft_base_6b_{mode}.pt\"\n",
    "        # each checkpoint was 8mil tokens, so chkpt 6 was 56mil tokens (0 indexed)\n",
    "\n",
    "        from huggingface_hub import HfApi\n",
    "        api = HfApi()\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=local_file,\n",
    "            path_in_repo=file_in_repo,\n",
    "            repo_id=model_id,\n",
    "            repo_type=\"model\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Dead Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_repo_name = \"Benw8888/pythia-6.9b-sae\"\n",
    "model_id = \"Benw8888/pythia-6.9b-sae\"\n",
    "local_file = f\"/root/sparse_coding/trained_models/sft_dead_features_70m.pt\"\n",
    "file_in_repo = f\"sft_dead_features_70m.pt\" # \"base_sae_6b.pt\" \"sft_sae_6b.pt\" \"transfer_sft_ppo_6b.pt\" \"rm_dead_features.pt\" \"base_dead_features_70m.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=local_file,\n",
    "    path_in_repo=file_in_repo,\n",
    "    repo_id=model_id,\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_repo_name = \"Benw8888/pythia-6.9b-sae\"\n",
    "model_id = \"Benw8888/pythia-6.9b-sae\"\n",
    "modes = [\"scale\", \"rotation\", \"bias\", \"free\"]\n",
    "huggingface_model_names = []\n",
    "# huggingface_model_names += [\"rm_sae_gptj.pt\", \"ppo_sae_6b.pt\"] + [f\"transfer_rm_ppo_6b_{mode}.pt\" for mode in modes]\n",
    "# huggingface_model_names += [\"base_sae_6b.pt\", \"sft_sae_6b.pt\"] + [f\"transfer_base_sft_6b_{mode}.pt\" for mode in modes]\n",
    "# huggingface_model_names += [f\"transfer_sft_base_6b_{mode}_6.pt\" for mode in modes]\n",
    "# huggingface_model_names += [f\"transfer_base_sft_6b_{mode}_6.pt\" for mode in modes]\n",
    "# huggingface_model_names += [f\"{model}_dead_features.pt\" for model in [\"base\",\"sft\",\"rm\",\"ppo\"]]\n",
    "huggingface_model_names += [\"base_sae_70m.pt\", \"sft_sae_70m.pt\"]\n",
    "huggingface_model_names += [f\"transfer_base_sft_70m_{mode}.pt\" for mode in modes]\n",
    "huggingface_model_names += [f\"transfer_sft_base_70m_{mode}.pt\" for mode in modes]\n",
    "\n",
    "\n",
    "# huggingface_model_names = [\"base_sae_6b.pt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "# model_id = \"Elriggs/pythia-70m-deduped-layer-2\"\n",
    "\n",
    "for hf_name in huggingface_model_names:\n",
    "    ae_download_location = hf_hub_download(repo_id=model_id, filename=hf_name)\n",
    "    downloaded_autoencoder = torch.load(ae_download_location)\n",
    "        \n",
    "    import os\n",
    "    if not os.path.exists(\"trained_models\"):\n",
    "        os.makedirs(\"trained_models\")\n",
    "    # Save model\n",
    "    torch.save(downloaded_autoencoder, f\"trained_models/{hf_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading From Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_repo_name = \"Benw8888/pythia-6.9b-sae\"\n",
    "model_id = \"Benw8888/pythia-6.9b-sae\"\n",
    "# modes = [\"scale\", \"rotation\", \"bias\", \"free\"]\n",
    "huggingface_folder_names = []\n",
    "huggingface_folder_names += [\"base_frequency_70m\", \"base_dead_features_70m\", \"base_sae_70m\", \"base_retrain_70m\"] #, \"transfer_base_sft_70m\"] \"base_autoTED_70m\"\n",
    "layers = [0,1,2,3,4,5]\n",
    "modes = [\"dnorotation\", \"dfree\", \"scale\", \"enorotation\", \"efree\", \"norotation\"]\n",
    "l1s = [f\"{l1_alpha}\" for l1_alpha in [2e-3,]] #[1e-3, 2e-3, 4e-3, 8e-3]]\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "import os\n",
    "# model_id = \"Elriggs/pythia-70m-deduped-layer-2\"\n",
    "\n",
    "for folder in huggingface_folder_names:\n",
    "    if not os.path.exists(\"trained_models\"):\n",
    "        os.makedirs(\"trained_models\")\n",
    "    if not os.path.exists(f\"trained_models/{folder}\"):\n",
    "        os.makedirs(f\"trained_models/{folder}\")\n",
    "    for layer in layers:\n",
    "        for l1 in l1s:\n",
    "            file_name = f\"{folder}_{layer}_{l1}.pt\"\n",
    "            if folder==\"base_retrain_70m\":\n",
    "                for mode in modes:\n",
    "                    file_name = f\"base_autoTED_70m_{mode}_{layer}_{l1}.pt\"\n",
    "                    hf_name = f\"{folder}/{file_name}\"\n",
    "                    ae_download_location = hf_hub_download(repo_id=model_id, filename=hf_name)\n",
    "                    downloaded_autoencoder = torch.load(ae_download_location)\n",
    "                    torch.save(downloaded_autoencoder, f\"trained_models/{folder}/{file_name}\")\n",
    "            if folder[:8] == \"transfer\":\n",
    "                file_name = f\"{folder}_free_{layer}_{l1}.pt\"\n",
    "            hf_name = f\"{folder}/{file_name}\"\n",
    "            ae_download_location = hf_hub_download(repo_id=model_id, filename=hf_name)\n",
    "            downloaded_autoencoder = torch.load(ae_download_location)\n",
    "            torch.save(downloaded_autoencoder, f\"trained_models/{folder}/{file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading reward model stuff??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save reward model\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "\n",
    "ae_download_location = hf_hub_download(repo_id=\"Dahoas/gptj-rm-static\", filename=\"hf_ckpt.pt\")\n",
    "downloaded_rm = torch.load(ae_download_location)\n",
    "    \n",
    "import os\n",
    "if not os.path.exists(\"llms\"):\n",
    "    os.makedirs(\"llms\")\n",
    "# Save model\n",
    "torch.save(downloaded_rm, f\"llms/gptj-rm-static.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
