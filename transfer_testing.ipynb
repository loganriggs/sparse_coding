{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import argparse\n",
    "from utils import dotdict\n",
    "from activation_dataset import setup_token_data\n",
    "import wandb\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cfg = dotdict()\n",
    "# models: \"EleutherAI/pythia-6.9b\", \"usvsnsp/pythia-6.9b-ppo\", \"lomahony/eleuther-pythia6.9b-hh-sft\", \"reciprocate/dahoas-gptj-rm-static\"\n",
    "cfg.target_name=\"EleutherAI/pythia-70m\"\n",
    "cfg.model_name=\"lomahony/pythia-70m-helpful-sft\"\n",
    "cfg.layers=[4]\n",
    "cfg.setting=\"residual\"\n",
    "# cfg.tensor_name=\"gpt_neox.layers.{layer}\" or \"transformer.h.{layer}\"\n",
    "cfg.tensor_name=\"gpt_neox.layers.{layer}\"\n",
    "cfg.target_tensor_name=\"gpt_neox.layers.{layer}\"\n",
    "original_l1_alpha = 8e-4\n",
    "cfg.l1_alpha=original_l1_alpha\n",
    "cfg.sparsity=None\n",
    "cfg.num_epochs=10\n",
    "cfg.model_batch_size=8\n",
    "cfg.lr=1e-3\n",
    "cfg.kl=False\n",
    "cfg.reconstruction=False\n",
    "# cfg.dataset_name=\"NeelNanda/pile-10k\"\n",
    "cfg.dataset_name=\"Elriggs/openwebtext-100k\"\n",
    "cfg.device=\"cuda:0\"\n",
    "cfg.ratio = 4\n",
    "cfg.seed = 10\n",
    "# cfg.device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_names = [cfg.tensor_name.format(layer=layer) for layer in cfg.layers]\n",
    "target_tensor_names = [cfg.target_tensor_name.format(layer=layer) for layer in cfg.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoXForCausalLM were not initialized from the model checkpoint at lomahony/pythia-70m-helpful-sft and are newly initialized: ['gpt_neox.layers.2.attention.masked_bias', 'gpt_neox.layers.4.attention.bias', 'gpt_neox.layers.3.attention.masked_bias', 'gpt_neox.layers.0.attention.bias', 'gpt_neox.layers.1.attention.masked_bias', 'gpt_neox.layers.0.attention.masked_bias', 'gpt_neox.layers.2.attention.bias', 'gpt_neox.layers.5.attention.bias', 'gpt_neox.layers.1.attention.bias', 'gpt_neox.layers.5.attention.masked_bias', 'gpt_neox.layers.3.attention.bias', 'gpt_neox.layers.4.attention.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load in the model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(cfg.model_name)\n",
    "model = model.to(cfg.device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-3a119b63aad7e838_*_of_00008.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 112750592\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "cfg.max_length = 256\n",
    "token_loader = setup_token_data(cfg, tokenizer, model, seed=cfg.seed, split=\"train\")\n",
    "num_tokens = cfg.max_length*cfg.model_batch_size*len(token_loader)\n",
    "print(f\"Number of tokens: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation size: 512\n"
     ]
    }
   ],
   "source": [
    "# Run 1 datapoint on model to get the activation size\n",
    "from baukit import Trace\n",
    "\n",
    "text = \"1\"\n",
    "tokens = tokenizer(text, return_tensors=\"pt\").input_ids.to(cfg.device)\n",
    "# Your activation name will be different. In the next cells, we will show you how to find it.\n",
    "with torch.no_grad():\n",
    "    with Trace(model, tensor_names[0]) as ret:\n",
    "        _ = model(tokens)\n",
    "        representation = ret.output\n",
    "        # check if instance tuple\n",
    "        if(isinstance(representation, tuple)):\n",
    "            representation = representation[0]\n",
    "        activation_size = representation.shape[-1]\n",
    "print(f\"Activation size: {activation_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target sparsity: 25\n"
     ]
    }
   ],
   "source": [
    "# Set target sparsity to 10% of activation_size if not set\n",
    "if cfg.sparsity is None:\n",
    "    cfg.sparsity = int(activation_size*0.05)\n",
    "    print(f\"Target sparsity: {cfg.sparsity}\")\n",
    "\n",
    "target_lower_sparsity = cfg.sparsity * 0.9\n",
    "target_upper_sparsity = cfg.sparsity * 1.1\n",
    "adjustment_factor = 0.1  # You can set this to whatever you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoencoder loaded from fsft_sae_70m\n",
      "target_autoencoder loaded from fbase_sae_70m\n"
     ]
    }
   ],
   "source": [
    "# Load base and target autoencoders\n",
    "from autoencoders.learned_dict import TiedSAE, UntiedSAE, AnthropicSAE, TransferSAE\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "target_model = AutoModelForCausalLM.from_pretrained(cfg.target_name).cpu()\n",
    "\n",
    "save_name = f\"sft_sae_70m\"  # trim year\n",
    "autoencoder = torch.load(f\"trained_models/{save_name}.pt\")\n",
    "print(f\"autoencoder loaded from f{save_name}\")\n",
    "autoencoder.to_device(cfg.device)\n",
    "\n",
    "save_name = f\"base_sae_70m\" \n",
    "target_autoencoder = torch.load(f\"trained_models/{save_name}.pt\")\n",
    "print(f\"target_autoencoder loaded from f{save_name}\")\n",
    "target_autoencoder.to_device(cfg.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize New transfer autoencoder\n",
    "from autoencoders.learned_dict import TiedSAE, UntiedSAE, AnthropicSAE, TransferSAE\n",
    "from torch import nn\n",
    "\n",
    "modes = [\"scale\", \"rotation\", \"bias\", \"free\"]\n",
    "transfer_autoencoders = []\n",
    "for mode in modes:\n",
    "    # mode_tsae = TransferSAE(\n",
    "    #     # n_feats = n_dict_components, \n",
    "    #     # activation_size=activation_size,\n",
    "    #     autoencoder,\n",
    "    #     decoder=autoencoder.get_learned_dict().detach().clone(),\n",
    "    #     decoder_bias=autoencoder.shift_bias.detach().clone(),\n",
    "    #     mode=mode,\n",
    "    # )\n",
    "    mode_tsae = torch.load(f\"/root/sparse_coding/trained_models/pythia-70m-helpful-sft_pythia-70m_{mode}_r4_gpt_neox.layers.4_ckpt4.pt\") #trained_models/transfer_base_sft_6b_{mode}_6.pt\n",
    "    mode_tsae.to_device(cfg.device)\n",
    "    transfer_autoencoders.append(mode_tsae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb_run_name: testing_lomahony/pythia-70m-helpful-sft_EleutherAI/pythia-70m_1123-152010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/sparse_coding/wandb/run-20231123_152010-km60be9j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/benw8888/sparse%20coding/runs/km60be9j' target=\"_blank\">testing_lomahony/pythia-70m-helpful-sft_EleutherAI/pythia-70m_1123-152010</a></strong> to <a href='https://wandb.ai/benw8888/sparse%20coding' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/benw8888/sparse%20coding' target=\"_blank\">https://wandb.ai/benw8888/sparse%20coding</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/benw8888/sparse%20coding/runs/km60be9j' target=\"_blank\">https://wandb.ai/benw8888/sparse%20coding/runs/km60be9j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/benw8888/sparse%20coding/runs/km60be9j?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f7ccc4ab6a0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wandb setup\n",
    "secrets = json.load(open(\"secrets.json\"))\n",
    "wandb.login(key=secrets[\"wandb_key\"])\n",
    "start_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "wandb_run_name = f\"testing_{cfg.model_name}_{cfg.target_name}_{start_time[4:]}\"  # trim year\n",
    "print(f\"wandb_run_name: {wandb_run_name}\")\n",
    "wandb.init(project=\"sparse coding\", config=dict(cfg), name=wandb_run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_activations(model, inputs, layer_name):\n",
    "    acts = []\n",
    "    for tokens in inputs:\n",
    "        with torch.no_grad(): # As long as not doing KL divergence, don't need gradients for model\n",
    "            with Trace(model, layer_name) as ret:\n",
    "                _ = model(tokens)\n",
    "                representation = ret.output\n",
    "                if(isinstance(representation, tuple)):\n",
    "                    representation = representation[0]\n",
    "        layer_activations = rearrange(representation, \"b seq d_model -> (b seq) d_model\")\n",
    "        acts.append(layer_activations.cpu())\n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_activations(model, target_model, token_loader, cfg, model_on_gpu=True, num_batches=500):\n",
    "    saved_inputs = []\n",
    "    for k, (batch) in enumerate(token_loader):\n",
    "        saved_inputs.append(batch[\"input_ids\"].to(cfg.device))\n",
    "        \n",
    "        if (k+1)%num_batches==0:\n",
    "            # compute base and target model activations\n",
    "            if model_on_gpu:\n",
    "                base_activations = compute_activations(model, saved_inputs, layer_name=tensor_names[0])\n",
    "                model = model.cpu()\n",
    "                target_model = target_model.to(cfg.device)\n",
    "            target_activations = compute_activations(target_model, saved_inputs, layer_name=target_tensor_names[0])\n",
    "            if not model_on_gpu:\n",
    "                target_model = target_model.cpu()\n",
    "                model = model.to(cfg.device)\n",
    "                base_activations = compute_activations(model, saved_inputs, layer_name=tensor_names[0])\n",
    "            model_on_gpu = not model_on_gpu\n",
    "            \n",
    "            for base_activation, target_activation in zip(base_activations, target_activations):\n",
    "                yield base_activation, target_activation\n",
    "\n",
    "            # wipe saved inputs\n",
    "            saved_inputs = []\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/Elriggs___parquet/Elriggs--openwebtext-100k-79076ecafee8a6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fdb1163a47646e9b8f4ca8c0d537e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 7/488 [00:09<07:38,  1.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction Loss: 0.09 | Tokens: 0 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.09 | Tokens: 0 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.09 | Tokens: 0 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.08 | Tokens: 0 | Self Similarity: 1.00\n",
      "Sparsity: 23.7 | Dead Features: 928 | Reconstruction Loss: 0.10 | Tokens: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 105/488 [00:11<00:08, 47.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction Loss: 0.10 | Tokens: 204800 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.09 | Tokens: 204800 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.10 | Tokens: 204800 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.08 | Tokens: 204800 | Self Similarity: 1.00\n",
      "Sparsity: 24.7 | Dead Features: 776 | Reconstruction Loss: 0.10 | Tokens: 204800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 205/488 [00:21<00:10, 25.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction Loss: 0.10 | Tokens: 409600 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.09 | Tokens: 409600 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.10 | Tokens: 409600 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.08 | Tokens: 409600 | Self Similarity: 1.00\n",
      "Sparsity: 24.0 | Dead Features: 666 | Reconstruction Loss: 0.11 | Tokens: 409600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 307/488 [00:32<00:58,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction Loss: 0.09 | Tokens: 614400 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.09 | Tokens: 614400 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.09 | Tokens: 614400 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.08 | Tokens: 614400 | Self Similarity: 1.00\n",
      "Sparsity: 23.9 | Dead Features: 600 | Reconstruction Loss: 0.10 | Tokens: 614400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 409/488 [00:34<00:01, 48.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction Loss: 0.10 | Tokens: 819200 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.10 | Tokens: 819200 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.10 | Tokens: 819200 | Self Similarity: 1.00\n",
      "Reconstruction Loss: 0.09 | Tokens: 819200 | Self Similarity: 1.00\n",
      "Sparsity: 23.2 | Dead Features: 540 | Reconstruction Loss: 0.11 | Tokens: 819200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 488/488 [00:44<00:00, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached max number of tokens: 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing transfer autoencoders\n",
    "token_loader = setup_token_data(cfg, tokenizer, model, seed=cfg.seed, split=\"train\")\n",
    "dead_features = torch.zeros(autoencoder.encoder.shape[0]) # dead features of base SAE on base\n",
    "target_dead_features = torch.zeros(autoencoder.encoder.shape[0]) # dead features of target SAE on base\n",
    "sft_dead_features = torch.zeros(autoencoder.encoder.shape[0]) # dead features of target SAE on target\n",
    "\n",
    "max_num_tokens = 1_000_000\n",
    "log_every=100\n",
    "# Freeze model parameters \n",
    "target_model = target_model.cpu()\n",
    "target_model.eval()\n",
    "model = model.to(cfg.device)\n",
    "model.eval()\n",
    "\n",
    "target_model.requires_grad_(False)\n",
    "model.requires_grad_(False)\n",
    "\n",
    "last_decoders = dict([(modes[i],transfer_autoencoders[i].decoder.clone().detach()) for i in range(len(transfer_autoencoders))])\n",
    "model_on_gpu = True\n",
    "\n",
    "saved_inputs = []\n",
    "i = 0 # counts all optimization steps\n",
    "num_saved_so_far = 0\n",
    "print(\"starting loop\")\n",
    "\n",
    "auto_total_loss = 0\n",
    "auto_base_loss = 0\n",
    "auto_sft_loss = 0\n",
    "\n",
    "target_base_loss = 0\n",
    "target_sft_loss = 0\n",
    "\n",
    "target_total_loss = 0\n",
    "total_losses = dict((mode,0) for mode in modes)\n",
    "\n",
    "for (base_activation, target_activation) in tqdm(generate_activations(model, target_model, token_loader, cfg, model_on_gpu=model_on_gpu, num_batches=150),\n",
    "                                                 total=int(max_num_tokens/(cfg.max_length*cfg.model_batch_size))):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        c = autoencoder.encode(base_activation.to(cfg.device))\n",
    "        x_hat = autoencoder.decode(c)\n",
    "        autoencoder_loss = (x_hat - target_activation.to(cfg.device)).pow(2).mean()\n",
    "        auto_total_loss += autoencoder_loss\n",
    "        auto_base_loss += (x_hat - base_activation.to(cfg.device)).pow(2).mean()\n",
    "        c_sft = autoencoder.encode(target_activation.to(cfg.device))\n",
    "        auto_sft_loss += (autoencoder.decode(c_sft) - target_activation.to(cfg.device)).pow(2).mean()\n",
    "        dead_features += c.sum(dim=0).cpu()\n",
    "        \n",
    "        \n",
    "        target_c = target_autoencoder.encode(base_activation.to(cfg.device))\n",
    "        target_x_hat = target_autoencoder.decode(c)\n",
    "        target_autoencoder_loss = (target_x_hat - target_activation.to(cfg.device)).pow(2).mean()\n",
    "        target_total_loss += target_autoencoder_loss\n",
    "        target_base_loss += (target_x_hat - base_activation.to(cfg.device)).pow(2).mean()\n",
    "        target_c_sft = target_autoencoder.encode(target_activation.to(cfg.device))\n",
    "        target_sft_loss += (target_autoencoder.decode(target_c_sft) - target_activation.to(cfg.device)).pow(2).mean()\n",
    "        target_dead_features += target_c.sum(dim=0).cpu()\n",
    "        sft_dead_features += target_c_sft.sum(dim=0).cpu()\n",
    "    \n",
    "    wandb_log = {}\n",
    "    \n",
    "    for tsae, mode in zip(transfer_autoencoders, modes):\n",
    "        with torch.no_grad():\n",
    "            x_hat = tsae.decode(c)\n",
    "        \n",
    "        reconstruction_loss = (x_hat - target_activation.to(cfg.device)).pow(2).mean()\n",
    "        total_loss = reconstruction_loss # NO L1 LOSS\n",
    "        total_losses[mode] += total_loss\n",
    "\n",
    "        if (i % log_every == 0): # Check here so first check is model w/o change\n",
    "            self_similarity = torch.cosine_similarity(tsae.decoder, last_decoders[mode], dim=-1).mean().cpu().item()\n",
    "            last_decoders[mode] = tsae.decoder.clone().detach()\n",
    "            num_tokens_so_far = i*cfg.max_length*cfg.model_batch_size\n",
    "            with torch.no_grad():\n",
    "                sparsity = (c != 0).float().mean(dim=0).sum().cpu().item()\n",
    "            print(f\"Reconstruction Loss: {reconstruction_loss:.2f} | Tokens: {num_tokens_so_far} | Self Similarity: {self_similarity:.2f}\")\n",
    "            wandb_log.update({\n",
    "                f'{mode} Reconstruction Loss': reconstruction_loss.item(),\n",
    "                f'{mode} Self Similarity': self_similarity\n",
    "            })\n",
    "\n",
    "    if (i % log_every == 0):\n",
    "        with torch.no_grad():\n",
    "            sparsity = (c != 0).float().mean(dim=0).sum().cpu().item()\n",
    "            num_dead_features = (dead_features == 0).sum().item()\n",
    "            \n",
    "            target_sparsity = (target_c != 0).float().mean(dim=0).sum().cpu().item()\n",
    "            target_num_dead_features = (target_dead_features == 0).sum().item()\n",
    "            \n",
    "        print(f\"Sparsity: {sparsity:.1f} | Dead Features: {num_dead_features} | Reconstruction Loss: {autoencoder_loss:.2f} | Tokens: {num_tokens_so_far}\")\n",
    "        \n",
    "        wandb_log.update({  # Base SAE log\n",
    "                f'SAE Sparsity': sparsity,\n",
    "                f'Dead Features': num_dead_features,\n",
    "                f'SAE Reconstruction Loss': autoencoder_loss.item(),\n",
    "                f'Tokens': num_tokens_so_far,\n",
    "            })\n",
    "        \n",
    "        wandb_log.update({  # Target SAE log\n",
    "                f'Target SAE Sparsity': target_sparsity,\n",
    "                f'Target Dead Features': target_num_dead_features,\n",
    "                f'Target SAE Reconstruction Loss': target_autoencoder_loss.item(),\n",
    "            })\n",
    "        \n",
    "        # Non transfer statistics (only base, or only sft)\n",
    "        with torch.no_grad():\n",
    "            sft_sparsity = (c_sft != 0).float().mean(dim=0).sum().cpu().item()            \n",
    "            target_sft_sparsity = (target_c_sft != 0).float().mean(dim=0).sum().cpu().item()\n",
    "            num_sft_dead_features = (sft_dead_features == 0).sum().item()\n",
    "            \n",
    "        wandb_log.update({  # Base only and Target only losses\n",
    "                f'Sparsity on Target': sft_sparsity,\n",
    "                f'Target Sparsity on Target': target_sft_sparsity,\n",
    "                f'Target Dead Features': num_sft_dead_features,\n",
    "            })\n",
    "        wandb.log(wandb_log)\n",
    "    i+=1\n",
    "    \n",
    "                \n",
    "    \n",
    "    num_tokens_so_far = i*cfg.max_length*cfg.model_batch_size\n",
    "    if(num_tokens_so_far > max_num_tokens):\n",
    "        print(f\"Reached max number of tokens: {max_num_tokens}\")\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Dead Features</td><td>█▅▃▂▁</td></tr><tr><td>SAE Average Loss</td><td>▁</td></tr><tr><td>SAE Average Loss on Base</td><td>▁</td></tr><tr><td>SAE Average Loss on Target</td><td>▁</td></tr><tr><td>SAE Reconstruction Loss</td><td>▁▄▅▁█</td></tr><tr><td>SAE Sparsity</td><td>▃█▅▄▁</td></tr><tr><td>Sparsity on Target</td><td>▁█▄▁▄</td></tr><tr><td>Target Dead Features</td><td>█▅▃▂▁</td></tr><tr><td>Target SAE Average Loss</td><td>▁</td></tr><tr><td>Target SAE Average Loss on Base</td><td>▁</td></tr><tr><td>Target SAE Average Loss on Target</td><td>▁</td></tr><tr><td>Target SAE Reconstruction Loss</td><td>▁▁▂▂█</td></tr><tr><td>Target SAE Sparsity</td><td>▅█▅▇▁</td></tr><tr><td>Target Sparsity on Target</td><td>▁█▅▂▂</td></tr><tr><td>Tokens</td><td>▁▃▅▆█</td></tr><tr><td>bias Average Loss</td><td>▁</td></tr><tr><td>bias Reconstruction Loss</td><td>▁▅▆▁█</td></tr><tr><td>bias Self Similarity</td><td>▁▁▁▁▁</td></tr><tr><td>free Average Loss</td><td>▁</td></tr><tr><td>free Reconstruction Loss</td><td>▁▆█▁█</td></tr><tr><td>free Self Similarity</td><td>▁▁▁▁▁</td></tr><tr><td>rotation Average Loss</td><td>▁</td></tr><tr><td>rotation Reconstruction Loss</td><td>▁▅▆▁█</td></tr><tr><td>rotation Self Similarity</td><td>▁▁▁▁▁</td></tr><tr><td>scale Average Loss</td><td>▁</td></tr><tr><td>scale Reconstruction Loss</td><td>▁▄▆▁█</td></tr><tr><td>scale Self Similarity</td><td>▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Dead Features</td><td>540</td></tr><tr><td>SAE Average Loss</td><td>0.10131</td></tr><tr><td>SAE Average Loss on Base</td><td>0.08454</td></tr><tr><td>SAE Average Loss on Target</td><td>0.08638</td></tr><tr><td>SAE Reconstruction Loss</td><td>0.11138</td></tr><tr><td>SAE Sparsity</td><td>23.21191</td></tr><tr><td>Sparsity on Target</td><td>30.12939</td></tr><tr><td>Target Dead Features</td><td>311</td></tr><tr><td>Target SAE Average Loss</td><td>0.24842</td></tr><tr><td>Target SAE Average Loss on Base</td><td>0.25479</td></tr><tr><td>Target SAE Average Loss on Target</td><td>0.07987</td></tr><tr><td>Target SAE Reconstruction Loss</td><td>0.30192</td></tr><tr><td>Target SAE Sparsity</td><td>24.46338</td></tr><tr><td>Target Sparsity on Target</td><td>26.24805</td></tr><tr><td>Tokens</td><td>819200</td></tr><tr><td>bias Average Loss</td><td>0.09138</td></tr><tr><td>bias Reconstruction Loss</td><td>0.10019</td></tr><tr><td>bias Self Similarity</td><td>1.0</td></tr><tr><td>free Average Loss</td><td>0.07947</td></tr><tr><td>free Reconstruction Loss</td><td>0.08506</td></tr><tr><td>free Self Similarity</td><td>1.0</td></tr><tr><td>rotation Average Loss</td><td>0.08795</td></tr><tr><td>rotation Reconstruction Loss</td><td>0.0961</td></tr><tr><td>rotation Self Similarity</td><td>1.0</td></tr><tr><td>scale Average Loss</td><td>0.09354</td></tr><tr><td>scale Reconstruction Loss</td><td>0.10132</td></tr><tr><td>scale Self Similarity</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">testing_lomahony/pythia-70m-helpful-sft_EleutherAI/pythia-70m_1123-152010</strong> at: <a href='https://wandb.ai/benw8888/sparse%20coding/runs/km60be9j' target=\"_blank\">https://wandb.ai/benw8888/sparse%20coding/runs/km60be9j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231123_152010-km60be9j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log total average loss and finish wandb\n",
    "wandb_log = {\n",
    "    'SAE Average Loss': auto_total_loss/i,\n",
    "    'Target SAE Average Loss': target_total_loss/i,\n",
    "    \n",
    "    'SAE Average Loss on Base': auto_base_loss/i,\n",
    "    'Target SAE Average Loss on Base': target_base_loss/i,\n",
    "    \n",
    "    'SAE Average Loss on Target': auto_sft_loss/i,\n",
    "    'Target SAE Average Loss on Target': target_sft_loss/i,\n",
    "    }\n",
    "for mode in modes:\n",
    "    wandb_log.update({  # Target SAE log\n",
    "                    f'{mode} Average Loss': total_losses[mode]/i,\n",
    "                })\n",
    "    \n",
    "wandb.log(wandb_log)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SAE Average Loss': tensor(0.1013, device='cuda:0'),\n",
      " 'SAE Average Loss on Base': tensor(0.0845, device='cuda:0'),\n",
      " 'SAE Average Loss on Target': tensor(0.0864, device='cuda:0'),\n",
      " 'Target SAE Average Loss': tensor(0.2484, device='cuda:0'),\n",
      " 'Target SAE Average Loss on Base': tensor(0.2548, device='cuda:0'),\n",
      " 'Target SAE Average Loss on Target': tensor(0.0799, device='cuda:0'),\n",
      " 'bias Average Loss': tensor(0.0914, device='cuda:0'),\n",
      " 'free Average Loss': tensor(0.0795, device='cuda:0'),\n",
      " 'rotation Average Loss': tensor(0.0879, device='cuda:0'),\n",
      " 'scale Average Loss': tensor(0.0935, device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "# Prints the nicely formatted dictionary\n",
    "pprint.pprint(wandb_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.1013, device='cuda:0'), tensor(0.0845, device='cuda:0'), tensor(0.0864, device='cuda:0'), tensor(0.2548, device='cuda:0'), tensor(0.0799, device='cuda:0'), tensor(0.2484, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "auto_and_target_losses = [\n",
    "    auto_total_loss,\n",
    "    auto_base_loss,\n",
    "    auto_sft_loss,\n",
    "    target_base_loss,\n",
    "    target_sft_loss,\n",
    "    target_total_loss\n",
    "]\n",
    "\n",
    "print([x/i for x in auto_and_target_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dead features\n",
    "import os\n",
    "if not os.path.exists(\"trained_models\"):\n",
    "    os.makedirs(\"trained_models\")\n",
    "# Save model\n",
    "torch.save(dead_features, f\"trained_models/base_dead_features_70m.pt\")\n",
    "torch.save(target_dead_features, f\"trained_models/base_on_sft_dead_features_70m.pt\")\n",
    "torch.save(sft_dead_features, f\"trained_models/sft_dead_features_70m.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
