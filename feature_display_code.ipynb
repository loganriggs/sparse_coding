{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/logan/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset, load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "from einops import rearrange\n",
    "from huggingface_hub import hf_hub_download\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "\n",
    "features = 1\n",
    "autoencoder_path = \"/mnt/ssd-cluster/longrun2408/tied_residual_l2_r6/_31/learned_dicts.pt\"\n",
    "autoencoder_index = 5\n",
    "layer = 10\n",
    "dataset_name = \"NeelNanda/pile-10k\"\n",
    "device = \"cuda:0\"\n",
    "# model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "model_name=\"usvsnsp/pythia-6.9b-rm-full-hh-rlhf\"\n",
    "max_seq_length=30\n",
    "input_setting = \"input_only\"\n",
    "model_type=\"reward_model\"\n",
    "# input_setting = \"both\"\n",
    "\n",
    "# model_id = \"Elriggs/pythia-70m-deduped\"\n",
    "model_id = \"Elriggs/pythia-6.9-rm\"\n",
    "filename = f\"pythia-6.9b-rm-full-hh-rlhf_sp409_r4_gpt_neox.layers.{layer}.pt\"\n",
    "# filename = f\"tied_residual_l{layer}_r6/_63/learned_dicts.pt\" \n",
    "ae_download_location = hf_hub_download(repo_id=model_id, filename=filename)\n",
    "# all_autoencoders = torch.load(ae_download_location)\n",
    "# num_l1s = len(all_autoencoders)\n",
    "# all_l1s = [hyperparams[\"l1_alpha\"] for autoencoder, hyperparams in all_autoencoders]\n",
    "# print(all_l1s)\n",
    "# auto_num = 5\n",
    "# autoencoder, hyperparams = all_autoencoders[auto_num]\n",
    "autoencoder = torch.load(ae_download_location)\n",
    "autoencoder.to_device(device)\n",
    "cache_name = f\"gpt_neox.layers.{layer}\"\n",
    "\n",
    "if(model_type == \"reward_model\"):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/logan/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:34<00:00, 11.48s/it]\n",
      "Some weights of GPTNeoXForSequenceClassification were not initialized from the model checkpoint at usvsnsp/pythia-6.9b-rm-full-hh-rlhf and are newly initialized: ['gpt_neox.layers.24.attention.bias', 'gpt_neox.layers.12.attention.masked_bias', 'gpt_neox.layers.27.attention.bias', 'gpt_neox.layers.5.attention.masked_bias', 'gpt_neox.layers.18.attention.masked_bias', 'gpt_neox.layers.30.attention.masked_bias', 'gpt_neox.layers.1.attention.masked_bias', 'gpt_neox.layers.1.attention.bias', 'gpt_neox.layers.23.attention.bias', 'gpt_neox.layers.19.attention.masked_bias', 'gpt_neox.layers.7.attention.bias', 'gpt_neox.layers.15.attention.masked_bias', 'gpt_neox.layers.3.attention.masked_bias', 'gpt_neox.layers.26.attention.masked_bias', 'gpt_neox.layers.22.attention.bias', 'gpt_neox.layers.20.attention.masked_bias', 'gpt_neox.layers.14.attention.masked_bias', 'gpt_neox.layers.13.attention.bias', 'gpt_neox.layers.6.attention.masked_bias', 'gpt_neox.layers.15.attention.bias', 'gpt_neox.layers.11.attention.bias', 'gpt_neox.layers.9.attention.bias', 'gpt_neox.layers.17.attention.masked_bias', 'gpt_neox.layers.30.attention.bias', 'gpt_neox.layers.9.attention.masked_bias', 'gpt_neox.layers.18.attention.bias', 'gpt_neox.layers.10.attention.masked_bias', 'gpt_neox.layers.24.attention.masked_bias', 'gpt_neox.layers.17.attention.bias', 'gpt_neox.layers.25.attention.masked_bias', 'gpt_neox.layers.20.attention.bias', 'gpt_neox.layers.13.attention.masked_bias', 'gpt_neox.layers.19.attention.bias', 'gpt_neox.layers.8.attention.masked_bias', 'gpt_neox.layers.6.attention.bias', 'gpt_neox.layers.10.attention.bias', 'gpt_neox.layers.0.attention.bias', 'gpt_neox.layers.3.attention.bias', 'gpt_neox.layers.2.attention.bias', 'gpt_neox.layers.25.attention.bias', 'gpt_neox.layers.29.attention.masked_bias', 'gpt_neox.layers.26.attention.bias', 'gpt_neox.layers.16.attention.masked_bias', 'gpt_neox.layers.5.attention.bias', 'gpt_neox.layers.11.attention.masked_bias', 'gpt_neox.layers.21.attention.masked_bias', 'gpt_neox.layers.16.attention.bias', 'gpt_neox.layers.12.attention.bias', 'gpt_neox.layers.27.attention.masked_bias', 'gpt_neox.layers.7.attention.masked_bias', 'gpt_neox.layers.31.attention.bias', 'gpt_neox.layers.0.attention.masked_bias', 'gpt_neox.layers.21.attention.bias', 'gpt_neox.layers.28.attention.bias', 'gpt_neox.layers.28.attention.masked_bias', 'gpt_neox.layers.14.attention.bias', 'gpt_neox.layers.22.attention.masked_bias', 'gpt_neox.layers.8.attention.bias', 'gpt_neox.layers.29.attention.bias', 'gpt_neox.layers.2.attention.masked_bias', 'gpt_neox.layers.4.attention.bias', 'gpt_neox.layers.31.attention.masked_bias', 'gpt_neox.layers.23.attention.masked_bias', 'gpt_neox.layers.4.attention.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutputWithPast(loss=None, logits=tensor([[-7.3593]], grad_fn=<IndexBackward0>), past_key_values=((tensor([[[[ 0.2733, -1.5498, -0.9108,  ...,  0.6258,  1.3284, -0.5538],\n",
       "          [ 0.4396, -1.2312, -1.3465,  ...,  1.0522,  0.7047,  0.9536]],\n",
       "\n",
       "         [[-0.0686,  0.4051, -0.1179,  ..., -0.5993,  0.1932,  0.3753],\n",
       "          [-0.1515, -0.5560,  0.2071,  ...,  0.2653, -1.0390,  0.6071]],\n",
       "\n",
       "         [[-0.2319, -0.4030, -0.3603,  ..., -0.7610,  0.7749,  0.2992],\n",
       "          [-0.5131, -0.3703, -0.1571,  ...,  0.4599, -1.4750,  0.0063]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.3137,  0.0943, -0.9110,  ..., -0.0522, -0.1277, -0.3282],\n",
       "          [ 0.6090,  1.2255,  1.2124,  ..., -0.7386,  1.0228, -1.2077]],\n",
       "\n",
       "         [[ 0.1653,  0.1118, -0.1032,  ...,  0.2161, -0.5078, -1.0716],\n",
       "          [-0.0593, -0.7695,  0.1072,  ..., -0.0765,  0.6198, -0.6102]],\n",
       "\n",
       "         [[ 1.5089, -0.0649,  0.4764,  ...,  0.7236, -0.5146,  0.7688],\n",
       "          [-0.0624,  0.3078, -0.0258,  ..., -0.6429, -0.8984,  0.9038]]]],\n",
       "       grad_fn=<CatBackward0>), tensor([[[[-1.8001e-03, -8.2190e-02, -6.9819e-01,  ...,  1.4757e-01,\n",
       "           -2.8142e-01, -7.3897e-01],\n",
       "          [-2.1970e-01, -1.1182e-01, -2.2084e-01,  ..., -1.9455e-01,\n",
       "            1.5384e-01,  6.5030e-02]],\n",
       "\n",
       "         [[ 3.9649e-01,  1.0993e-01, -4.4653e-01,  ..., -6.2982e-01,\n",
       "           -2.3925e-01, -2.5913e-01],\n",
       "          [ 6.8191e-01, -3.2604e-02,  1.1831e-01,  ...,  3.3597e-01,\n",
       "            1.3466e-01,  2.0481e-01]],\n",
       "\n",
       "         [[ 9.9019e-02,  1.0307e-04, -1.0617e-01,  ..., -6.8006e-01,\n",
       "           -6.0863e-02,  4.8870e-02],\n",
       "          [-3.4213e-01,  8.7343e-01, -2.5817e-01,  ...,  1.1481e-01,\n",
       "            7.6138e-01,  2.4485e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.0100e-01, -1.7487e-01,  2.5512e-03,  ...,  6.8138e-02,\n",
       "            9.9254e-02,  9.2121e-02],\n",
       "          [ 2.2130e-02, -2.0294e-01, -1.6862e-01,  ..., -2.2291e-01,\n",
       "            9.2724e-02, -1.0133e-01]],\n",
       "\n",
       "         [[-9.5263e-02,  3.3011e-01,  2.5173e-02,  ..., -1.7955e-01,\n",
       "           -2.2275e-01, -8.2413e-01],\n",
       "          [ 1.8597e-01, -2.0264e-01, -3.4762e-02,  ..., -2.4121e-01,\n",
       "            7.0542e-05, -1.3105e+00]],\n",
       "\n",
       "         [[ 3.6398e-01, -3.4214e-01,  3.2686e-01,  ...,  3.2496e-01,\n",
       "            2.5072e-01, -1.1085e-01],\n",
       "          [-1.7941e-01, -1.5007e-01, -2.5343e-01,  ...,  1.1289e-01,\n",
       "            6.4039e-01, -2.2180e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 4.4270e-01,  1.3131e-01,  7.6612e-01,  ..., -6.7012e-01,\n",
       "           -4.9101e-01,  6.3737e-01],\n",
       "          [ 6.6333e-01, -9.6455e-01,  4.1531e+00,  ..., -7.0566e-01,\n",
       "           -1.7330e-01,  4.1222e-01]],\n",
       "\n",
       "         [[-3.9698e-01, -6.0446e-01,  1.3150e-03,  ..., -6.1378e-01,\n",
       "            8.9581e-02,  4.7538e-01],\n",
       "          [ 2.1109e+00, -6.8186e-01, -2.0935e+00,  ..., -7.7744e-02,\n",
       "           -1.9658e-01,  4.4817e-01]],\n",
       "\n",
       "         [[ 8.5270e-01, -3.5458e-01, -3.1474e-01,  ..., -3.7807e+00,\n",
       "            9.4392e-01, -3.0902e+00],\n",
       "          [ 2.7028e+00, -2.5106e+00, -1.1395e+00,  ..., -3.5454e+00,\n",
       "            2.7445e+00, -2.0364e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.7255e-01, -9.8529e-01,  5.2959e-01,  ..., -7.4203e-01,\n",
       "           -3.0643e-01, -9.4552e-01],\n",
       "          [ 6.6683e-01,  5.3742e-01,  1.6649e+00,  ...,  1.1506e+00,\n",
       "           -7.6499e-01, -7.6940e-01]],\n",
       "\n",
       "         [[-3.6061e-01,  8.0795e-02, -3.7733e-01,  ..., -1.8763e+00,\n",
       "           -4.4194e-01,  3.1924e+00],\n",
       "          [ 1.2405e-01,  7.7121e-01, -2.1001e-01,  ...,  1.2312e-02,\n",
       "           -3.3340e-01,  4.1328e+00]],\n",
       "\n",
       "         [[ 2.1691e-01, -5.6321e-01,  9.2634e-02,  ..., -1.2866e-01,\n",
       "            3.2764e+00, -2.0410e-01],\n",
       "          [-4.3714e-01,  1.6560e-01,  1.2688e-01,  ..., -3.8689e-01,\n",
       "            2.3544e+00,  6.0670e-02]]]], grad_fn=<CatBackward0>), tensor([[[[-1.4450e-02, -6.2498e-02,  9.9735e-02,  ...,  2.2832e-02,\n",
       "           -8.2327e-02,  7.7505e-02],\n",
       "          [ 5.7511e-01,  4.1008e-01, -5.0675e-01,  ..., -4.3152e-01,\n",
       "            1.1431e+00, -5.1564e-01]],\n",
       "\n",
       "         [[-3.2354e-02,  6.8071e-02,  2.9639e-02,  ..., -4.3884e-03,\n",
       "           -5.3848e-02, -1.0274e-01],\n",
       "          [-1.1140e+00, -1.5104e+00, -5.6995e-01,  ...,  1.8708e+00,\n",
       "            2.6313e-01,  7.1768e-02]],\n",
       "\n",
       "         [[-3.4738e-01,  1.0355e-01, -7.9538e-02,  ..., -1.1747e-02,\n",
       "            1.5899e-01, -1.1750e-01],\n",
       "          [ 1.2784e+00, -6.2873e-01, -1.1523e+00,  ...,  1.2837e+00,\n",
       "           -6.3523e-01,  4.0303e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.0398e-01, -6.8844e-01,  4.5955e-02,  ...,  1.7383e-02,\n",
       "            6.1314e-02, -4.0307e-01],\n",
       "          [ 2.9298e-01, -1.4288e-01,  2.9676e-01,  ...,  2.3272e-01,\n",
       "           -3.0662e-01,  3.5373e-01]],\n",
       "\n",
       "         [[-7.5448e-02,  2.0422e-01,  6.0014e-02,  ..., -3.1071e-02,\n",
       "           -6.2851e-02, -3.5812e-02],\n",
       "          [ 4.1959e-01,  1.1052e-01,  3.0269e-02,  ...,  6.3464e-01,\n",
       "            6.4947e-01, -2.5037e-01]],\n",
       "\n",
       "         [[ 1.3172e-01, -1.2808e-03, -2.5256e-02,  ...,  8.3118e-02,\n",
       "            2.7175e-01, -5.8509e-01],\n",
       "          [-5.6494e-01, -8.7811e-01, -2.0115e-01,  ...,  8.0573e-01,\n",
       "           -2.1401e-01,  7.7043e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.1705, -0.3523, -0.0059,  ..., -2.7143, -4.2471, -3.2399],\n",
       "          [-0.9794, -1.9871,  0.1076,  ..., -0.7338, -2.9151, -1.5856]],\n",
       "\n",
       "         [[ 0.0230, -0.2852, -0.0707,  ...,  2.1049, -0.2363, -2.4223],\n",
       "          [ 3.1644, -2.1671, -0.4477,  ...,  1.9392,  0.1537, -1.9993]],\n",
       "\n",
       "         [[-0.8960,  0.7898, -1.7481,  ..., -0.4973, -1.1311,  0.1823],\n",
       "          [-0.2013,  0.3949, -0.9415,  ..., -0.6929, -1.4342, -0.3908]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1878, -1.3166,  0.5735,  ...,  0.8001,  0.7739, -0.7988],\n",
       "          [ 1.1889,  0.9296, -1.3804,  ...,  0.7086, -0.5703, -1.7653]],\n",
       "\n",
       "         [[ 0.1003,  0.5503,  0.7055,  ..., -1.3940,  2.5856, -1.2797],\n",
       "          [ 0.3437,  0.3706,  1.2143,  ..., -2.0347,  1.9660, -0.3670]],\n",
       "\n",
       "         [[ 0.4868,  0.3945, -0.5409,  ...,  1.8230,  0.4023,  0.2926],\n",
       "          [-0.8964,  1.3555, -1.4796,  ...,  0.0339,  0.8109,  1.2871]]]],\n",
       "       grad_fn=<CatBackward0>), tensor([[[[-0.1448, -0.0199, -0.1827,  ...,  0.0147, -0.2415, -0.1919],\n",
       "          [-0.0284,  0.5499, -0.0963,  ..., -0.0888, -0.1238,  0.1301]],\n",
       "\n",
       "         [[ 0.0030,  0.0686, -0.1552,  ..., -0.1510, -0.0153, -0.1963],\n",
       "          [ 0.3297,  0.1017, -0.2182,  ...,  0.2448,  0.0169,  0.1658]],\n",
       "\n",
       "         [[ 0.2024, -0.0333,  0.4225,  ...,  0.3383,  0.4021, -0.0332],\n",
       "          [ 0.9230,  0.5115,  0.0107,  ..., -0.1320,  0.6703,  0.4174]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1614,  0.0024, -0.0790,  ...,  0.1926,  0.0850,  0.1439],\n",
       "          [-0.6897,  0.2376,  0.4663,  ...,  0.1074, -0.2235,  0.7003]],\n",
       "\n",
       "         [[ 0.1379, -0.0779, -0.2392,  ..., -0.0170,  0.3833,  0.0732],\n",
       "          [ 0.0051, -0.0976, -0.0217,  ...,  0.2271,  0.0886, -0.0114]],\n",
       "\n",
       "         [[-0.0813, -0.0581, -0.1337,  ..., -0.2747,  0.0777,  0.2835],\n",
       "          [-0.3596,  0.4592,  0.6273,  ...,  0.2955,  0.2403, -0.1426]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.1110e-01, -5.6608e-01, -6.9875e-01,  ..., -4.9872e-01,\n",
       "            6.3182e-02,  6.9984e-01],\n",
       "          [ 1.2727e+00, -1.2069e+00, -7.1490e-01,  ...,  7.0037e-01,\n",
       "           -7.2566e-01, -3.0013e-01]],\n",
       "\n",
       "         [[ 3.9668e-01,  1.8931e-01,  1.2464e+00,  ..., -1.6564e+00,\n",
       "            2.1995e+00,  1.3910e-01],\n",
       "          [-9.8257e-01,  7.7939e-01,  1.4913e+00,  ..., -1.0086e+00,\n",
       "            8.4086e-01, -1.0507e+00]],\n",
       "\n",
       "         [[-1.7002e-01,  4.5677e-01, -2.0840e+00,  ...,  9.8388e-01,\n",
       "            6.9691e-01,  7.9946e-01],\n",
       "          [-5.5504e+00, -9.8667e-01, -1.4303e+00,  ..., -2.1614e-03,\n",
       "           -3.3366e-01,  1.9530e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.7097e+00,  2.9766e+00,  4.9415e+00,  ...,  1.1356e+00,\n",
       "            1.3034e+00, -8.6272e-01],\n",
       "          [ 6.2877e+00,  2.0317e+00,  5.9454e+00,  ...,  5.4428e-02,\n",
       "            1.2815e+00, -1.3124e-01]],\n",
       "\n",
       "         [[-3.6884e-01,  3.1370e-01, -1.2626e+00,  ..., -1.3790e+00,\n",
       "           -6.5410e-02,  4.5951e+00],\n",
       "          [ 9.7561e-01,  2.8986e-01,  1.1191e-02,  ..., -1.1082e+00,\n",
       "            1.2277e+00,  2.2471e+00]],\n",
       "\n",
       "         [[ 6.7734e-01, -8.5826e-01,  9.1179e-01,  ..., -2.2683e-01,\n",
       "           -1.3398e-01,  1.6825e+00],\n",
       "          [-5.0043e-01, -1.3320e+00, -1.0980e+00,  ..., -2.0465e-01,\n",
       "            1.5823e+00,  2.2207e+00]]]], grad_fn=<CatBackward0>), tensor([[[[ 2.8574e-01,  1.9437e-01,  3.8461e-02,  ..., -4.1517e-01,\n",
       "           -3.8055e-01, -8.0442e-02],\n",
       "          [ 4.2786e-01,  2.6350e-01, -4.7333e-01,  ..., -3.0012e-01,\n",
       "            1.4274e-01, -4.7712e-01]],\n",
       "\n",
       "         [[-2.3525e-02, -4.9306e-01,  8.6192e-02,  ...,  1.4829e-01,\n",
       "           -9.5277e-02,  3.5461e-01],\n",
       "          [ 1.7980e-01,  3.0989e-01, -1.1101e-01,  ...,  1.2688e-01,\n",
       "            3.2200e-02,  3.5468e-02]],\n",
       "\n",
       "         [[ 2.3869e-01, -3.9099e-02, -3.3741e-04,  ...,  4.6353e-02,\n",
       "            1.1420e-01, -1.8150e-02],\n",
       "          [ 3.2887e-02,  3.5671e-01, -3.9499e-01,  ..., -7.6931e-01,\n",
       "           -1.0178e-02,  3.6996e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.8399e-02,  8.3943e-02, -6.8902e-02,  ...,  9.1154e-01,\n",
       "            7.5521e-01,  1.8247e-01],\n",
       "          [ 7.6271e-01,  4.7370e-02, -7.2192e-01,  ..., -7.0770e-01,\n",
       "           -6.4748e-01,  4.5343e-01]],\n",
       "\n",
       "         [[ 2.9433e-02, -1.5411e-01,  3.4946e-02,  ..., -1.0205e-01,\n",
       "           -1.1823e-01,  8.9285e-02],\n",
       "          [-5.5835e-01,  1.0051e-01,  4.2163e-01,  ...,  3.8552e-01,\n",
       "            5.0857e-01, -5.8589e-01]],\n",
       "\n",
       "         [[ 2.1279e-01,  3.6868e-02, -1.0485e-01,  ..., -1.7231e-01,\n",
       "           -7.0251e-02, -7.9688e-02],\n",
       "          [-2.1010e-01, -2.1084e-01,  2.2184e-01,  ...,  5.5773e-01,\n",
       "            3.4010e-01, -8.4697e-02]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-6.1213e-02,  6.0060e-02,  9.7037e-02,  ...,  1.0624e+00,\n",
       "           -2.4847e+00, -2.3508e-01],\n",
       "          [ 2.0923e-01, -1.2379e-01, -1.8933e-01,  ...,  1.3139e+00,\n",
       "           -2.7371e+00,  3.0138e-01]],\n",
       "\n",
       "         [[-8.2177e-01,  8.5948e-01, -9.0249e-01,  ...,  1.9630e-01,\n",
       "            1.1459e+00, -1.8792e-01],\n",
       "          [-7.3321e-01, -1.1784e+00, -5.3129e-01,  ...,  1.4611e+00,\n",
       "            5.5821e-01, -1.0179e+00]],\n",
       "\n",
       "         [[ 5.9640e-03, -2.1208e-02,  1.4049e-01,  ...,  1.1619e+00,\n",
       "            2.0393e+00, -9.4420e-01],\n",
       "          [-1.1092e+00, -3.1636e-01,  1.3928e+00,  ...,  4.3005e-01,\n",
       "            9.2868e-01, -5.1194e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.1084e-02,  4.7461e-02,  4.6482e-03,  ...,  7.4284e-01,\n",
       "            5.1202e-01,  2.4607e-01],\n",
       "          [-6.3758e-01,  7.5558e-01,  1.2243e+00,  ...,  2.5162e+00,\n",
       "           -8.3772e-01, -7.0758e-01]],\n",
       "\n",
       "         [[ 2.6528e-02,  2.8251e-02,  1.1316e-01,  ...,  7.3541e-01,\n",
       "            4.8987e+00,  1.5861e+00],\n",
       "          [ 1.4392e-01,  9.8905e-02, -2.2745e-01,  ...,  1.3866e+00,\n",
       "            2.6667e+00,  9.1560e-01]],\n",
       "\n",
       "         [[-1.5752e-01,  1.6195e-01, -9.3733e-02,  ...,  1.8316e+00,\n",
       "           -1.1689e+00,  3.8827e-01],\n",
       "          [ 2.4482e+00, -1.1695e-02, -1.3435e+00,  ...,  1.5402e+00,\n",
       "           -3.2773e-01, -1.6941e-01]]]], grad_fn=<CatBackward0>), tensor([[[[ 3.6005e-02,  4.0358e-02, -8.2436e-02,  ..., -9.8789e-02,\n",
       "           -3.0187e-01,  2.1586e-02],\n",
       "          [ 6.7145e-01, -7.2497e-02,  5.3541e-01,  ...,  2.2321e-01,\n",
       "            4.4685e-01,  5.6731e-01]],\n",
       "\n",
       "         [[ 1.3637e-01, -3.0366e-02,  1.6481e-02,  ..., -9.3315e-02,\n",
       "            1.1520e-02,  2.7441e-01],\n",
       "          [-1.2394e-01,  7.7613e-02,  7.7220e-01,  ...,  1.6184e+00,\n",
       "            2.7584e-02, -4.9791e-01]],\n",
       "\n",
       "         [[ 5.4762e-02, -1.8883e-02, -2.2677e-02,  ..., -1.3656e-02,\n",
       "           -2.7684e-03, -1.5865e-02],\n",
       "          [-1.3846e-01,  5.6874e-02,  5.1824e-02,  ..., -2.0378e-02,\n",
       "           -1.1720e-01, -3.7663e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-9.6350e-02, -1.0149e-02, -1.1186e-01,  ..., -2.4450e-02,\n",
       "           -1.5028e-02,  2.0368e-02],\n",
       "          [-3.6240e-01,  7.4103e-01,  1.0211e+00,  ..., -3.0328e-02,\n",
       "           -8.7288e-01,  5.8798e-01]],\n",
       "\n",
       "         [[ 4.8001e-03, -1.1475e-02,  2.4961e-03,  ..., -1.1111e-02,\n",
       "           -3.3143e-02, -7.3149e-02],\n",
       "          [ 4.4006e-01,  1.5509e-01, -2.4015e-01,  ..., -4.0396e-01,\n",
       "           -6.7850e-01,  5.6616e-01]],\n",
       "\n",
       "         [[-4.1013e-02,  1.3767e-01,  4.1080e-02,  ..., -1.7735e-01,\n",
       "            4.5903e-02,  3.2015e-02],\n",
       "          [-2.9430e+00, -7.4090e-01,  7.8165e-01,  ...,  5.5562e-01,\n",
       "            5.2702e-01, -1.6925e-02]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.0459,  0.0392, -0.0251,  ...,  0.4486,  0.8013,  0.4226],\n",
       "          [ 0.4159,  0.1427, -1.2592,  ...,  1.6328, -1.3122, -0.1454]],\n",
       "\n",
       "         [[-0.0648, -0.0323, -0.0631,  ..., -3.3379,  0.0099, -3.0615],\n",
       "          [ 0.6540,  0.3751, -0.8878,  ..., -2.0380, -0.0353, -2.3058]],\n",
       "\n",
       "         [[-0.0616, -0.0268,  0.0123,  ..., -0.3872, -1.4498, -0.2327],\n",
       "          [-0.1753, -0.0495,  0.8649,  ...,  0.2407, -1.8408, -0.3836]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0577,  0.1588, -0.0172,  ..., -1.1964,  1.0351,  1.0082],\n",
       "          [ 0.3043,  0.1111, -0.1352,  ..., -1.2138,  0.7752,  1.3812]],\n",
       "\n",
       "         [[ 0.0647, -0.0561,  0.0110,  ...,  0.7089, -4.8893, -0.3631],\n",
       "          [ 0.1008,  1.2318,  0.3021,  ...,  1.1759,  0.5606, -1.1321]],\n",
       "\n",
       "         [[ 0.0716,  0.0065,  0.1516,  ..., -0.9397,  1.2560, -0.3582],\n",
       "          [-0.5025,  0.9365, -0.4213,  ...,  0.0264,  0.2230,  0.3239]]]],\n",
       "       grad_fn=<CatBackward0>), tensor([[[[ 4.7845e-03,  3.1992e-02,  1.8187e-02,  ..., -2.0032e-02,\n",
       "            2.2042e-03, -4.0847e-02],\n",
       "          [ 4.4244e-01, -5.2869e-01, -3.5690e-01,  ..., -1.4795e-01,\n",
       "           -1.3529e-01,  1.9406e-01]],\n",
       "\n",
       "         [[-9.9818e-02,  1.8329e-02, -8.0535e-02,  ...,  5.7072e-02,\n",
       "           -1.0919e-03, -6.9020e-02],\n",
       "          [ 4.7676e-01,  2.5689e-01, -2.4422e-01,  ..., -5.7020e-01,\n",
       "           -4.8279e-01, -2.1934e-01]],\n",
       "\n",
       "         [[-7.1153e-02,  3.7905e-02, -9.1486e-02,  ..., -3.8848e-02,\n",
       "           -2.3289e-02,  3.0009e-02],\n",
       "          [-5.6731e-02,  7.5473e-01,  1.0961e+00,  ..., -8.6974e-01,\n",
       "            1.8517e-01,  1.1710e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.6276e-02,  4.3068e-02,  1.6114e-02,  ...,  7.6052e-02,\n",
       "           -3.7750e-03,  3.0742e-02],\n",
       "          [-3.1751e-01,  6.9149e-01, -2.0613e-01,  ..., -2.9426e-01,\n",
       "           -8.4816e-01,  5.1296e-01]],\n",
       "\n",
       "         [[-5.3509e-02,  6.9510e-02, -2.2947e-02,  ..., -4.9886e-02,\n",
       "            1.3901e-02, -9.7731e-02],\n",
       "          [ 2.5690e-01,  6.0194e-02, -2.4554e-01,  ..., -5.4254e-01,\n",
       "            2.8240e-01,  1.7805e+00]],\n",
       "\n",
       "         [[-1.2999e-02,  7.3833e-03,  1.0213e-01,  ...,  1.4087e-01,\n",
       "           -7.3577e-02, -1.7726e-02],\n",
       "          [-3.6771e-01,  6.1584e-01,  1.0674e-01,  ..., -3.7841e-01,\n",
       "            1.9396e-01, -7.2902e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-4.4118e-02,  5.7628e-02, -4.2932e-02,  ...,  2.2032e-01,\n",
       "           -1.6473e+00,  9.6381e-01],\n",
       "          [-8.4361e-01, -6.1592e-01, -8.9914e-01,  ...,  1.8570e+00,\n",
       "           -1.3150e+00,  1.1751e+00]],\n",
       "\n",
       "         [[-7.4594e-02, -4.1480e-02, -4.2847e-02,  ..., -5.5579e-01,\n",
       "            5.9126e-01, -1.1099e+00],\n",
       "          [ 8.9962e-01,  1.0435e+00,  1.0499e+00,  ..., -9.5290e-01,\n",
       "            2.0185e-01, -4.0565e-02]],\n",
       "\n",
       "         [[ 7.5054e-02,  5.5750e-02, -6.9044e-02,  ...,  7.8808e-01,\n",
       "            2.9093e-01,  5.2652e-01],\n",
       "          [ 1.4941e+00, -1.0902e+00, -7.7999e-01,  ...,  1.4008e+00,\n",
       "           -9.1811e-01,  9.1806e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.9555e-02, -1.8530e-02,  2.9731e-02,  ...,  3.4529e+00,\n",
       "            7.5759e-01,  2.8800e-02],\n",
       "          [-2.4282e-01, -6.6891e-02, -4.0489e-01,  ...,  2.9720e+00,\n",
       "            1.8349e+00, -1.6215e+00]],\n",
       "\n",
       "         [[-5.1140e-03,  1.3224e-02, -9.8861e-02,  ...,  4.4043e-01,\n",
       "           -2.8938e+00, -1.5900e+00],\n",
       "          [-2.2039e-01,  7.5340e-02,  6.7756e-01,  ...,  1.9453e+00,\n",
       "           -3.2930e+00, -3.5304e+00]],\n",
       "\n",
       "         [[ 1.8257e-02, -1.4040e-03,  2.3473e-02,  ...,  1.5082e+00,\n",
       "            1.2131e+00, -6.1646e-01],\n",
       "          [-1.9833e+00, -2.6799e+00,  2.0724e+00,  ...,  1.8947e+00,\n",
       "            1.6577e+00, -1.7409e+00]]]], grad_fn=<CatBackward0>), tensor([[[[-1.0279e-02, -2.7968e-02,  2.6372e-02,  ...,  2.7297e-02,\n",
       "            1.7959e-03, -5.0871e-02],\n",
       "          [-3.0480e-01,  2.1408e-01, -1.5048e-01,  ...,  5.4784e-01,\n",
       "            7.1839e-01, -1.1033e+00]],\n",
       "\n",
       "         [[ 2.6038e-02, -4.6383e-02, -8.2392e-02,  ..., -7.3324e-02,\n",
       "            1.4125e-02, -5.7649e-02],\n",
       "          [-6.0136e-01, -4.9531e-01,  3.7807e-04,  ..., -4.4194e-01,\n",
       "            5.2446e-02, -2.3003e-01]],\n",
       "\n",
       "         [[-9.8460e-02, -1.9753e-03,  2.4167e-02,  ..., -7.1335e-02,\n",
       "            1.2621e-01, -8.5356e-02],\n",
       "          [-1.8607e-02,  3.1187e-01, -4.9035e-01,  ..., -3.1523e-01,\n",
       "            2.1758e-01,  4.8067e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.1179e-02,  8.9684e-02,  1.4469e-01,  ...,  2.3247e-01,\n",
       "           -6.5647e-02,  1.4975e-01],\n",
       "          [ 5.7109e-01, -1.9736e-01,  2.3957e-01,  ..., -7.0389e-01,\n",
       "            5.0904e-01,  2.9019e-01]],\n",
       "\n",
       "         [[ 2.3665e-02,  3.2640e-03, -1.1371e-02,  ...,  6.6312e-02,\n",
       "            2.8457e-02,  1.5056e-03],\n",
       "          [ 6.3713e-01, -5.5677e-01, -6.2295e-01,  ..., -4.4607e-01,\n",
       "           -1.0447e+00,  1.1009e+00]],\n",
       "\n",
       "         [[ 9.3984e-03,  6.0732e-03,  1.3476e-01,  ..., -1.1656e-01,\n",
       "           -1.1164e-01, -6.8205e-04],\n",
       "          [-8.1890e-01,  1.6624e-01, -1.2018e+00,  ..., -8.5617e-01,\n",
       "           -5.5771e-01, -3.2410e-02]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 2.7265e-02,  6.8912e-02, -6.4781e-02,  ..., -1.2391e+00,\n",
       "           -1.7819e+00, -9.5084e-01],\n",
       "          [-6.9105e-01,  1.8628e-01,  7.3259e-01,  ..., -1.4573e-01,\n",
       "           -2.3409e+00, -1.3571e+00]],\n",
       "\n",
       "         [[ 8.0178e-02, -5.4758e-02, -4.8829e-02,  ..., -1.5686e+00,\n",
       "            3.3680e-01,  4.9011e-01],\n",
       "          [ 3.1388e-01,  2.0314e-01,  6.1006e-01,  ..., -8.9509e-01,\n",
       "            3.0138e-01,  4.1305e-01]],\n",
       "\n",
       "         [[-2.6883e-02, -1.7986e-02,  7.4941e-03,  ..., -1.4842e+00,\n",
       "            8.8804e-01,  8.3948e-01],\n",
       "          [-9.8411e-03, -1.6559e-01, -4.7695e-01,  ..., -2.1412e+00,\n",
       "            1.0222e+00,  4.7851e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.3955e-02,  3.3998e-02, -6.4540e-04,  ...,  8.4521e-01,\n",
       "            1.0076e+00, -8.1428e-02],\n",
       "          [-5.7271e-01,  2.6469e+00,  2.8448e+00,  ...,  2.3757e-01,\n",
       "            1.6260e-01, -6.4357e-01]],\n",
       "\n",
       "         [[ 7.5631e-02,  4.4173e-03,  3.0139e-02,  ...,  1.3476e-02,\n",
       "            6.8591e-01, -1.9552e-01],\n",
       "          [ 2.2289e-01,  4.5746e-01,  7.4738e-01,  ..., -3.3635e-01,\n",
       "            1.2759e+00, -1.0717e-01]],\n",
       "\n",
       "         [[ 3.1405e-03,  3.3142e-02, -4.3628e-02,  ..., -5.4472e-01,\n",
       "            6.0019e-01, -2.1265e-01],\n",
       "          [-1.2032e-01, -1.3188e-01, -1.9396e-01,  ..., -1.9065e+00,\n",
       "           -2.2139e-01, -1.7912e-01]]]], grad_fn=<CatBackward0>), tensor([[[[-0.0500,  0.1495,  0.0050,  ...,  0.0311, -0.0213,  0.0150],\n",
       "          [ 0.9883, -0.7002,  0.1107,  ..., -0.8646,  1.5193, -0.1661]],\n",
       "\n",
       "         [[-0.0585,  0.0154, -0.0349,  ..., -0.0397, -0.0084,  0.0408],\n",
       "          [-1.9268,  1.2558, -1.0582,  ...,  1.2060, -0.7591,  0.6485]],\n",
       "\n",
       "         [[-0.0136, -0.0033, -0.0177,  ...,  0.0027, -0.0408, -0.1292],\n",
       "          [-0.1574, -0.5933, -1.0887,  ...,  1.4173, -0.3702, -0.1464]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1347,  0.0597,  0.1303,  ..., -0.0131,  0.0231, -0.0198],\n",
       "          [ 0.9537, -0.5476, -0.1241,  ...,  0.2853, -0.1064, -0.7878]],\n",
       "\n",
       "         [[ 0.0395, -0.1715, -0.0700,  ...,  0.0218, -0.0160, -0.2767],\n",
       "          [-0.4560, -0.7608, -0.6451,  ..., -0.3381,  0.4613, -0.9035]],\n",
       "\n",
       "         [[-0.0228,  0.0191, -0.0541,  ...,  0.1035, -0.0108,  0.0084],\n",
       "          [ 0.5840, -0.2990,  0.6372,  ...,  0.5543, -1.7805,  0.8946]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-4.9107e-03,  5.9174e-02, -2.1795e-02,  ..., -4.3037e-01,\n",
       "            2.1295e+00,  2.4310e+00],\n",
       "          [-2.1530e+00, -9.5578e-01, -6.9862e-01,  ..., -2.9554e-01,\n",
       "            2.6968e+00,  1.7963e+00]],\n",
       "\n",
       "         [[-2.3288e-02,  5.4295e-02, -1.7026e-02,  ...,  1.3969e+00,\n",
       "            1.4208e+00,  4.5422e+00],\n",
       "          [ 8.6653e-01, -1.8287e+00,  1.2235e+00,  ...,  1.0168e+00,\n",
       "            1.1942e+00,  4.8481e+00]],\n",
       "\n",
       "         [[-7.7530e-02, -1.0947e-01, -6.3895e-02,  ..., -8.1515e-01,\n",
       "            1.0841e+00, -5.0502e-01],\n",
       "          [-5.6374e-02,  4.0199e-01, -6.0959e-01,  ...,  8.6437e-01,\n",
       "            1.3489e+00,  1.5627e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.7175e-03, -2.5735e-02,  2.8804e-02,  ...,  2.7968e+00,\n",
       "            4.2672e-02, -2.0169e+00],\n",
       "          [ 6.3559e-01,  1.8322e-01,  2.3422e-01,  ...,  3.8833e+00,\n",
       "            8.6639e-01, -2.9968e+00]],\n",
       "\n",
       "         [[ 6.1110e-02,  2.8314e-03, -5.6127e-03,  ...,  2.2061e+00,\n",
       "            6.9860e-01,  6.5935e-01],\n",
       "          [-2.5100e-02, -4.4928e-01, -3.2118e-01,  ...,  1.5977e+00,\n",
       "           -7.4388e-01,  1.7282e+00]],\n",
       "\n",
       "         [[-8.5203e-02,  1.6260e-02, -1.0952e-02,  ...,  6.0429e-02,\n",
       "            2.5428e-01,  7.7319e+00],\n",
       "          [ 9.2983e-02,  8.6638e-01, -9.9134e-01,  ...,  8.1502e-01,\n",
       "           -1.4726e+00,  8.6552e+00]]]], grad_fn=<CatBackward0>), tensor([[[[ 8.9469e-02, -8.4242e-03,  5.4578e-02,  ...,  1.6221e-02,\n",
       "            3.2396e-03, -2.1280e-02],\n",
       "          [ 3.8666e-01, -3.7392e-01,  2.7859e-01,  ...,  8.1551e-01,\n",
       "            8.4114e-01,  4.6317e-01]],\n",
       "\n",
       "         [[-4.2269e-02,  3.3636e-02,  3.8067e-02,  ...,  1.6508e-02,\n",
       "            1.1890e-01, -5.2494e-02],\n",
       "          [-5.6919e-01,  1.6706e-01, -1.6981e+00,  ..., -1.7302e+00,\n",
       "           -9.0328e-01, -1.7305e+00]],\n",
       "\n",
       "         [[ 5.5603e-02, -1.1874e-02, -1.6912e-02,  ...,  2.5500e-02,\n",
       "            3.1629e-02,  3.0418e-02],\n",
       "          [ 1.8424e-01, -1.6202e+00,  2.4746e-01,  ...,  1.9862e-01,\n",
       "           -3.5627e-01,  2.5481e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.2270e-02, -6.7597e-02,  1.1157e-02,  ...,  2.5653e-03,\n",
       "           -3.6568e-02,  3.1585e-02],\n",
       "          [ 6.2553e-01,  3.7485e-01, -4.3586e-01,  ..., -1.8338e+00,\n",
       "            4.7500e-01,  2.6785e-01]],\n",
       "\n",
       "         [[ 6.7260e-02, -8.0631e-02,  4.4182e-02,  ...,  1.6257e-02,\n",
       "           -1.6860e-01, -2.9944e-01],\n",
       "          [-9.5886e-01, -4.2857e-01,  1.1998e-01,  ..., -1.0627e+00,\n",
       "            1.0099e+00,  7.0349e-01]],\n",
       "\n",
       "         [[-5.7042e-02, -3.6506e-02, -1.0605e-03,  ...,  5.5005e-02,\n",
       "            5.7018e-02,  2.1394e-02],\n",
       "          [-2.0079e-01, -2.2734e-01, -5.5455e-01,  ...,  4.4918e-02,\n",
       "            5.7463e-02, -6.5551e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.4595e-02,  5.4620e-03, -3.9791e-02,  ..., -2.6417e-01,\n",
       "            1.7850e+00,  1.1178e+00],\n",
       "          [ 2.2769e-01, -2.1447e-01,  8.4661e-01,  ..., -1.0129e+00,\n",
       "            1.4036e+00,  2.6145e+00]],\n",
       "\n",
       "         [[ 4.2090e-02,  3.0699e-02,  8.0819e-02,  ...,  1.3983e+00,\n",
       "            4.6546e-01, -3.2719e+00],\n",
       "          [ 2.9009e-01, -5.3940e-01,  7.7341e-01,  ...,  1.4926e+00,\n",
       "            1.5094e+00, -4.6675e+00]],\n",
       "\n",
       "         [[ 5.9229e-04,  4.4374e-02, -4.0155e-02,  ...,  2.3228e+00,\n",
       "           -8.5700e+00,  9.0364e+00],\n",
       "          [-7.0004e-01,  2.7080e-01,  3.8878e-01,  ...,  2.8796e+00,\n",
       "           -9.3340e+00,  9.1408e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.0568e-02,  4.7219e-02, -1.8587e-02,  ..., -1.7273e+00,\n",
       "            3.4964e-01,  4.5343e+00],\n",
       "          [-3.3838e-01,  4.3377e-02, -2.9417e-01,  ..., -7.9568e-01,\n",
       "            1.5616e+00,  5.5273e+00]],\n",
       "\n",
       "         [[-3.2786e-03, -1.0885e-01,  2.5450e-02,  ...,  1.3783e+00,\n",
       "           -2.3126e+00,  2.2238e+00],\n",
       "          [ 9.9332e-01,  2.5881e-01, -7.7966e-01,  ...,  7.4089e-01,\n",
       "           -2.4120e-01,  2.8097e+00]],\n",
       "\n",
       "         [[-2.8739e-02,  8.1291e-03, -3.3092e-02,  ..., -1.4344e+00,\n",
       "           -1.3900e+00,  2.3138e+00],\n",
       "          [-4.4991e-02,  5.8032e-01,  9.2004e-01,  ..., -4.3714e-01,\n",
       "            5.2351e-01,  1.7922e+00]]]], grad_fn=<CatBackward0>), tensor([[[[-1.0135e-01,  5.4433e-02, -1.0255e-02,  ..., -1.4932e-01,\n",
       "            2.1620e-01, -3.2555e-02],\n",
       "          [ 1.0103e+00,  9.1253e-01,  7.0438e-01,  ..., -6.2159e-01,\n",
       "            8.4477e-01, -2.2286e-01]],\n",
       "\n",
       "         [[-3.0445e-02, -9.1370e-02,  3.0405e-02,  ...,  6.7006e-02,\n",
       "            2.8841e-02,  7.9145e-03],\n",
       "          [-6.2353e-01, -5.5179e-01, -3.1384e-01,  ...,  4.8861e-01,\n",
       "           -6.6075e-01, -1.1097e+00]],\n",
       "\n",
       "         [[-5.9507e-02, -6.5248e-03,  8.5191e-02,  ..., -2.6476e-02,\n",
       "           -1.8710e-02,  5.9910e-02],\n",
       "          [-2.1181e-01, -1.9661e-01, -2.1682e-01,  ...,  1.5327e-01,\n",
       "            5.9589e-01,  1.5138e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.9292e-02, -2.0540e-02,  1.6788e-02,  ...,  6.0357e-04,\n",
       "           -3.8950e-02, -4.2628e-02],\n",
       "          [-2.8452e-01, -1.0780e-01, -4.7879e-01,  ...,  4.6529e-01,\n",
       "            2.1775e-01, -9.1038e-01]],\n",
       "\n",
       "         [[-1.2597e-02, -6.6748e-03,  7.5087e-03,  ..., -9.3029e-04,\n",
       "           -1.3747e-02,  1.3079e-02],\n",
       "          [-3.8668e-01, -7.7474e-01,  4.6128e-01,  ..., -9.4315e-01,\n",
       "           -1.1703e+00, -9.5834e-01]],\n",
       "\n",
       "         [[ 9.9067e-02, -4.3009e-02, -1.1474e-02,  ...,  2.1092e-02,\n",
       "            1.4838e-01, -8.1968e-03],\n",
       "          [ 1.4722e-01,  1.5540e+00, -1.6055e+00,  ...,  6.3716e-01,\n",
       "           -5.8460e-01, -1.1827e+00]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-4.4105e-02,  8.6601e-02,  3.9616e-02,  ..., -6.1761e+00,\n",
       "           -3.6017e+00, -3.9190e+00],\n",
       "          [-1.0569e-01,  4.5682e-01, -5.0862e-01,  ..., -6.4493e+00,\n",
       "           -4.5758e+00, -4.4553e+00]],\n",
       "\n",
       "         [[-2.5251e-02,  7.2190e-02,  7.2747e-02,  ...,  4.6785e-01,\n",
       "            1.1905e+00,  1.8653e+00],\n",
       "          [-3.6230e-01,  1.3415e+00,  1.0244e-01,  ...,  7.7600e-01,\n",
       "            1.4321e+00,  9.5820e-01]],\n",
       "\n",
       "         [[-6.2143e-02,  5.8271e-02,  2.6768e-02,  ..., -7.4029e+00,\n",
       "            4.0270e+00,  4.7363e+00],\n",
       "          [-1.8453e+00,  2.8853e-01,  1.8844e+00,  ..., -7.2045e+00,\n",
       "            6.1803e+00,  5.5689e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.7365e-02, -7.0825e-02, -6.7316e-03,  ..., -6.1693e+00,\n",
       "            2.2788e+00,  5.0879e+00],\n",
       "          [ 2.1019e+00,  6.8618e-01, -2.7773e+00,  ..., -5.5865e+00,\n",
       "            3.7352e+00,  5.1328e+00]],\n",
       "\n",
       "         [[ 4.9834e-02,  3.7994e-02,  2.9317e-03,  ...,  3.7862e+00,\n",
       "            6.8116e+00, -3.5419e+00],\n",
       "          [ 2.9311e-02, -2.2563e-01,  8.6505e-01,  ...,  4.2371e+00,\n",
       "            8.3748e+00, -4.9657e+00]],\n",
       "\n",
       "         [[ 1.2153e-02,  2.4011e-02, -2.9671e-02,  ..., -1.4588e+00,\n",
       "            2.9772e-01,  1.1714e+00],\n",
       "          [-1.6630e+00, -2.0653e+00, -8.7707e-01,  ..., -9.7997e-01,\n",
       "            2.2778e-01,  9.2836e-02]]]], grad_fn=<CatBackward0>), tensor([[[[ 7.0073e-02, -2.9620e-02, -2.4197e-02,  ..., -1.2509e-01,\n",
       "           -1.9650e-02,  1.1791e-02],\n",
       "          [ 2.4437e-01, -1.0047e+00, -1.0723e+00,  ...,  9.2834e-02,\n",
       "            1.3450e+00, -1.2577e-01]],\n",
       "\n",
       "         [[ 1.4488e-02,  3.2268e-02,  1.6011e-02,  ...,  8.0806e-02,\n",
       "            3.9566e-02, -4.0846e-02],\n",
       "          [ 1.6495e+00, -3.9398e-01, -1.5717e-01,  ...,  1.1568e+00,\n",
       "           -1.5753e-03, -1.7238e-02]],\n",
       "\n",
       "         [[ 3.3816e-02,  1.6180e-02, -2.8654e-02,  ..., -6.7549e-03,\n",
       "            7.7475e-02,  2.8747e-02],\n",
       "          [ 6.7008e-02, -5.9658e-01,  8.0839e-01,  ...,  3.5498e-01,\n",
       "            3.0961e-01, -2.2080e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.2838e-01,  3.2826e-03,  3.2056e-02,  ..., -3.5510e-02,\n",
       "            1.3822e-02,  6.6130e-03],\n",
       "          [ 1.2180e+00, -7.9673e-02,  2.6628e-01,  ..., -8.0287e-01,\n",
       "            2.0179e+00,  5.6114e-01]],\n",
       "\n",
       "         [[-2.0670e-02, -1.5801e-02,  5.1986e-03,  ...,  1.1152e-02,\n",
       "           -7.4926e-02,  8.4648e-02],\n",
       "          [-1.0675e+00, -1.4899e+00,  4.3610e-02,  ..., -7.9827e-01,\n",
       "            3.1507e-02, -6.2926e-01]],\n",
       "\n",
       "         [[-1.0332e-02, -2.2143e-02, -6.5426e-02,  ..., -1.4930e-02,\n",
       "           -4.9874e-02, -3.9006e-02],\n",
       "          [-1.2345e+00, -2.9708e-01, -4.3779e-01,  ..., -6.2931e-01,\n",
       "           -1.6439e-01, -4.0119e-02]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 7.3578e-03,  3.9115e-02, -3.5355e-02,  ..., -4.0464e+00,\n",
       "           -1.0064e+01, -7.9680e+00],\n",
       "          [ 1.1004e+00,  1.4656e-01, -8.8613e-01,  ..., -3.9782e+00,\n",
       "           -1.0804e+01, -8.3820e+00]],\n",
       "\n",
       "         [[ 1.8097e-02, -8.0828e-02, -2.8966e-02,  ..., -1.5071e+01,\n",
       "            1.1556e+01, -4.0618e+00],\n",
       "          [ 2.5902e-02,  2.8738e-01,  8.8534e-01,  ..., -1.5369e+01,\n",
       "            1.2028e+01, -5.2442e+00]],\n",
       "\n",
       "         [[-1.1085e-02,  3.3686e-03,  7.4594e-02,  ...,  8.4651e+00,\n",
       "           -9.4797e+00, -1.1488e+01],\n",
       "          [ 1.3585e-02,  4.8075e-01,  5.9417e-01,  ...,  8.4323e+00,\n",
       "           -1.1029e+01, -1.1582e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.3939e-03, -6.8250e-04, -7.2088e-03,  ..., -4.4272e+00,\n",
       "           -5.9273e+00, -6.7332e+00],\n",
       "          [-8.6864e-01, -9.5872e-01,  2.2775e+00,  ..., -4.3073e+00,\n",
       "           -5.9722e+00, -5.7595e+00]],\n",
       "\n",
       "         [[-1.1098e-01, -7.5940e-02, -1.3858e-01,  ..., -2.4045e+00,\n",
       "           -6.1383e+00, -3.7303e+00],\n",
       "          [-4.0178e-01, -1.1951e+00, -1.5170e+00,  ..., -2.2227e+00,\n",
       "           -6.0641e+00, -2.6750e+00]],\n",
       "\n",
       "         [[-7.0484e-02, -2.2188e-02, -6.3577e-02,  ..., -1.7242e+00,\n",
       "            8.5836e+00,  3.8951e+00],\n",
       "          [-1.4043e+00, -3.7369e-01, -3.0130e-01,  ..., -1.6962e+00,\n",
       "            9.7073e+00,  4.2955e+00]]]], grad_fn=<CatBackward0>), tensor([[[[-2.4243e-02, -2.0206e-02,  9.2354e-02,  ...,  1.6538e-02,\n",
       "            5.5140e-03,  2.0427e-01],\n",
       "          [ 1.5668e+00, -6.3112e-01, -4.1599e-02,  ..., -3.6092e-02,\n",
       "           -9.4563e-01,  1.6766e-01]],\n",
       "\n",
       "         [[ 2.0333e-02, -2.1311e-02, -6.3756e-02,  ..., -6.0233e-02,\n",
       "           -1.4465e-01, -7.7645e-02],\n",
       "          [ 7.3391e-01,  2.1615e+00,  1.1352e+00,  ..., -7.8397e-02,\n",
       "           -8.2469e-02, -3.0900e-01]],\n",
       "\n",
       "         [[ 1.5204e-02,  5.4415e-02, -5.0133e-02,  ...,  6.3810e-03,\n",
       "           -3.7552e-02,  1.8793e-03],\n",
       "          [-1.7379e-01, -3.0233e-01,  4.9500e-01,  ..., -3.7457e-01,\n",
       "           -6.7720e-01, -6.0558e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.3377e-02,  1.0519e-01, -1.0714e-02,  ..., -1.3754e-01,\n",
       "            1.0150e-01,  1.6324e-01],\n",
       "          [ 7.6330e-01, -1.5285e+00, -6.5477e-02,  ..., -3.6413e-02,\n",
       "            7.5496e-01,  1.4343e-01]],\n",
       "\n",
       "         [[ 4.3365e-02, -1.1268e-02,  1.0282e-01,  ..., -3.2410e-03,\n",
       "           -3.5548e-01, -4.6222e-02],\n",
       "          [-1.1125e-01,  1.8171e-01,  1.6117e-01,  ..., -6.9681e-01,\n",
       "            5.7860e-02, -4.9884e-01]],\n",
       "\n",
       "         [[-1.8922e-02, -1.8115e-02, -3.5297e-02,  ..., -2.5400e-02,\n",
       "            4.1580e-02,  7.0280e-02],\n",
       "          [-6.5344e-01,  1.0313e+00,  6.8784e-01,  ...,  8.6793e-01,\n",
       "           -3.7356e-03, -6.6387e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.9071e-02, -2.0052e-02,  3.0765e-02,  ..., -1.6172e+00,\n",
       "           -3.0645e+00, -3.7555e+00],\n",
       "          [-8.6599e-01,  1.8937e+00, -4.8940e-01,  ..., -1.7113e+00,\n",
       "           -2.9873e+00, -4.4759e+00]],\n",
       "\n",
       "         [[ 2.9536e-02,  1.3358e-02,  4.1069e-03,  ..., -8.0989e+00,\n",
       "            8.9812e+00, -1.0434e+01],\n",
       "          [ 4.4076e-01, -9.9501e-01,  4.9736e-01,  ..., -8.4673e+00,\n",
       "            1.0087e+01, -1.1064e+01]],\n",
       "\n",
       "         [[-3.7612e-02, -6.5047e-02,  1.1975e-02,  ..., -8.5180e+00,\n",
       "            9.1535e+00, -6.7999e-01],\n",
       "          [-5.8157e-02,  2.5014e-01, -2.9044e-01,  ..., -8.5329e+00,\n",
       "            7.3026e+00,  2.4450e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.7226e-03, -7.2651e-03,  6.2071e-02,  ...,  1.0111e+01,\n",
       "           -2.1292e+00,  1.1906e+01],\n",
       "          [ 2.1458e-02, -6.7941e-01,  3.7888e-01,  ...,  9.2933e+00,\n",
       "           -3.8630e-01,  1.1714e+01]],\n",
       "\n",
       "         [[ 6.6215e-03, -5.3377e-02, -4.3132e-02,  ..., -3.3755e+00,\n",
       "           -6.1967e+00,  4.6534e+00],\n",
       "          [-1.1552e+00, -1.0449e+00,  1.7325e+00,  ..., -2.1661e+00,\n",
       "           -6.1144e+00,  3.4514e+00]],\n",
       "\n",
       "         [[ 1.4629e-03,  3.2663e-02,  1.3378e-02,  ..., -1.0846e+01,\n",
       "            1.2755e+01,  1.2532e+01],\n",
       "          [ 1.6314e+00, -1.2268e+00, -2.3380e+00,  ..., -1.1167e+01,\n",
       "            1.1833e+01,  1.1726e+01]]]], grad_fn=<CatBackward0>), tensor([[[[-0.0041, -0.0669,  0.1033,  ...,  0.0466, -0.3649, -0.1461],\n",
       "          [-0.9655,  0.6187,  0.5210,  ...,  0.0564,  1.1726, -0.1776]],\n",
       "\n",
       "         [[ 0.1863, -0.1012, -0.0490,  ...,  0.0234,  0.1277, -0.0666],\n",
       "          [-0.5468, -0.1583,  0.4895,  ..., -0.1719,  1.3434,  0.7529]],\n",
       "\n",
       "         [[ 0.0243, -0.0162, -0.0597,  ..., -0.0055,  0.0853,  0.0145],\n",
       "          [ 0.6473,  1.3509,  0.5389,  ..., -0.6263,  0.6589,  0.9996]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0865, -0.0829, -0.0104,  ..., -0.0154, -0.1543,  0.1254],\n",
       "          [-0.0346, -0.5733, -0.2770,  ..., -0.5324, -0.1390,  0.3819]],\n",
       "\n",
       "         [[ 0.0615,  0.0101, -0.0224,  ...,  0.0208,  0.0819, -0.0135],\n",
       "          [-0.0823,  0.4750,  0.4291,  ...,  1.2669,  0.5824,  0.5268]],\n",
       "\n",
       "         [[ 0.0222,  0.0337,  0.0160,  ..., -0.0382,  0.0301,  0.0347],\n",
       "          [-1.0085,  1.3574,  0.3626,  ...,  0.6160,  0.4115, -0.1019]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-2.4363e-02,  1.0554e-01,  4.8274e-02,  ...,  3.4581e+00,\n",
       "            7.3223e+00, -3.7397e+00],\n",
       "          [ 6.2751e-01, -4.8273e-01,  8.0017e-01,  ...,  4.2429e+00,\n",
       "            7.4273e+00, -2.9982e+00]],\n",
       "\n",
       "         [[-5.8158e-02, -1.0164e-02, -1.6261e-02,  ...,  3.5755e+00,\n",
       "           -1.5452e+00, -4.3483e+00],\n",
       "          [-1.0827e-01, -5.1585e-01, -9.2994e-01,  ...,  3.4441e+00,\n",
       "           -2.3938e+00, -5.6217e+00]],\n",
       "\n",
       "         [[-6.6556e-04, -2.4397e-02,  2.5733e-03,  ...,  3.6734e+00,\n",
       "            1.9435e+00,  5.5571e-01],\n",
       "          [-5.0403e-01,  1.0777e+00,  2.1208e+00,  ...,  4.8011e+00,\n",
       "            4.3934e-01,  1.1147e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.8312e-02,  1.5950e-02, -2.5857e-03,  ..., -8.4537e+00,\n",
       "           -8.2571e+00,  7.6862e+00],\n",
       "          [ 5.3274e-01,  4.6477e-01,  1.0558e+00,  ..., -6.9058e+00,\n",
       "           -8.6778e+00,  8.6480e+00]],\n",
       "\n",
       "         [[-2.4049e-02, -5.1384e-02,  3.5819e-02,  ...,  2.1979e+00,\n",
       "            6.1971e+00, -2.9073e-01],\n",
       "          [ 5.6381e-01, -1.2404e+00,  9.8626e-01,  ...,  1.2927e+00,\n",
       "            6.2808e+00, -1.9604e+00]],\n",
       "\n",
       "         [[ 5.9865e-02,  1.3869e-02, -4.8216e-02,  ...,  1.1621e+01,\n",
       "           -1.3431e+01, -1.1753e+01],\n",
       "          [-2.1303e+00, -1.3202e-01,  2.7748e+00,  ...,  1.1452e+01,\n",
       "           -1.4156e+01, -1.3570e+01]]]], grad_fn=<CatBackward0>), tensor([[[[ 0.0106, -0.1528,  0.0794,  ...,  0.0204,  0.0698,  0.1105],\n",
       "          [ 1.1310, -0.1612, -0.7728,  ...,  1.8018,  0.6445, -0.5297]],\n",
       "\n",
       "         [[ 0.0886,  0.1721,  0.0562,  ...,  0.0540, -0.1962, -0.0724],\n",
       "          [ 0.1628,  0.3508, -1.4103,  ..., -0.2842, -0.3690, -0.7487]],\n",
       "\n",
       "         [[-0.1439,  0.1926,  0.1244,  ..., -0.1570, -0.0645,  0.1173],\n",
       "          [-1.2118, -0.6106,  0.3753,  ...,  1.3931, -1.0930,  0.2821]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0248, -0.0460,  0.0267,  ..., -0.0303, -0.0956,  0.0320],\n",
       "          [-1.4341, -0.6962, -1.2734,  ..., -0.7281, -0.6856,  0.5176]],\n",
       "\n",
       "         [[ 0.0915,  0.0779,  0.0737,  ...,  0.3520, -0.0675, -0.0207],\n",
       "          [-0.4903, -0.3519, -0.4249,  ..., -2.2601, -0.9942, -0.2931]],\n",
       "\n",
       "         [[ 0.0237,  0.0389,  0.0416,  ...,  0.0309,  0.0261,  0.0143],\n",
       "          [ 0.3653, -0.4133, -0.3256,  ..., -1.0431,  0.3076, -0.3162]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-5.1352e-02,  5.0490e-03,  7.6073e-02,  ..., -4.6968e+00,\n",
       "            1.5853e+00,  5.6236e+00],\n",
       "          [ 8.6448e-01, -8.9523e-02,  1.4667e+00,  ..., -2.5629e+00,\n",
       "            2.5026e+00,  5.7210e+00]],\n",
       "\n",
       "         [[ 1.0456e-01, -5.5114e-03, -5.9416e-02,  ..., -5.3160e+00,\n",
       "            1.0278e+01, -8.5873e+00],\n",
       "          [-3.2354e-01,  1.4695e-01,  1.2329e+00,  ..., -5.4381e+00,\n",
       "            1.0783e+01, -8.0317e+00]],\n",
       "\n",
       "         [[-4.6299e-03, -3.6192e-02,  5.5979e-02,  ...,  1.4830e+01,\n",
       "            1.2935e+01,  1.5581e+01],\n",
       "          [-4.5596e-01, -1.5430e+00, -6.8705e-01,  ...,  1.5635e+01,\n",
       "            1.2897e+01,  1.6914e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.3442e-02, -2.6096e-02, -4.1991e-02,  ...,  6.7069e+00,\n",
       "            1.4204e+01, -7.4243e+00],\n",
       "          [-1.6303e-01,  1.1930e+00, -4.3457e-01,  ...,  9.1273e+00,\n",
       "            1.4786e+01, -6.6920e+00]],\n",
       "\n",
       "         [[-2.2760e-02,  9.1622e-02,  2.5919e-02,  ..., -2.4348e+01,\n",
       "            2.2380e+01, -2.4186e+01],\n",
       "          [ 4.2815e-01,  5.8226e-01,  7.6934e-01,  ..., -2.4411e+01,\n",
       "            2.2134e+01, -2.4356e+01]],\n",
       "\n",
       "         [[-7.5159e-02, -3.6333e-03, -5.9721e-02,  ...,  6.4557e+00,\n",
       "           -8.0625e+00,  1.3157e+01],\n",
       "          [ 1.9912e-01, -6.0516e-01,  4.5914e-01,  ...,  7.2268e+00,\n",
       "           -7.7146e+00,  1.0969e+01]]]], grad_fn=<CatBackward0>), tensor([[[[ 1.5073e-02,  2.9779e-02, -2.4245e-02,  ...,  2.2653e-02,\n",
       "            3.0944e-02, -5.2972e-02],\n",
       "          [-1.4550e+00, -1.2483e-02,  3.2823e-01,  ...,  2.4703e-01,\n",
       "           -1.1268e+00, -4.3373e-01]],\n",
       "\n",
       "         [[ 4.3502e-03, -6.0985e-03, -3.9061e-02,  ...,  2.0402e-02,\n",
       "            2.7950e-02,  3.9214e-02],\n",
       "          [ 8.0423e-02, -6.3534e-01, -1.8982e+00,  ..., -1.5365e+00,\n",
       "           -7.8579e-01, -5.8587e-01]],\n",
       "\n",
       "         [[-1.8096e-03, -3.3539e-02,  4.0113e-03,  ..., -4.3706e-02,\n",
       "            3.9462e-02,  2.8599e-02],\n",
       "          [ 1.0362e+00,  7.0693e-01, -1.2848e+00,  ...,  1.0763e-01,\n",
       "           -4.1471e-01, -5.9589e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.8699e-02, -8.2770e-02,  2.0181e-01,  ...,  9.7752e-02,\n",
       "            2.5688e-01, -4.7532e-02],\n",
       "          [-5.4784e-01,  8.6588e-01,  2.7446e-01,  ..., -4.5724e-01,\n",
       "           -5.6360e-01,  3.2655e-01]],\n",
       "\n",
       "         [[ 9.0232e-03,  3.3992e-02, -2.3679e-02,  ..., -3.9576e-02,\n",
       "            2.4929e-02, -6.2866e-03],\n",
       "          [ 9.3757e-01,  2.9336e-01, -2.3821e+00,  ..., -9.0062e-01,\n",
       "            9.9807e-01, -1.4481e+00]],\n",
       "\n",
       "         [[ 1.7231e-01, -1.7049e-02, -7.6877e-02,  ...,  5.2983e-02,\n",
       "            9.6399e-02, -5.2481e-02],\n",
       "          [ 3.0362e-01,  2.2993e+00,  8.9833e-01,  ..., -9.9081e-01,\n",
       "            3.0719e-01,  5.1662e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 6.6667e-02,  4.6410e-02, -6.1251e-03,  ..., -1.1469e+01,\n",
       "            1.1668e+01,  8.2199e+00],\n",
       "          [-6.0728e-01,  8.3942e-01,  1.4289e+00,  ..., -1.1125e+01,\n",
       "            1.1802e+01,  8.0056e+00]],\n",
       "\n",
       "         [[ 5.3580e-02, -3.0274e-02, -3.3952e-02,  ..., -2.1904e+01,\n",
       "           -2.3366e+01,  2.9055e+01],\n",
       "          [-9.1752e-01, -5.6855e-01,  2.2083e-01,  ..., -2.1665e+01,\n",
       "           -2.3357e+01,  2.8898e+01]],\n",
       "\n",
       "         [[ 9.0047e-03, -6.7203e-02,  1.3186e-02,  ...,  1.9111e+01,\n",
       "           -2.3065e+01, -1.9558e+01],\n",
       "          [ 1.7638e-01,  4.9785e-01, -1.6705e-01,  ...,  1.9696e+01,\n",
       "           -2.2434e+01, -2.0160e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.4869e-05, -7.1609e-02, -7.8822e-02,  ...,  1.7331e+01,\n",
       "            4.3876e-01, -1.5091e+01],\n",
       "          [-9.1001e-01,  1.5522e+00, -1.5902e+00,  ...,  1.7605e+01,\n",
       "            6.1247e-01, -1.4465e+01]],\n",
       "\n",
       "         [[ 3.5457e-02,  7.3223e-02,  3.6790e-02,  ...,  1.4235e+01,\n",
       "            1.2392e+00, -1.4428e+01],\n",
       "          [-3.7876e-01, -1.0632e-01, -1.8308e-01,  ...,  1.4259e+01,\n",
       "            1.9135e+00, -1.7202e+01]],\n",
       "\n",
       "         [[ 3.9509e-02, -4.7465e-02, -2.1140e-02,  ...,  3.4497e+00,\n",
       "            3.5607e+00,  2.1746e-01],\n",
       "          [ 1.4425e+00,  1.8157e-01,  5.8904e-01,  ...,  5.4885e+00,\n",
       "            2.3764e+00, -1.0239e+00]]]], grad_fn=<CatBackward0>), tensor([[[[ 0.0597, -0.0528,  0.0510,  ...,  0.0357, -0.0302, -0.0108],\n",
       "          [-0.1495, -0.2248, -0.5099,  ...,  0.1887, -0.5554, -0.3768]],\n",
       "\n",
       "         [[-0.0128, -0.0159,  0.0526,  ...,  0.0170, -0.0444, -0.0628],\n",
       "          [ 0.5085, -0.6359, -0.3710,  ...,  0.1979, -0.5731, -0.4276]],\n",
       "\n",
       "         [[-0.0182,  0.0213,  0.0219,  ..., -0.0283,  0.0119,  0.0382],\n",
       "          [ 1.0971, -0.3737,  0.9344,  ...,  0.2984, -0.3585, -0.5807]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0427,  0.0353, -0.0237,  ..., -0.0310,  0.0738, -0.0242],\n",
       "          [-0.6185, -0.6828, -0.3648,  ..., -0.2087,  1.1019, -0.3951]],\n",
       "\n",
       "         [[ 0.0066,  0.0368, -0.0377,  ...,  0.0365,  0.0389,  0.0449],\n",
       "          [ 0.7685,  0.0642,  1.1073,  ..., -1.9340, -2.0172, -0.5781]],\n",
       "\n",
       "         [[ 0.0533, -0.0038,  0.0906,  ..., -0.0484, -0.0625, -0.2521],\n",
       "          [-0.2151,  0.2117,  0.1692,  ..., -0.2250, -0.2628,  0.6105]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-5.3714e-02,  6.5364e-02, -9.9485e-02,  ...,  7.1225e+00,\n",
       "           -8.3941e+00, -1.0636e+01],\n",
       "          [-3.1556e-01, -5.6518e-01,  2.2468e-01,  ...,  7.2486e+00,\n",
       "           -8.5639e+00, -1.0317e+01]],\n",
       "\n",
       "         [[ 1.1910e-01, -4.0193e-02,  3.4733e-02,  ...,  2.2251e+01,\n",
       "           -2.6579e+01, -1.9880e+01],\n",
       "          [-6.3950e-01,  5.9327e-01,  7.5993e-01,  ...,  2.3686e+01,\n",
       "           -2.8105e+01, -2.1146e+01]],\n",
       "\n",
       "         [[ 9.3198e-02, -1.4027e-01,  1.6290e-02,  ...,  3.4737e+01,\n",
       "           -3.5122e+01,  2.7409e+01],\n",
       "          [ 2.0766e-01,  1.3487e+00,  8.1385e-02,  ...,  3.5437e+01,\n",
       "           -3.5195e+01,  2.6888e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.7648e-02, -1.5739e-01,  2.0739e-01,  ...,  1.2448e+01,\n",
       "           -1.8426e+01,  2.4853e+01],\n",
       "          [-3.9213e-01, -7.1342e-01, -1.7614e+00,  ...,  1.2625e+01,\n",
       "           -1.9195e+01,  2.4216e+01]],\n",
       "\n",
       "         [[-8.8149e-02, -2.2299e-01,  1.8147e-01,  ..., -3.1152e+01,\n",
       "            2.8470e+01, -5.5377e+00],\n",
       "          [ 1.0743e+00,  2.6502e-01, -1.9019e+00,  ..., -3.0563e+01,\n",
       "            2.8053e+01, -7.0167e+00]],\n",
       "\n",
       "         [[-9.9791e-02,  1.4537e-02, -2.3446e-02,  ...,  3.1387e+01,\n",
       "            2.9409e+01, -6.8077e+00],\n",
       "          [-2.0530e+00, -1.8672e-01, -4.7219e-01,  ...,  3.0970e+01,\n",
       "            3.0612e+01, -6.5194e+00]]]], grad_fn=<CatBackward0>), tensor([[[[ 0.0613,  0.1976,  0.0779,  ..., -0.1938,  0.0466,  0.1320],\n",
       "          [-0.6615, -0.7773, -1.1000,  ..., -1.3968, -0.7800, -0.5185]],\n",
       "\n",
       "         [[ 0.0368, -0.0815,  0.1211,  ...,  0.0099, -0.0838, -0.0137],\n",
       "          [-0.1212, -1.2534,  0.4384,  ...,  0.7102,  0.2884, -0.5467]],\n",
       "\n",
       "         [[ 0.0595,  0.0774, -0.0418,  ..., -0.0521,  0.0463, -0.0223],\n",
       "          [-0.9726, -1.0329,  0.0966,  ..., -0.1896,  0.8130, -0.6271]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0145,  0.0132, -0.0535,  ...,  0.2160, -0.0941, -0.0444],\n",
       "          [-0.8487, -0.1921,  0.7716,  ...,  0.0864, -0.5869, -0.4178]],\n",
       "\n",
       "         [[-0.0152, -0.0624, -0.0264,  ...,  0.1797,  0.0746, -0.0703],\n",
       "          [-1.6994, -1.2902,  0.0503,  ..., -0.0795,  0.0040,  0.4915]],\n",
       "\n",
       "         [[ 0.1003, -0.0052,  0.0394,  ..., -0.0555, -0.0846,  0.1511],\n",
       "          [ 0.6826, -0.5519,  0.1731,  ..., -0.6282,  0.7981,  0.4837]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 5.7209e-02, -1.5658e-01, -2.4675e-02,  ...,  3.2290e+01,\n",
       "            3.6588e+01,  2.3127e+01],\n",
       "          [-2.6833e-01,  1.1704e+00, -1.3851e+00,  ...,  3.2584e+01,\n",
       "            3.7429e+01,  2.3383e+01]],\n",
       "\n",
       "         [[ 2.8117e-02, -1.1364e-01,  5.7641e-02,  ...,  2.1849e+01,\n",
       "            2.8020e+01,  2.3991e+01],\n",
       "          [ 1.8325e+00, -4.4714e-01,  2.1059e+00,  ...,  2.2981e+01,\n",
       "            3.0210e+01,  2.4191e+01]],\n",
       "\n",
       "         [[-3.4811e-02,  7.4371e-02,  1.6168e-02,  ...,  3.1936e+01,\n",
       "           -4.6331e+01,  3.3920e+01],\n",
       "          [-5.1835e-01, -9.7183e-02, -4.7157e-01,  ...,  3.2647e+01,\n",
       "           -4.8263e+01,  3.4126e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.0595e-01,  1.3413e-02,  1.5574e-01,  ...,  4.0016e+01,\n",
       "           -3.2567e+01, -4.8353e+01],\n",
       "          [ 5.2181e-01, -4.1115e-01,  1.7495e-01,  ...,  3.9920e+01,\n",
       "           -3.3461e+01, -4.9180e+01]],\n",
       "\n",
       "         [[ 1.4993e-01,  6.3678e-03, -1.2571e-01,  ...,  7.3496e+00,\n",
       "            2.7644e+01, -1.9150e+01],\n",
       "          [ 1.0192e-01, -2.1068e-01,  6.7692e-01,  ...,  6.8693e+00,\n",
       "            2.9154e+01, -1.8760e+01]],\n",
       "\n",
       "         [[-9.8717e-02,  2.1431e-02,  7.0248e-03,  ..., -3.5776e+01,\n",
       "            3.5092e+01,  4.1247e+01],\n",
       "          [ 1.2020e+00,  7.6484e-01, -1.8467e+00,  ..., -3.6486e+01,\n",
       "            3.4901e+01,  3.9365e+01]]]], grad_fn=<CatBackward0>), tensor([[[[-8.0118e-03, -8.9335e-02,  1.2622e-01,  ..., -1.1133e-01,\n",
       "           -5.4800e-02, -6.8037e-02],\n",
       "          [ 3.4881e-02,  1.1036e-01, -6.5238e-01,  ...,  1.3603e+00,\n",
       "            4.4228e-01, -6.7171e-01]],\n",
       "\n",
       "         [[-2.3815e-02, -9.4793e-02, -7.0589e-02,  ..., -1.1776e-01,\n",
       "            6.6116e-05, -4.3292e-02],\n",
       "          [ 1.6015e+00,  3.2854e-01, -1.3030e+00,  ...,  3.2849e-01,\n",
       "            1.2946e+00, -6.2587e-01]],\n",
       "\n",
       "         [[ 1.5048e-02,  4.4756e-02,  1.8137e-02,  ...,  2.3644e-01,\n",
       "           -1.2564e-01,  1.2345e-01],\n",
       "          [ 1.6056e+00, -7.8961e-01,  2.0371e-01,  ..., -2.5796e-01,\n",
       "           -1.2516e+00,  7.8355e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.6456e-02,  4.5761e-02, -7.3747e-02,  ..., -1.2080e-02,\n",
       "            1.1527e-01, -6.6195e-02],\n",
       "          [-2.4303e-01, -1.0893e+00,  2.4992e-01,  ..., -4.1499e-01,\n",
       "           -3.5035e-01, -4.4110e-01]],\n",
       "\n",
       "         [[-2.3243e-01, -1.9899e-01, -6.6560e-02,  ..., -8.8979e-02,\n",
       "            6.2817e-02,  1.8936e-01],\n",
       "          [-3.9971e-02,  6.3565e-01,  1.3057e+00,  ..., -1.6427e+00,\n",
       "            6.1145e-01, -1.1415e+00]],\n",
       "\n",
       "         [[-4.4029e-02,  1.0944e-01, -1.8701e-01,  ..., -9.4664e-02,\n",
       "           -3.3931e-02,  1.4076e-01],\n",
       "          [-1.2921e-01, -4.5100e-01, -1.1675e+00,  ..., -2.1791e-01,\n",
       "           -5.2810e-01,  1.3346e+00]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-1.0423e-01, -8.8861e-02,  2.0265e-01,  ...,  4.2067e+01,\n",
       "           -4.1858e+01, -4.1313e+01],\n",
       "          [-2.6068e-01, -7.1811e-01,  8.1751e-01,  ...,  4.1061e+01,\n",
       "           -4.1863e+01, -4.0736e+01]],\n",
       "\n",
       "         [[ 1.5334e-01, -1.7493e-01, -1.4434e-01,  ..., -4.8510e+01,\n",
       "            3.5481e+01,  4.9649e+01],\n",
       "          [ 8.4130e-01, -6.7387e-01, -8.1988e-01,  ..., -5.0324e+01,\n",
       "            3.6107e+01,  4.8589e+01]],\n",
       "\n",
       "         [[ 1.1792e-01, -1.6293e-01, -1.3737e-01,  ...,  4.4527e+01,\n",
       "           -4.3524e+01, -4.4539e+01],\n",
       "          [ 1.6376e-01, -8.9642e-01,  3.7358e-01,  ...,  4.4773e+01,\n",
       "           -4.2287e+01, -4.5316e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-7.7020e-02, -2.9559e-02,  3.3140e-03,  ...,  3.5348e+00,\n",
       "           -2.9887e+01, -4.1848e+01],\n",
       "          [-1.1462e+00,  1.3766e-01, -1.0625e+00,  ...,  3.4817e+00,\n",
       "           -2.9767e+01, -4.2442e+01]],\n",
       "\n",
       "         [[ 1.0543e-01, -7.8344e-02, -1.0573e-01,  ..., -2.1688e+01,\n",
       "           -1.3787e+01,  2.9315e+00],\n",
       "          [ 1.7528e-01,  1.9564e+00,  1.4153e+00,  ..., -2.2033e+01,\n",
       "           -1.3189e+01,  3.3890e+00]],\n",
       "\n",
       "         [[-1.3340e-01,  1.5832e-01, -1.2669e-01,  ...,  3.2502e+01,\n",
       "           -3.1548e+01,  3.5917e+01],\n",
       "          [ 1.8826e+00,  1.5096e+00, -2.3924e+00,  ...,  3.2822e+01,\n",
       "           -3.0518e+01,  3.5664e+01]]]], grad_fn=<CatBackward0>), tensor([[[[-0.0683, -0.0603, -0.0137,  ..., -0.0439,  0.0611,  0.0070],\n",
       "          [ 0.3053, -0.8064, -0.6211,  ..., -0.4044, -1.1373,  0.0450]],\n",
       "\n",
       "         [[-0.0378,  0.0532,  0.1964,  ...,  0.0510,  0.0707,  0.1022],\n",
       "          [-1.5397,  0.3528,  1.1989,  ...,  0.1625, -0.8586,  0.6534]],\n",
       "\n",
       "         [[ 0.0184,  0.0419, -0.0659,  ...,  0.0758,  0.0472,  0.0953],\n",
       "          [-0.2356,  1.2361, -0.5138,  ...,  0.6142, -0.0378,  0.3259]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1548,  0.1051,  0.3390,  ...,  0.2306,  0.8009, -0.0716],\n",
       "          [ 0.7098, -1.1701,  0.3669,  ...,  0.1420, -0.9640, -0.9028]],\n",
       "\n",
       "         [[-0.1101,  0.0283,  0.0313,  ...,  0.0227, -0.0213,  0.0817],\n",
       "          [-0.2495, -0.1618,  0.1197,  ...,  0.0906,  0.3464,  1.1398]],\n",
       "\n",
       "         [[ 0.0882, -0.0293,  0.0286,  ...,  0.1066, -0.0552, -0.1033],\n",
       "          [ 1.0879, -0.4817,  0.1656,  ..., -0.3826,  0.1095, -0.7616]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.6360e-01, -4.3823e-02, -3.8638e-02,  ..., -4.3190e+01,\n",
       "           -5.6356e+01,  5.3840e+01],\n",
       "          [-1.2516e+00, -1.2305e+00, -1.1241e+00,  ..., -4.1077e+01,\n",
       "           -5.5738e+01,  5.3007e+01]],\n",
       "\n",
       "         [[-1.8035e-02, -9.0418e-02, -1.1275e-02,  ...,  5.1765e+01,\n",
       "            1.4591e+01, -4.2902e+01],\n",
       "          [-5.6385e-02, -7.6475e-02, -1.3084e-01,  ...,  5.1715e+01,\n",
       "            1.4412e+01, -4.0248e+01]],\n",
       "\n",
       "         [[ 1.3559e-01, -5.7850e-02,  1.0544e-01,  ...,  4.1854e+01,\n",
       "            4.3280e+01, -4.6683e+01],\n",
       "          [-1.4333e+00, -2.8143e-01,  8.7382e-01,  ...,  4.0978e+01,\n",
       "            4.2391e+01, -4.6212e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1344e-02, -9.9675e-02, -1.8907e-01,  ...,  6.4801e+01,\n",
       "           -5.6687e+01, -3.8196e+01],\n",
       "          [-1.1675e-01, -9.6781e-01, -1.5110e+00,  ...,  6.4850e+01,\n",
       "           -5.6578e+01, -3.7036e+01]],\n",
       "\n",
       "         [[-1.7890e-02, -2.4027e-01,  8.0644e-02,  ...,  5.0269e+01,\n",
       "           -4.8466e+01,  2.2836e+01],\n",
       "          [-3.9728e-01, -2.9194e-01, -3.7532e-02,  ...,  4.9550e+01,\n",
       "           -4.6905e+01,  2.3381e+01]],\n",
       "\n",
       "         [[ 2.3950e-02, -1.2978e-01, -7.7469e-02,  ..., -5.9960e+01,\n",
       "            5.2381e+01, -4.4866e+01],\n",
       "          [ 2.5665e-01, -7.4196e-01, -3.5368e-01,  ..., -6.0123e+01,\n",
       "            4.9668e+01, -4.4561e+01]]]], grad_fn=<CatBackward0>), tensor([[[[ 5.3520e-02, -2.8923e-01, -1.0775e-01,  ..., -6.4485e-02,\n",
       "           -2.7186e-03,  4.0247e-02],\n",
       "          [-3.5415e-01, -1.0527e+00, -1.5929e+00,  ..., -3.5784e-01,\n",
       "           -4.8108e-01,  6.7007e-01]],\n",
       "\n",
       "         [[-1.0157e-01,  1.8034e-01, -1.2391e-01,  ...,  7.0169e-02,\n",
       "            4.1178e-02, -8.1210e-04],\n",
       "          [ 3.4630e-01, -7.9993e-01,  6.7820e-02,  ..., -6.6229e-01,\n",
       "           -4.4049e-01, -7.1524e-01]],\n",
       "\n",
       "         [[-1.6871e-01,  2.9182e-01, -5.1394e-02,  ..., -7.2247e+00,\n",
       "            1.1211e-01,  9.7286e-02],\n",
       "          [-5.3119e-02,  3.0558e-01,  6.3269e-01,  ..., -1.0613e+01,\n",
       "           -3.7172e-01,  1.6819e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.4455e-01, -9.1270e-02,  1.2867e-01,  ...,  6.9190e-02,\n",
       "           -6.4779e-02,  2.3315e-01],\n",
       "          [ 5.4103e-01,  6.2214e-01,  4.5010e-01,  ...,  6.9015e-01,\n",
       "            9.3957e-01,  4.7893e-01]],\n",
       "\n",
       "         [[ 1.1134e-01, -1.1241e-01, -1.2399e-01,  ...,  1.7327e-02,\n",
       "            1.6547e-01, -2.9270e-03],\n",
       "          [-4.2598e-01,  2.4202e-01,  1.1024e-01,  ...,  6.9025e-01,\n",
       "            2.1180e-01, -8.8045e-01]],\n",
       "\n",
       "         [[-4.4653e-02, -5.8199e-02,  2.0321e-01,  ..., -6.9675e-02,\n",
       "           -4.6765e-02,  1.9892e-01],\n",
       "          [-4.7889e-01,  7.1257e-02, -1.3108e-01,  ..., -1.0318e+00,\n",
       "           -9.8049e-01, -7.0863e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 7.2116e-03,  9.0714e-02, -3.5645e-02,  ..., -6.0617e+00,\n",
       "           -3.5608e+01,  1.0264e+01],\n",
       "          [-1.1414e+00,  2.1535e+00,  2.4569e+00,  ..., -5.9877e+00,\n",
       "           -3.4815e+01,  9.8469e+00]],\n",
       "\n",
       "         [[ 3.9731e-01,  1.5754e-01, -4.5683e-01,  ...,  5.6688e+01,\n",
       "           -5.5687e+01,  2.6027e+01],\n",
       "          [ 3.8720e+00, -5.4460e-01, -1.9117e+00,  ...,  5.6577e+01,\n",
       "           -5.5021e+01,  2.5555e+01]],\n",
       "\n",
       "         [[ 6.6129e-02,  1.5805e-01, -1.7524e-01,  ..., -5.5551e+01,\n",
       "           -5.7816e+01, -5.0254e+01],\n",
       "          [-3.2599e-01,  3.8537e-01, -1.6849e-01,  ..., -5.4774e+01,\n",
       "           -5.8388e+01, -4.9018e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.5275e-02, -5.4488e-02, -8.4198e-02,  ..., -7.1748e+01,\n",
       "            5.9264e+01, -1.0737e+01],\n",
       "          [-3.2214e-01, -9.5199e-02,  9.0359e-01,  ..., -7.0289e+01,\n",
       "            5.8521e+01, -1.0539e+01]],\n",
       "\n",
       "         [[-1.2213e-01, -2.2962e-01,  9.4974e-04,  ..., -3.9027e+01,\n",
       "            5.7458e+01, -5.3164e+01],\n",
       "          [-9.4244e-01, -2.1792e+00,  2.3105e+00,  ..., -4.2565e+01,\n",
       "            5.7475e+01, -5.2127e+01]],\n",
       "\n",
       "         [[ 5.8150e-02,  4.0226e-01,  1.3513e-02,  ..., -5.3869e+01,\n",
       "            5.2247e+01, -5.9382e+01],\n",
       "          [ 3.2209e-01,  1.8416e-01, -5.7846e-01,  ..., -5.3235e+01,\n",
       "            5.3524e+01, -5.9286e+01]]]], grad_fn=<CatBackward0>), tensor([[[[-0.2397, -0.0757, -0.4934,  ...,  0.0132,  0.0410,  0.1465],\n",
       "          [-0.3494,  0.2885, -0.4897,  ..., -0.4924,  0.2126,  1.4728]],\n",
       "\n",
       "         [[-0.0981,  0.3227, -0.2934,  ..., -0.0893, -0.1886,  0.1411],\n",
       "          [-0.4327,  0.7762, -1.2196,  ..., -0.2561, -0.0874, -0.0912]],\n",
       "\n",
       "         [[-0.0649,  0.2483,  0.0971,  ...,  0.0243, -0.2362, -0.0404],\n",
       "          [-1.0798,  0.4285,  0.6634,  ...,  0.4986,  0.3481,  0.2669]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1016,  0.1376,  0.1930,  ..., -0.0021, -0.0185,  0.1566],\n",
       "          [ 0.4882,  0.0124,  0.1708,  ..., -0.4926,  0.3181,  0.4153]],\n",
       "\n",
       "         [[ 0.2341,  0.2165,  0.1687,  ...,  0.0300, -0.0798,  0.3126],\n",
       "          [ 0.5910,  0.3389, -0.2501,  ...,  0.2207, -0.4708,  1.9034]],\n",
       "\n",
       "         [[ 0.0381,  0.0811,  0.1221,  ..., -0.0519,  0.1837,  0.0905],\n",
       "          [ 0.0328,  1.1721, -0.1070,  ..., -0.2455,  1.1482,  0.3697]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.6468e-01, -1.1600e-01,  7.3822e-02,  ..., -4.2420e+01,\n",
       "            7.5783e+01,  4.6611e+01],\n",
       "          [-1.2735e+00, -1.2709e-01,  5.2185e-01,  ..., -4.2538e+01,\n",
       "            7.3523e+01,  4.5253e+01]],\n",
       "\n",
       "         [[-1.5349e-01,  3.3638e-01, -1.0354e-01,  ...,  6.5639e+01,\n",
       "            7.0366e+01,  7.0831e+01],\n",
       "          [-2.1304e-01, -1.7856e+00,  1.2622e+00,  ...,  6.2420e+01,\n",
       "            6.8626e+01,  6.8338e+01]],\n",
       "\n",
       "         [[ 1.7984e-01, -5.7394e-02,  3.8311e-01,  ..., -7.0244e+01,\n",
       "           -7.0402e+01,  6.9488e+01],\n",
       "          [-3.2558e-01, -1.4145e+00,  1.8178e+00,  ..., -6.7773e+01,\n",
       "           -6.9173e+01,  6.8350e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.0572e-01, -5.1558e-02,  4.5295e-02,  ...,  7.6232e+01,\n",
       "           -6.6927e+01, -2.2088e+01],\n",
       "          [-1.1686e+00,  9.1997e-02,  1.0853e+00,  ...,  7.4310e+01,\n",
       "           -6.5750e+01, -2.7248e+01]],\n",
       "\n",
       "         [[-4.0743e-01, -7.4057e-02, -1.5411e-04,  ...,  8.0603e+01,\n",
       "            8.0051e+01, -8.1361e+01],\n",
       "          [-6.8145e-01, -3.7197e-01,  2.2137e-01,  ...,  7.9375e+01,\n",
       "            7.8257e+01, -8.0500e+01]],\n",
       "\n",
       "         [[ 7.5770e-02,  3.1517e-02, -4.0717e-02,  ...,  4.6909e+01,\n",
       "           -5.0454e+01, -5.7257e+01],\n",
       "          [ 4.9130e-03,  1.1007e+00,  1.4016e+00,  ...,  4.6885e+01,\n",
       "           -4.8158e+01, -5.5690e+01]]]], grad_fn=<CatBackward0>), tensor([[[[ 0.1592,  0.3483, -0.0480,  ...,  0.0152, -0.1553,  0.1202],\n",
       "          [ 0.7907,  0.2421, -0.0996,  ...,  0.7608, -0.7492,  0.3284]],\n",
       "\n",
       "         [[ 0.0640,  0.1864,  0.2184,  ..., -0.1240,  0.1707,  0.1060],\n",
       "          [ 0.1928, -0.0507, -0.0480,  ...,  0.3732,  0.2306, -0.1357]],\n",
       "\n",
       "         [[-0.2697, -0.0255, -0.1011,  ..., -0.1885, -0.0423, -0.0428],\n",
       "          [-2.2740, -1.3918, -0.4193,  ..., -0.5258, -0.0840,  1.0939]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1754, -0.2069, -0.1839,  ...,  0.1502,  0.1068, -0.0229],\n",
       "          [ 0.0757, -0.8887, -0.7605,  ...,  0.6899, -0.5643,  0.7653]],\n",
       "\n",
       "         [[ 0.0399, -0.0100,  0.0687,  ..., -0.1195, -0.0052, -0.2321],\n",
       "          [ 0.7636, -0.3896, -0.0139,  ..., -0.2591, -0.1712, -0.7373]],\n",
       "\n",
       "         [[ 0.0232, -0.2329,  0.0063,  ..., -0.2466,  0.1510,  0.1881],\n",
       "          [ 0.3073, -0.4010, -1.5105,  ...,  0.4493,  1.8666,  0.1720]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.2935e-01, -4.6737e-02,  8.8916e-02,  ..., -3.4286e+01,\n",
       "            5.3358e+01, -6.6122e+01],\n",
       "          [ 1.6185e+00,  2.5453e+00, -2.2817e+00,  ..., -3.4135e+01,\n",
       "            5.1852e+01, -6.5129e+01]],\n",
       "\n",
       "         [[-8.8416e-02,  3.1353e-01, -8.5060e-02,  ..., -2.9507e+01,\n",
       "            4.9914e+01,  4.2344e+01],\n",
       "          [-6.8411e-01,  1.6247e+00, -1.0229e+00,  ..., -2.6456e+01,\n",
       "            4.9652e+01,  4.1199e+01]],\n",
       "\n",
       "         [[ 2.0943e-01,  6.1418e-02, -2.3206e-01,  ...,  7.4260e+01,\n",
       "            8.0147e+01,  7.4344e+01],\n",
       "          [-2.8582e-02,  1.4751e-01, -1.7866e-01,  ...,  7.2386e+01,\n",
       "            7.7621e+01,  7.1016e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.4639e-01, -1.1796e-01, -5.4231e-02,  ...,  7.9031e+01,\n",
       "           -8.4949e+01,  7.8180e+01],\n",
       "          [ 1.5874e-01, -4.3161e-01, -5.5886e-01,  ...,  7.6468e+01,\n",
       "           -8.1598e+01,  7.6862e+01]],\n",
       "\n",
       "         [[-3.6929e-01, -5.6821e-02, -2.4199e-01,  ...,  6.9464e+01,\n",
       "            7.1713e+01, -4.9933e+01],\n",
       "          [-9.8935e-01, -2.3212e-01, -5.2403e-02,  ...,  6.7708e+01,\n",
       "            6.9594e+01, -4.9588e+01]],\n",
       "\n",
       "         [[-4.6746e-02, -2.1077e-01,  1.2257e-01,  ..., -7.5662e+01,\n",
       "           -8.4699e+01, -7.2998e+01],\n",
       "          [-2.7575e-01, -8.4759e-01, -6.1644e-01,  ..., -7.4012e+01,\n",
       "           -8.0848e+01, -7.0381e+01]]]], grad_fn=<CatBackward0>), tensor([[[[ 1.0330e-01, -1.8609e-02, -1.3459e-03,  ...,  6.9434e-02,\n",
       "           -6.7790e-02, -2.1647e-01],\n",
       "          [ 4.9405e-02, -5.9773e-01, -4.3352e-01,  ...,  9.2463e-01,\n",
       "           -6.0862e-01,  3.1929e-01]],\n",
       "\n",
       "         [[-1.0306e-01,  4.8470e-04,  2.8466e-01,  ...,  9.4903e-02,\n",
       "           -1.9170e-01,  1.6816e-02],\n",
       "          [-9.9763e-01,  1.6352e-01,  1.0305e+00,  ...,  9.2570e-02,\n",
       "           -9.5648e-01, -3.2064e-01]],\n",
       "\n",
       "         [[-1.5040e-01, -2.4014e-01,  9.5953e-02,  ..., -2.0600e-02,\n",
       "            1.1934e-01, -1.5453e-01],\n",
       "          [-1.2657e-01, -8.6095e-01,  3.9340e-01,  ...,  3.2210e-01,\n",
       "            6.8705e-01, -6.4232e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-9.4756e-02,  2.7437e-01, -1.4186e-02,  ..., -2.9918e-02,\n",
       "            1.5848e-01, -5.2807e-03],\n",
       "          [-3.5009e-01,  4.0613e-01, -3.7747e-01,  ..., -2.0323e-01,\n",
       "            7.2338e-01,  2.3528e-01]],\n",
       "\n",
       "         [[ 7.8041e-02, -1.3939e-01,  1.4739e-02,  ...,  4.0046e-02,\n",
       "            1.3648e-01,  4.4826e-02],\n",
       "          [-4.0096e-01, -3.4352e-01, -1.8328e-01,  ..., -5.2789e-01,\n",
       "            8.9913e-01,  2.9424e-01]],\n",
       "\n",
       "         [[ 1.3486e-02,  2.8002e-02, -1.7311e-01,  ..., -2.0864e-02,\n",
       "            5.1883e-02,  2.7501e-01],\n",
       "          [ 5.0910e-01,  3.9767e-01, -4.5919e-01,  ..., -4.4081e-01,\n",
       "            1.1091e-01,  2.4748e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.2503e-01, -1.5459e-01, -5.7731e-01,  ...,  7.3546e+01,\n",
       "           -6.8462e+01, -6.9633e+01],\n",
       "          [ 9.3733e-01, -5.4756e-02, -1.8339e+00,  ...,  7.0769e+01,\n",
       "           -6.6483e+01, -6.7215e+01]],\n",
       "\n",
       "         [[-4.5773e-01, -3.3713e-01,  1.0737e-02,  ..., -8.4102e+01,\n",
       "           -5.7380e+01, -5.3009e+01],\n",
       "          [-6.4145e-01, -7.7091e-01, -3.5836e-01,  ..., -8.1186e+01,\n",
       "           -5.4915e+01, -5.0184e+01]],\n",
       "\n",
       "         [[ 3.8483e-01, -1.3327e-01, -2.8384e-01,  ..., -6.7984e+01,\n",
       "           -6.0000e+01,  5.1321e+01],\n",
       "          [ 8.3374e-01, -1.0908e+00, -1.3050e+00,  ..., -6.5464e+01,\n",
       "           -5.6712e+01,  5.0416e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.8010e-01,  3.1606e-01, -2.6754e-01,  ...,  8.5136e+01,\n",
       "            4.2821e+01, -7.1511e+01],\n",
       "          [ 1.0547e+00, -2.1058e-01, -1.5168e+00,  ...,  8.1421e+01,\n",
       "            4.2378e+01, -6.7818e+01]],\n",
       "\n",
       "         [[-8.9515e-02,  1.2044e-01, -1.2788e-01,  ..., -8.4136e+01,\n",
       "           -6.4379e+01, -2.9259e+01],\n",
       "          [ 9.0018e-01,  6.5191e-01,  4.3950e-01,  ..., -8.1972e+01,\n",
       "           -6.1427e+01, -2.7500e+01]],\n",
       "\n",
       "         [[ 2.8377e-03, -1.3625e-01, -6.4239e-01,  ...,  7.1882e+01,\n",
       "            5.1270e+01, -5.9058e+01],\n",
       "          [-9.7604e-01, -9.6207e-01, -1.6845e+00,  ...,  6.8469e+01,\n",
       "            4.9388e+01, -5.5442e+01]]]], grad_fn=<CatBackward0>), tensor([[[[ 7.9219e-03,  1.0672e-01,  7.0761e-02,  ..., -8.9499e-02,\n",
       "           -2.4094e-01, -1.1022e-01],\n",
       "          [ 8.3509e-02,  7.7724e-01,  5.6125e-01,  ..., -9.4792e-01,\n",
       "            1.4979e-04, -7.1598e-01]],\n",
       "\n",
       "         [[-9.3948e-02, -4.9976e-03,  9.6805e-02,  ..., -4.9151e-02,\n",
       "           -2.6476e-02, -2.7672e-01],\n",
       "          [-5.2907e-01,  3.7328e-01,  5.7166e-01,  ...,  1.4221e-01,\n",
       "           -5.6600e-01, -4.5178e-01]],\n",
       "\n",
       "         [[ 2.6446e-01, -1.4728e-01, -1.6720e-01,  ...,  3.7713e-02,\n",
       "            5.2207e-02,  5.8666e-02],\n",
       "          [ 5.1819e-01, -3.6345e-01, -3.4000e-01,  ..., -7.0590e-01,\n",
       "           -9.9812e-01,  1.3821e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.6072e-01,  2.2058e-01, -2.7424e-01,  ...,  9.5405e-02,\n",
       "            2.1637e-01, -3.1784e-01],\n",
       "          [ 1.5868e-01,  5.1638e-01, -9.4341e-01,  ...,  7.2285e-01,\n",
       "            5.5756e-01, -1.3748e+00]],\n",
       "\n",
       "         [[ 2.9903e-02, -1.6064e-01,  1.7599e-01,  ...,  1.0514e-01,\n",
       "           -3.2976e-01, -1.2421e-01],\n",
       "          [-1.1452e-01, -2.4120e-02,  1.4240e-02,  ..., -7.2363e-01,\n",
       "           -3.9381e-02, -1.9823e-01]],\n",
       "\n",
       "         [[-1.3283e-01,  3.4652e-01, -1.1033e-01,  ..., -3.2570e-01,\n",
       "           -1.8359e-01,  2.1510e-01],\n",
       "          [-1.3557e+00,  7.2314e-01, -7.1919e-01,  ..., -6.0847e-01,\n",
       "           -1.2700e-01,  6.6475e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-5.1502e-01,  1.8906e-01, -2.2676e-01,  ...,  7.9188e+01,\n",
       "            7.8210e+01, -4.8965e+01],\n",
       "          [-2.4662e+00, -2.3888e-01, -1.0934e+00,  ...,  7.4280e+01,\n",
       "            7.3828e+01, -4.8574e+01]],\n",
       "\n",
       "         [[-2.2667e-02,  4.8256e-01, -3.7445e-01,  ...,  7.1313e+01,\n",
       "            6.4598e+01,  7.2749e+01],\n",
       "          [-6.3312e-01,  1.5929e+00, -9.0013e-01,  ...,  6.9392e+01,\n",
       "            6.0980e+01,  7.0023e+01]],\n",
       "\n",
       "         [[ 3.4564e-01, -2.3569e-01, -2.8719e-01,  ...,  7.3260e+01,\n",
       "            6.9201e+01,  7.4050e+01],\n",
       "          [ 2.0545e+00, -1.5997e+00, -2.1138e-01,  ...,  6.9483e+01,\n",
       "            6.4468e+01,  6.9928e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.4012e-02,  5.1675e-01, -2.4115e-01,  ..., -7.9894e+01,\n",
       "           -7.7789e+01,  8.6843e+01],\n",
       "          [-4.6749e-01,  1.1951e+00, -6.2393e-01,  ..., -7.6816e+01,\n",
       "           -7.3020e+01,  8.3518e+01]],\n",
       "\n",
       "         [[ 3.9326e-02,  1.6027e-01,  3.0375e-01,  ..., -7.3693e+01,\n",
       "           -5.2445e+01,  6.3237e+01],\n",
       "          [ 1.5190e+00,  6.0112e-01,  2.4454e-02,  ..., -6.9100e+01,\n",
       "           -5.0470e+01,  6.0924e+01]],\n",
       "\n",
       "         [[ 4.4441e-01, -6.2851e-01, -5.1859e-01,  ...,  7.9887e+01,\n",
       "           -7.4498e+01, -6.2750e+01],\n",
       "          [-5.0794e-02, -8.9334e-01,  2.5911e-01,  ...,  7.6747e+01,\n",
       "           -7.2342e+01, -5.9856e+01]]]], grad_fn=<CatBackward0>), tensor([[[[ 4.8615e-02, -6.1537e-02,  2.9529e-01,  ..., -1.0930e-01,\n",
       "            1.7566e-01, -1.0285e-01],\n",
       "          [-5.2401e-01, -2.6323e-01,  6.3864e-01,  ..., -2.6178e-01,\n",
       "            7.4244e-01, -3.2096e-01]],\n",
       "\n",
       "         [[ 3.0971e-02,  1.3835e-01, -1.4861e-01,  ...,  3.2088e-01,\n",
       "           -9.1344e-02, -1.2220e-02],\n",
       "          [ 1.7007e-01,  4.4835e-01, -7.6618e-01,  ...,  1.7011e+00,\n",
       "           -7.6778e-02, -1.0119e-01]],\n",
       "\n",
       "         [[ 2.0302e-01,  1.5399e-01,  1.1600e-02,  ...,  2.0037e-03,\n",
       "           -1.9684e-02, -2.0390e-01],\n",
       "          [ 2.2722e+00,  3.9780e-01, -3.3341e-01,  ..., -5.1332e-02,\n",
       "            5.4947e-01, -1.4414e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.8866e-01, -7.0951e-02,  1.6130e-02,  ...,  2.0154e-01,\n",
       "            3.4575e-01,  4.0743e-02],\n",
       "          [-7.1638e-01, -6.6345e-01,  6.2416e-02,  ...,  7.5480e-01,\n",
       "            1.2902e+00, -8.5076e-01]],\n",
       "\n",
       "         [[-2.4370e-01, -1.2540e-01,  2.1973e-01,  ..., -3.3767e-03,\n",
       "           -7.8199e-02, -1.0310e-02],\n",
       "          [-1.3809e+00, -5.4689e-01,  1.0067e+00,  ..., -6.0861e-02,\n",
       "           -8.9474e-02, -4.4795e-01]],\n",
       "\n",
       "         [[ 2.1018e-01,  1.1386e-01,  1.4218e-01,  ...,  9.0091e-02,\n",
       "            3.5550e-01, -2.2667e-01],\n",
       "          [ 4.7678e-01,  2.2106e-01, -1.0737e-01,  ...,  4.3043e-01,\n",
       "            4.0285e-01, -6.8839e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 2.5953e-01, -2.3437e-01, -7.4045e-02,  ...,  5.3824e+01,\n",
       "            8.6443e+01,  5.1625e+01],\n",
       "          [-4.3245e-01, -1.3710e+00,  6.6221e-01,  ...,  4.8427e+01,\n",
       "            8.0407e+01,  4.9585e+01]],\n",
       "\n",
       "         [[ 1.4651e-01, -3.4095e-01,  7.4379e-02,  ...,  6.1299e+01,\n",
       "            6.2097e+01, -8.0756e+01],\n",
       "          [ 9.2083e-01, -9.1934e-01, -3.2821e-01,  ...,  5.7760e+01,\n",
       "            5.8578e+01, -7.5249e+01]],\n",
       "\n",
       "         [[ 3.0204e-01,  1.6086e-01,  5.0658e-02,  ...,  6.4807e+01,\n",
       "           -5.8495e+01, -7.8454e+01],\n",
       "          [-6.8603e-01,  1.2725e+00, -9.6749e-01,  ...,  6.1608e+01,\n",
       "           -5.5304e+01, -7.3620e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.8567e-02,  1.7502e-01,  4.0193e-01,  ..., -7.9738e+01,\n",
       "           -7.0071e+01, -6.3362e+01],\n",
       "          [ 2.7803e-01, -4.4308e-02,  2.3836e-01,  ..., -7.6043e+01,\n",
       "           -6.7405e+01, -5.7430e+01]],\n",
       "\n",
       "         [[ 5.2693e-01, -2.0300e-01,  3.0278e-01,  ..., -5.2324e+01,\n",
       "            7.3244e+01,  6.9412e+01],\n",
       "          [-6.1922e-01, -4.7841e-01,  9.6344e-01,  ..., -4.9043e+01,\n",
       "            6.8002e+01,  6.4495e+01]],\n",
       "\n",
       "         [[-1.7809e-01, -1.6895e-01, -2.2074e-01,  ...,  8.0982e+01,\n",
       "            8.0932e+01,  8.1452e+01],\n",
       "          [-2.7803e-01, -7.4361e-01, -4.7754e-01,  ...,  7.7148e+01,\n",
       "            7.6076e+01,  7.7402e+01]]]], grad_fn=<CatBackward0>), tensor([[[[-0.0563, -0.0168, -0.1360,  ..., -0.5617, -0.1365, -0.3748],\n",
       "          [ 0.1912,  0.1136, -0.0168,  ..., -1.0971, -0.5333, -2.5970]],\n",
       "\n",
       "         [[-0.1097, -0.1708, -0.1599,  ...,  0.1413,  0.0193,  0.1353],\n",
       "          [-0.8897, -1.1461, -0.5818,  ...,  0.0033, -0.0285,  0.0296]],\n",
       "\n",
       "         [[-0.0511,  0.2071,  0.0130,  ..., -0.1914,  0.1544,  0.0894],\n",
       "          [ 0.4169,  0.4543,  0.3640,  ..., -0.7488,  0.2845, -0.3812]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1318,  0.2239,  0.0449,  ...,  0.0690,  0.1205,  0.2158],\n",
       "          [ 0.1593,  0.7721,  0.1007,  ...,  0.4371,  0.3281,  0.9871]],\n",
       "\n",
       "         [[-0.0268,  0.0667,  0.0854,  ..., -0.1148,  0.2245, -0.3641],\n",
       "          [ 0.0405,  0.1361, -0.0760,  ..., -0.7710,  0.7412, -1.3979]],\n",
       "\n",
       "         [[ 0.1633,  0.0296,  0.1357,  ..., -0.0671, -0.2132,  0.2362],\n",
       "          [ 0.3255,  0.3315, -0.1725,  ...,  0.1146,  0.1528,  0.6811]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.3080e-01,  2.3002e-01,  3.3928e-02,  ...,  9.9536e+01,\n",
       "            1.0778e+02, -8.7049e+01],\n",
       "          [-5.2179e-01,  1.8359e+00,  2.9071e-01,  ...,  9.2263e+01,\n",
       "            9.9778e+01, -8.1020e+01]],\n",
       "\n",
       "         [[ 5.9213e-02, -4.1469e-01,  1.5964e-01,  ...,  7.6668e+01,\n",
       "           -6.6685e+01,  6.5045e+01],\n",
       "          [ 9.3916e-01, -1.0687e+00,  1.5292e+00,  ...,  7.1841e+01,\n",
       "           -6.2122e+01,  6.2882e+01]],\n",
       "\n",
       "         [[ 6.1557e-01, -4.0293e-01, -4.8812e-01,  ..., -9.1753e+01,\n",
       "            7.1017e+01, -5.3258e+01],\n",
       "          [-1.7704e-02, -1.6072e+00,  1.4563e+00,  ..., -8.6056e+01,\n",
       "            6.5831e+01, -4.9612e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.6921e-01,  1.6810e-02,  1.8342e-02,  ..., -8.8313e+01,\n",
       "           -5.2606e+01, -8.3267e+01],\n",
       "          [ 7.8535e-01, -8.9952e-01, -3.4216e-02,  ..., -8.2797e+01,\n",
       "           -4.9070e+01, -7.8240e+01]],\n",
       "\n",
       "         [[-2.8560e-02,  2.6597e-01,  4.2560e-01,  ..., -7.4744e+01,\n",
       "            7.5730e+01, -7.9011e+01],\n",
       "          [ 1.0313e+00,  4.0271e-01,  1.6905e+00,  ..., -7.0308e+01,\n",
       "            7.0521e+01, -7.3934e+01]],\n",
       "\n",
       "         [[ 4.7118e-01,  4.8580e-02,  4.8063e-01,  ...,  7.7098e+01,\n",
       "           -4.8385e+01,  2.9781e+01],\n",
       "          [ 9.6727e-01, -4.2943e-01,  1.0401e+00,  ...,  7.1025e+01,\n",
       "           -4.4791e+01,  2.7607e+01]]]], grad_fn=<CatBackward0>), tensor([[[[ 0.1466, -0.0183, -0.0398,  ..., -0.0480, -0.0500,  0.1175],\n",
       "          [ 0.3839, -0.3388,  0.1795,  ..., -0.5020, -0.3894,  0.1377]],\n",
       "\n",
       "         [[ 0.1740,  0.0457, -0.0675,  ..., -0.1571, -0.1996, -0.3101],\n",
       "          [ 0.6976,  0.2254,  0.1221,  ..., -0.6199, -0.6310, -0.8219]],\n",
       "\n",
       "         [[-0.1465,  0.3260,  0.0025,  ...,  0.2712, -0.0749,  0.0112],\n",
       "          [ 0.1004,  1.3885, -0.0445,  ...,  0.8403, -0.4019,  0.0078]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0402,  0.2652, -0.0244,  ...,  0.2984, -0.0296, -0.1700],\n",
       "          [-0.8087,  0.8940, -0.0823,  ...,  0.6879, -0.5979, -0.8338]],\n",
       "\n",
       "         [[ 0.2854, -0.0099,  0.0453,  ..., -0.0320,  0.0682,  0.0221],\n",
       "          [ 0.4610, -0.2541, -0.1246,  ..., -0.2438,  0.2642,  0.1319]],\n",
       "\n",
       "         [[ 0.0952, -0.0310, -0.0051,  ...,  0.0815,  0.0871, -0.1603],\n",
       "          [-0.0110, -0.0500, -0.0344,  ...,  0.2069,  0.1147, -0.5811]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-8.7521e-01, -6.6136e-01, -6.0669e-01,  ..., -6.5024e+01,\n",
       "            6.7395e+01,  7.0126e+01],\n",
       "          [-2.9017e+00, -4.3264e+00, -1.0685e+00,  ..., -6.0480e+01,\n",
       "            6.3968e+01,  6.7388e+01]],\n",
       "\n",
       "         [[ 4.0036e-02,  2.6357e-01, -1.1899e-01,  ..., -5.5286e+01,\n",
       "           -9.5597e+00,  5.5601e+01],\n",
       "          [-1.6437e+00,  1.7550e-01, -1.7612e-01,  ..., -5.2336e+01,\n",
       "           -9.0504e+00,  5.2629e+01]],\n",
       "\n",
       "         [[ 6.4895e-02,  7.4323e-02, -1.0165e-01,  ...,  6.9055e+01,\n",
       "            3.5423e+01, -1.4803e+01],\n",
       "          [ 8.1586e-01,  3.5049e+00,  1.8091e+00,  ...,  6.4614e+01,\n",
       "            3.3824e+01, -1.2952e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.6401e-01, -2.0834e-01, -3.5846e-01,  ..., -6.4634e+01,\n",
       "           -4.2382e+01, -7.2642e+01],\n",
       "          [-1.7019e+00, -3.9347e-01, -2.7026e-01,  ..., -5.9894e+01,\n",
       "           -4.1949e+01, -6.7912e+01]],\n",
       "\n",
       "         [[ 8.2431e-01, -2.6939e-02,  2.2176e-01,  ...,  1.1046e+01,\n",
       "           -7.1894e+01, -6.6580e+01],\n",
       "          [ 2.4455e+00, -1.0935e+00, -2.8387e+00,  ...,  9.2086e+00,\n",
       "           -6.7007e+01, -6.4131e+01]],\n",
       "\n",
       "         [[-2.4068e-01, -1.9899e-01, -8.8359e-02,  ...,  6.4774e+01,\n",
       "           -3.8169e+01, -6.8437e+01],\n",
       "          [-4.6205e-01, -1.0073e+00, -1.7442e-01,  ...,  5.9876e+01,\n",
       "           -3.4490e+01, -6.1616e+01]]]], grad_fn=<CatBackward0>), tensor([[[[-0.0228,  0.0662,  0.1195,  ...,  0.0528, -0.1300,  0.1448],\n",
       "          [ 0.5066, -0.0420,  0.6825,  ...,  0.4893,  0.0636,  0.7351]],\n",
       "\n",
       "         [[-0.0533, -0.1602,  0.2000,  ...,  0.0277, -0.0124,  0.1968],\n",
       "          [ 0.4422, -0.4999,  0.7320,  ..., -0.0405,  0.1747,  0.4758]],\n",
       "\n",
       "         [[ 0.1852,  0.0628,  0.0351,  ...,  0.1201,  0.2668, -0.0250],\n",
       "          [ 1.8142,  0.4070, -0.0870,  ...,  0.2831,  1.4393,  0.2823]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0029, -0.3678,  0.1218,  ..., -0.0623, -0.1687,  0.0220],\n",
       "          [ 0.2886, -1.5475, -0.1375,  ..., -0.0042, -0.5927,  0.6258]],\n",
       "\n",
       "         [[ 0.0268,  0.2781,  0.2606,  ..., -0.3653,  0.1193, -0.1853],\n",
       "          [-0.4319,  1.1163,  0.4614,  ..., -1.2743,  0.2269, -1.1123]],\n",
       "\n",
       "         [[-0.2084, -0.1160, -0.4241,  ...,  0.1009, -0.1695, -0.0703],\n",
       "          [ 0.0563, -0.2921, -1.0963,  ...,  0.2836,  0.0684, -0.1733]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 6.2271e-01, -2.1736e-01,  2.1924e-01,  ..., -6.9252e+01,\n",
       "            4.5727e+01,  7.2019e+01],\n",
       "          [ 5.2126e+00, -1.7476e+00,  2.5479e+00,  ..., -6.5949e+01,\n",
       "            4.3324e+01,  6.6700e+01]],\n",
       "\n",
       "         [[ 9.4801e-01, -6.7193e-01, -2.5575e-01,  ..., -9.4546e+00,\n",
       "           -6.3584e+01,  4.6964e+01],\n",
       "          [ 3.9384e+00, -3.9648e+00, -1.7619e+00,  ..., -9.1632e+00,\n",
       "           -6.0193e+01,  4.5416e+01]],\n",
       "\n",
       "         [[ 7.0244e-01,  1.1118e+00,  8.0834e-01,  ...,  4.1522e+01,\n",
       "            7.1607e+01,  3.4062e+01],\n",
       "          [ 4.5896e+00,  6.0422e+00,  2.9717e+00,  ...,  3.9942e+01,\n",
       "            6.7432e+01,  3.3047e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.2199e-01, -1.3640e-01,  1.5331e-01,  ..., -6.8103e+01,\n",
       "            7.3318e+01,  4.6591e+01],\n",
       "          [-1.4386e+00,  1.2364e-01,  1.5226e-01,  ..., -6.2552e+01,\n",
       "            6.8734e+01,  4.4279e+01]],\n",
       "\n",
       "         [[-5.7676e-02,  3.6363e-01,  5.0312e-01,  ...,  5.6208e+01,\n",
       "            4.8443e+01, -5.4029e+01],\n",
       "          [ 5.2440e-01,  1.1282e-01,  1.2843e+00,  ...,  5.3524e+01,\n",
       "            4.5022e+01, -5.1114e+01]],\n",
       "\n",
       "         [[-3.7423e-01,  3.6256e-01,  1.8946e-01,  ..., -8.1413e+01,\n",
       "           -9.1913e+01,  7.7664e+01],\n",
       "          [-1.1689e+00, -2.1227e-01, -1.1169e+00,  ..., -7.7762e+01,\n",
       "           -8.5876e+01,  7.4890e+01]]]], grad_fn=<CatBackward0>), tensor([[[[ 0.0953, -0.0469,  0.2027,  ...,  0.0071,  0.0191, -0.1607],\n",
       "          [ 0.2544,  0.5862,  0.5580,  ...,  0.0352, -0.4635, -0.0151]],\n",
       "\n",
       "         [[ 0.2827, -0.2626,  0.1765,  ..., -0.3576, -0.0804,  0.2834],\n",
       "          [ 0.7358, -1.0078,  0.2250,  ..., -0.8385, -0.6061,  0.3028]],\n",
       "\n",
       "         [[-0.0304,  0.0056, -0.3636,  ..., -0.1370, -0.0791,  0.0849],\n",
       "          [-0.1294,  0.4341, -0.6231,  ..., -0.0518,  0.1329,  0.1447]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1734,  0.0132,  0.1965,  ..., -0.0506, -0.0298, -0.0248],\n",
       "          [ 0.6142, -0.0767,  0.1889,  ...,  0.3484, -0.1777, -0.3030]],\n",
       "\n",
       "         [[ 0.0690, -0.1723,  0.2810,  ...,  0.0270, -0.1448,  0.0077],\n",
       "          [ 0.6402, -1.6872,  0.5656,  ...,  0.0370, -0.9112,  0.2129]],\n",
       "\n",
       "         [[-0.1666,  0.0344, -0.0072,  ..., -0.0353, -0.0843,  0.2292],\n",
       "          [-1.1413,  0.1566,  0.1867,  ...,  0.0711, -0.2805,  1.1769]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 7.9551e-01,  4.1265e-01,  1.7882e-01,  ...,  4.8874e+01,\n",
       "           -5.6384e+01,  4.9551e+01],\n",
       "          [ 4.9124e+00,  2.6748e+00,  2.5256e+00,  ...,  4.6509e+01,\n",
       "           -5.2495e+01,  4.5443e+01]],\n",
       "\n",
       "         [[-4.2953e-02, -5.1749e-01,  5.6621e-01,  ...,  6.2708e+01,\n",
       "            6.4141e+01,  5.7499e+01],\n",
       "          [ 1.7319e+00, -1.1492e+00,  1.8600e+00,  ...,  6.0015e+01,\n",
       "            6.0931e+01,  5.4230e+01]],\n",
       "\n",
       "         [[ 1.0321e+00,  5.2841e-01, -8.2344e-01,  ...,  7.1612e+01,\n",
       "            5.8970e+01, -6.9621e+01],\n",
       "          [ 4.3151e+00,  4.3107e+00, -2.2240e+00,  ...,  6.6737e+01,\n",
       "            5.4280e+01, -6.6109e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.1832e-02,  4.4825e-02, -1.8894e-01,  ...,  5.0504e+01,\n",
       "           -7.1344e+01,  6.6393e+01],\n",
       "          [ 1.9779e+00, -9.1268e-01, -1.5942e+00,  ...,  4.7108e+01,\n",
       "           -6.6448e+01,  6.3162e+01]],\n",
       "\n",
       "         [[ 5.1709e-01, -8.0823e-01,  1.2438e+00,  ...,  6.6636e+01,\n",
       "           -5.7742e+01, -6.5435e+01],\n",
       "          [ 1.7830e+00, -1.9537e+00,  3.8170e+00,  ...,  6.2303e+01,\n",
       "           -5.5832e+01, -6.1522e+01]],\n",
       "\n",
       "         [[ 3.4136e-01,  1.3935e-01, -7.8461e-01,  ..., -5.7790e+01,\n",
       "           -6.3234e+01, -5.8545e+01],\n",
       "          [-1.4080e+00,  8.4343e-01, -2.3720e-01,  ..., -5.3517e+01,\n",
       "           -5.9794e+01, -5.5453e+01]]]], grad_fn=<CatBackward0>), tensor([[[[ 0.0476, -0.1428, -0.0394,  ..., -0.1661,  0.4024, -0.0911],\n",
       "          [ 0.3290, -0.2160, -0.2328,  ..., -0.5428,  1.0787, -0.2600]],\n",
       "\n",
       "         [[ 0.1361, -0.0104, -0.0722,  ...,  0.1840, -0.1756, -0.1780],\n",
       "          [ 0.2776, -0.0628, -0.1548,  ..., -0.0752, -0.2677, -0.9065]],\n",
       "\n",
       "         [[-0.2277, -0.1179,  0.0629,  ..., -0.3246,  0.1010, -0.1149],\n",
       "          [-0.7755,  0.0065, -0.0371,  ..., -0.7567, -0.1925, -0.4834]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0232, -0.0781,  0.0820,  ...,  0.1921,  0.0677, -0.4744],\n",
       "          [-0.5525, -0.6441,  0.5256,  ...,  0.8822, -0.6818, -1.2987]],\n",
       "\n",
       "         [[ 0.0015,  0.0275, -0.1945,  ...,  0.0128,  0.0176,  0.0993],\n",
       "          [-0.2144,  0.2992, -0.4691,  ...,  0.2143,  0.3369, -0.3050]],\n",
       "\n",
       "         [[ 0.2151,  0.2215,  0.1537,  ...,  0.0043, -0.1788, -0.1313],\n",
       "          [ 0.8697,  0.4996, -0.0289,  ...,  0.1315, -0.2034, -0.4556]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.5577e-01, -1.2267e-02, -1.3338e-01,  ...,  5.8949e+01,\n",
       "           -2.7885e+01, -4.2550e+01],\n",
       "          [-9.7695e-01,  2.1738e-01, -9.4330e-01,  ...,  5.6116e+01,\n",
       "           -2.6170e+01, -4.0966e+01]],\n",
       "\n",
       "         [[-9.9088e-01, -3.8026e-01, -4.2142e-02,  ...,  6.4052e+01,\n",
       "           -6.0618e+01, -4.3079e+01],\n",
       "          [-7.1428e-01, -1.8805e+00, -2.3027e+00,  ...,  6.1185e+01,\n",
       "           -5.7844e+01, -4.1038e+01]],\n",
       "\n",
       "         [[ 2.8533e-01, -2.0662e-01,  4.1453e-01,  ...,  1.2717e+01,\n",
       "           -7.0640e+01,  7.9939e+01],\n",
       "          [-1.9071e+00, -3.8585e-01,  2.7142e+00,  ...,  1.6526e+01,\n",
       "           -6.7825e+01,  7.7258e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.9103e-01, -2.9924e-01, -2.9001e-01,  ..., -5.9466e+01,\n",
       "            5.4788e+01,  2.9272e+01],\n",
       "          [-2.3378e+00, -1.5372e+00, -7.4849e-01,  ..., -5.6439e+01,\n",
       "            5.3824e+01,  2.6446e+01]],\n",
       "\n",
       "         [[-5.3409e-01, -1.0629e+00,  8.0319e-01,  ..., -6.7611e+01,\n",
       "           -5.8039e+01,  5.5589e+01],\n",
       "          [ 2.5148e-01, -1.0362e+00,  3.0605e+00,  ..., -6.4768e+01,\n",
       "           -5.7808e+01,  5.3821e+01]],\n",
       "\n",
       "         [[ 1.5266e-02,  7.5372e-01, -6.1390e-01,  ...,  4.8314e+01,\n",
       "           -7.9253e+01, -2.8181e+01],\n",
       "          [-5.5338e-01,  1.5786e+00, -2.4440e-01,  ...,  4.4821e+01,\n",
       "           -7.7445e+01, -2.9252e+01]]]], grad_fn=<CatBackward0>), tensor([[[[ 0.0052,  0.0672, -0.3648,  ...,  0.2459, -0.0171,  0.0469],\n",
       "          [ 0.0458,  0.2850, -1.3278,  ...,  0.5667,  0.1761, -0.1104]],\n",
       "\n",
       "         [[ 0.1854, -0.0798, -0.1924,  ...,  0.0608,  0.3308, -0.1495],\n",
       "          [ 0.5266, -0.1554, -0.0736,  ..., -0.2988, -0.4406, -0.4336]],\n",
       "\n",
       "         [[-0.3760,  0.1016,  0.0206,  ...,  0.0128, -0.1905,  0.0899],\n",
       "          [-0.9672,  0.4674, -0.3248,  ...,  0.4749, -0.4255,  0.4064]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1279, -0.3117,  0.0351,  ..., -0.3039, -0.3520,  0.2805],\n",
       "          [ 0.1532, -0.5743, -0.2274,  ..., -0.4152, -0.9961,  0.6680]],\n",
       "\n",
       "         [[ 0.1154,  0.0916,  0.3606,  ...,  0.3036, -0.2239,  0.3002],\n",
       "          [ 0.5499, -0.4283,  0.4958,  ...,  0.7436, -0.4607,  0.6325]],\n",
       "\n",
       "         [[-0.5553, -0.0826,  0.1933,  ...,  0.3203, -0.0378,  0.2206],\n",
       "          [-1.5620,  0.0888,  0.3448,  ...,  0.6906,  0.3440,  0.4728]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.2166e-01, -1.9016e-01,  6.2428e-01,  ..., -6.3912e+01,\n",
       "           -4.8892e+01, -5.6719e+01],\n",
       "          [ 1.6816e+00, -7.1570e-01,  1.0113e+00,  ..., -6.2976e+01,\n",
       "           -4.7571e+01, -5.5358e+01]],\n",
       "\n",
       "         [[ 5.3515e-02, -2.4585e-02,  2.8492e-01,  ..., -5.2274e+01,\n",
       "           -5.0836e+01, -5.6662e+01],\n",
       "          [ 7.4684e-02,  3.8370e-01,  2.6721e-01,  ..., -5.0803e+01,\n",
       "           -5.0597e+01, -5.6572e+01]],\n",
       "\n",
       "         [[-4.8218e-01, -6.4655e-01, -4.9008e-01,  ..., -4.7458e+01,\n",
       "           -6.4902e+01,  6.3323e+01],\n",
       "          [-6.3150e+00, -4.1931e+00, -2.4097e+00,  ..., -4.8243e+01,\n",
       "           -6.4013e+01,  6.2016e+01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.9470e-02,  4.1436e-01, -3.7760e-01,  ..., -4.7491e+01,\n",
       "           -5.1617e+01,  5.5598e+01],\n",
       "          [ 1.2122e+00, -7.7259e-01, -8.1466e-01,  ..., -4.3728e+01,\n",
       "           -4.9861e+01,  5.3548e+01]],\n",
       "\n",
       "         [[ 8.0023e-01,  2.5832e-01, -1.0114e+00,  ...,  2.4355e+01,\n",
       "           -6.0065e+01,  2.8320e+01],\n",
       "          [ 1.6869e-01, -5.4732e-01, -4.0382e+00,  ...,  2.4765e+01,\n",
       "           -5.9767e+01,  2.8096e+01]],\n",
       "\n",
       "         [[-1.0792e+00, -3.5799e-01,  3.4661e-01,  ..., -5.1807e+01,\n",
       "           -3.1160e+01, -1.0984e+01],\n",
       "          [-2.1848e+00, -7.1643e-01,  8.7687e-01,  ..., -5.1447e+01,\n",
       "           -3.2018e+01, -1.0732e+01]]]], grad_fn=<CatBackward0>), tensor([[[[-2.4117e-01, -4.0635e-01,  4.3670e-01,  ...,  6.8745e-01,\n",
       "            1.3875e-02,  3.9497e-01],\n",
       "          [-2.5326e-01,  3.4403e-01, -1.9460e-01,  ...,  2.3190e-01,\n",
       "            2.6860e-01,  3.4218e-01]],\n",
       "\n",
       "         [[ 1.6532e-01, -1.4633e-01, -2.3508e-01,  ...,  1.1054e-01,\n",
       "           -1.5671e-01, -7.3282e-02],\n",
       "          [ 8.6165e-01, -3.9699e-01, -2.6275e-01,  ..., -1.9270e-01,\n",
       "            1.4069e-01,  1.4995e-01]],\n",
       "\n",
       "         [[-5.7868e-01, -4.8127e-01,  6.0061e-02,  ..., -8.7298e-05,\n",
       "           -5.5525e-02, -5.5744e-01],\n",
       "          [-8.4849e-01, -9.7446e-01,  7.1189e-01,  ..., -1.9360e-01,\n",
       "           -2.2749e-01, -1.1015e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.5079e-02, -1.5601e-01,  7.2551e-04,  ..., -4.3407e-01,\n",
       "           -5.1869e-02,  1.0449e-01],\n",
       "          [-1.6597e-02, -1.6711e-01,  3.6305e-02,  ..., -8.0736e-01,\n",
       "           -5.4730e-01,  5.1543e-05]],\n",
       "\n",
       "         [[-3.3609e-01,  2.5240e-01, -5.4630e-01,  ...,  4.0711e-01,\n",
       "           -1.4253e-01,  4.5655e-01],\n",
       "          [-8.8717e-01, -2.2820e-02, -1.5328e+00,  ..., -8.3074e-02,\n",
       "           -4.5127e-01,  6.0319e-01]],\n",
       "\n",
       "         [[-4.4639e-01,  2.1368e-01, -3.4203e-01,  ..., -1.6925e-01,\n",
       "           -2.8032e-01, -2.6008e-01],\n",
       "          [-8.9645e-01,  6.2266e-01, -5.8199e-01,  ..., -5.0659e-01,\n",
       "           -7.9192e-01, -1.8845e-01]]]], grad_fn=<PermuteBackward0>))), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# model_name=\"usvsnsp/pythia-6.9b-rm-full-hh-rlhf\"\n",
    "# device = \"cuda:0\"\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# text = \"The dog\"\n",
    "# tokens = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "# output = model(tokens)\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NeelNanda/pile-10k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading metadata: 100%|██████████| 921/921 [00:00<00:00, 2.50MB/s]\n",
      "Downloading readme: 100%|██████████| 373/373 [00:00<00:00, 1.68MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None (download: 31.72 MiB, generated: 58.43 MiB, post-processed: Unknown size, total: 90.15 MiB) to /root/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 33.3M/33.3M [00:00<00:00, 83.9MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1558.64it/s]\n",
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    }
   ],
   "source": [
    "def download_dataset(dataset_name, tokenizer, max_length=256, num_datapoints=None):\n",
    "    if(num_datapoints):\n",
    "        split_text = f\"train[:{num_datapoints}]\"\n",
    "    else:\n",
    "        split_text = \"train\"\n",
    "    dataset = load_dataset(dataset_name, split=split_text).map(\n",
    "        lambda x: tokenizer(x['text']),\n",
    "        batched=True,\n",
    "    ).filter(\n",
    "        lambda x: len(x['input_ids']) > max_length\n",
    "    ).map(\n",
    "        lambda x: {'input_ids': x['input_ids'][:max_length]}\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "print(f\"Downloading {dataset_name}\")\n",
    "dataset = download_dataset(dataset_name, tokenizer=tokenizer, max_length=max_seq_length, num_datapoints=1000) # num_datapoints grabs all of them if None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:25<00:00,  1.24it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "type Tensor doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/sparse_coding/feature_display_code.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B50.217.254.168/root/sparse_coding/feature_display_code.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m(input_setting \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minput_only\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B50.217.254.168/root/sparse_coding/feature_display_code.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# Calculate logit diffs on this feature for the full_token_list\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B50.217.254.168/root/sparse_coding/feature_display_code.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     logit_diffs \u001b[39m=\u001b[39m ablate_feature_direction(model, full_token_list, cache_name, max_seq_length, autoencoder, feature \u001b[39m=\u001b[39m feature, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, setting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msentences\u001b[39m\u001b[39m\"\u001b[39m, model_type\u001b[39m=\u001b[39mmodel_type)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B50.217.254.168/root/sparse_coding/feature_display_code.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     save_token_display(full_token_list, full_activations, tokenizer, path \u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00msave_path\u001b[39m}\u001b[39;49;00m\u001b[39muniform_\u001b[39;49m\u001b[39m{\u001b[39;49;00mfeature\u001b[39m}\u001b[39;49;00m\u001b[39m.png\u001b[39;49m\u001b[39m\"\u001b[39;49m, logit_diffs \u001b[39m=\u001b[39;49m logit_diffs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B50.217.254.168/root/sparse_coding/feature_display_code.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B50.217.254.168/root/sparse_coding/feature_display_code.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     logit_diffs \u001b[39m=\u001b[39m ablate_feature_direction(model, dataset, cache_name, max_seq_length, autoencoder, feature \u001b[39m=\u001b[39m feature, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, setting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/sparse_coding/utils_interp.py:288\u001b[0m, in \u001b[0;36msave_token_display\u001b[0;34m(tokens, activations, tokenizer, path, save, logit_diffs, show, model_type)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_token_display\u001b[39m(tokens, activations, tokenizer, path, save\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, logit_diffs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, show\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, model_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcausal\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 288\u001b[0m     html \u001b[39m=\u001b[39m tokens_and_activations_to_html(tokens, activations, tokenizer, logit_diffs, model_type\u001b[39m=\u001b[39;49mmodel_type)\n\u001b[1;32m    289\u001b[0m     \u001b[39mif\u001b[39;00m(save):\n\u001b[1;32m    290\u001b[0m         imgkit\u001b[39m.\u001b[39mfrom_string(html, path)\n",
      "File \u001b[0;32m~/sparse_coding/utils_interp.py:260\u001b[0m, in \u001b[0;36mtokens_and_activations_to_html\u001b[0;34m(toks, activations, tokenizer, logit_diffs, model_type)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m(logit_diffs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    259\u001b[0m     highlighted_text\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m<div style=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmargin-top: 0.1em;\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m></div>\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 260\u001b[0m     highlighted_text\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mLogit Diff: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m make_colorbar(logit_min_value, logit_max_value))\n\u001b[1;32m    262\u001b[0m highlighted_text\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m<div style=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmargin-top: 0.5em;\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m></div>\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    263\u001b[0m \u001b[39mfor\u001b[39;00m seq_ind, (act, tok) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(activations, toks)):\n",
      "File \u001b[0;32m~/sparse_coding/utils_interp.py:195\u001b[0m, in \u001b[0;36mmake_colorbar\u001b[0;34m(min_value, max_value, white, red_blue_ness, positive_threshold, negative_threshold)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_colors, \u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m    194\u001b[0m     ratio \u001b[39m=\u001b[39m i \u001b[39m/\u001b[39m (num_colors)\n\u001b[0;32m--> 195\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mround\u001b[39;49m((min_value\u001b[39m*\u001b[39;49mratio),\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    196\u001b[0m     text_color \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m255,255,255\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m ratio \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m0,0,0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m     colorbar \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m<span style=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbackground-color:rgba(255, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(red_blue_ness\u001b[39m-\u001b[39m(red_blue_ness\u001b[39m*\u001b[39mratio))\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(red_blue_ness\u001b[39m-\u001b[39m(red_blue_ness\u001b[39m*\u001b[39mratio))\u001b[39m}\u001b[39;00m\u001b[39m,1); color:rgb(\u001b[39m\u001b[39m{\u001b[39;00mtext_color\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m>&nbsp\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m&nbsp</span>\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: type Tensor doesn't define __round__ method"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils_interp import *\n",
    "import os\n",
    "# make features/ dir if not exist\n",
    "save_path = \"features/\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "num_feature_datapoints = 10\n",
    "dictionary_activations, tokens_for_each_datapoint = get_dictionary_activations(model, dataset, cache_name, max_seq_length, autoencoder, batch_size=32)\n",
    "\n",
    "# features = [1,2,3,4,5,6,7,8,9,10]\n",
    "features = [5,6]\n",
    "\n",
    "for feature in features:\n",
    "    uniform_indices = get_feature_indices(feature, dictionary_activations, k=num_feature_datapoints, setting=\"uniform\")\n",
    "    text_list, full_text, token_list, full_token_list, partial_activations, full_activations = get_feature_datapoints(uniform_indices, dictionary_activations[:, feature], tokenizer, max_seq_length, dataset)\n",
    "    get_token_statistics(feature, dictionary_activations[:, feature], dataset, tokenizer, max_seq_length, tokens_for_each_datapoint, save_location = save_path, num_unique_tokens=10)\n",
    "    if(input_setting == \"input_only\"):\n",
    "        # Calculate logit diffs on this feature for the full_token_list\n",
    "        logit_diffs = ablate_feature_direction(model, full_token_list, cache_name, max_seq_length, autoencoder, feature = feature, batch_size=32, setting=\"sentences\", model_type=model_type)\n",
    "        save_token_display(full_token_list, full_activations, tokenizer, path =f\"{save_path}uniform_{feature}.png\", logit_diffs = logit_diffs)\n",
    "    else:\n",
    "        logit_diffs = ablate_feature_direction(model, dataset, cache_name, max_seq_length, autoencoder, feature = feature, batch_size=32, setting=\"dataset\")\n",
    "        _, _, _, full_token_list_ablated, _, full_activations_ablated = get_feature_datapoints(uniform_indices, logit_diffs, tokenizer, max_seq_length, dataset, model_type=model_type)\n",
    "        get_token_statistics(feature, logit_diffs, dataset, tokenizer, max_seq_length, tokens_for_each_datapoint, save_location = save_path, setting=\"output\", num_unique_tokens=10)\n",
    "        save_token_display(full_token_list_ablated, full_activations, tokenizer, path =f\"{save_path}uniform_{feature}.png\", logit_diffs = full_activations_ablated)\n",
    "    combine_images(feature, setting=input_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   0,   0,   0, 120,  75,   5,  10,   1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_activations.count_nonzero(dim=0)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(full_token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run example text through model\n",
    "text = \"I like to eat pizza.\"\n",
    "tokens = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "# outputs = model(tokens)\n",
    "# outputs.logits\n",
    "\n",
    "device = model.device\n",
    "def less_than_rank_1_ablate(value, hook):\n",
    "    # Only ablate the feature direction up to the negative bias\n",
    "    # ie Only subtract when it activates above that negative bias.\n",
    "\n",
    "    # Rearrange to fit autoencoder\n",
    "    int_val = rearrange(value, 'b s h -> (b s) h')\n",
    "    # Run through the autoencoder\n",
    "    act = autoencoder.encode(int_val)\n",
    "    dictionary_for_this_autoencoder = autoencoder.get_learned_dict()\n",
    "    feature_direction = torch.outer(act[:, feature].squeeze(), dictionary_for_this_autoencoder[feature].squeeze())\n",
    "    batch, seq_len, hidden_size = value.shape\n",
    "    feature_direction = rearrange(feature_direction, '(b s) h -> b s h', b=batch, s=seq_len)\n",
    "    value -= feature_direction\n",
    "    return value\n",
    "\n",
    "# with Trace(model, cache_name, edit_output=less_than_rank_1_ablate) as ret:\n",
    "#     _ = model(batch).logits\n",
    "#     representation = ret.output\n",
    "#     # check if instance tuple\n",
    "#     if(isinstance(representation, tuple)):\n",
    "#         representation = representation[0]\n",
    "\n",
    "\n",
    "batch = tokens\n",
    "original_logits = model(batch).logits.log_softmax(dim=-1)\n",
    "# with Trace(model, cache_name, edit_output=less_than_rank_1_ablate) as ret:\n",
    "with Trace(model, cache_name, edit_output=less_than_rank_1_ablate) as ret:\n",
    "    ablated_logits = model(batch).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def ablate_feature_direction(model, dataset, cache_name, max_seq_length, autoencoder, feature, batch_size=32):\n",
    "\n",
    "device = model.cfg.device\n",
    "def less_than_rank_1_ablate(value, hook):\n",
    "    # Only ablate the feature direction up to the negative bias\n",
    "    # ie Only subtract when it activates above that negative bias.\n",
    "    # Rearrange to fit autoencoder\n",
    "    int_val = rearrange(value, 'b s h -> (b s) h')\n",
    "    # Run through the autoencoder\n",
    "    act = autoencoder.encode(int_val)\n",
    "    dictionary_for_this_autoencoder = autoencoder.get_learned_dict()\n",
    "    feature_direction = torch.outer(act[:, feature].squeeze(), dictionary_for_this_autoencoder[feature].squeeze())\n",
    "    batch, seq_len, hidden_size = value.shape\n",
    "    feature_direction = rearrange(feature_direction, '(b s) h -> b s h', b=batch, s=seq_len)\n",
    "    value -= feature_direction\n",
    "    return value\n",
    "\n",
    "# tokens_batched = full_tokens_list\n",
    "tokens_batched = torch.stack(full_token_list)\n",
    "logit_diffs = torch.zeros((tokens_batched.shape[0], tokens_batched.shape[1]-1))\n",
    "\n",
    "with torch.no_grad(), dataset.formatted_as(\"pt\"):\n",
    "    original_logits = model(tokens_batched.to(device)).log_softmax(dim=-1)\n",
    "    ablated_logits = model.run_with_hooks(tokens_batched.to(device), fwd_hooks=[(cache_name, less_than_rank_1_ablate)]).log_softmax(dim=-1)\n",
    "    diff_logits = ablated_logits  - original_logits# ablated > original -> negative diff\n",
    "    gather_tokens = rearrange(tokens_batched[:,1:].to(device), \"b s -> b s 1\")\n",
    "    gathered = diff_logits[:, :-1].gather(-1,gather_tokens)\n",
    "    # append all 0's to the beggining of gathered\n",
    "    gathered = torch.cat([torch.zeros((gathered.shape[0],1,1)).to(device), gathered], dim=1)\n",
    "    logit_diffs = rearrange(gathered, \"b s n -> (b s n)\").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_colorbar(min_value, max_value, white = 255, red_blue_ness = 250, positive_threshold = 0.01, negative_threshold = 0.01):\n",
    "    # Add color bar\n",
    "    colorbar = \"\"\n",
    "    num_colors = 4\n",
    "    if(min_value < -negative_threshold):\n",
    "        for i in range(num_colors, 0, -1):\n",
    "            ratio = i / (num_colors)\n",
    "            value = round((min_value*ratio),1)\n",
    "            text_color = \"255,255,255\" if ratio > 0.5 else \"0,0,0\"\n",
    "            colorbar += f'<span style=\"background-color:rgba(255, {int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},1); color:rgb({text_color})\">&nbsp{value}&nbsp</span>'\n",
    "    # Do zero\n",
    "    colorbar += f'<span style=\"background-color:rgba({white},{white},{white},1);color:rgb(0,0,0)\">&nbsp0.0&nbsp</span>'\n",
    "    # Do positive\n",
    "    if(max_value > positive_threshold):\n",
    "        for i in range(1, num_colors+1):\n",
    "            ratio = i / (num_colors)\n",
    "            value = round((max_value*ratio),1)\n",
    "            text_color = \"255,255,255\" if ratio > 0.5 else \"0,0,0\"\n",
    "            colorbar += f'<span style=\"background-color:rgba({int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},255,1);color:rgb({text_color})\">&nbsp{value}&nbsp</span>'\n",
    "    return colorbar\n",
    "\n",
    "def value_to_color(activation, max_value, min_value, white = 255, red_blue_ness = 250, positive_threshold = 0.01, negative_threshold = 0.01):\n",
    "    if activation > positive_threshold:\n",
    "        ratio = activation/max_value\n",
    "        text_color = \"0,0,0\" if ratio <= 0.5 else \"255,255,255\"  \n",
    "        background_color = f'rgba({int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},255,1)'\n",
    "    elif activation < -negative_threshold:\n",
    "        ratio = activation/min_value\n",
    "        text_color = \"0,0,0\" if ratio <= 0.5 else \"255,255,255\"  \n",
    "        background_color = f'rgba(255, {int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},1)'\n",
    "    else:\n",
    "        text_color = \"0,0,0\"\n",
    "        background_color = f'rgba({white},{white},{white},1)'\n",
    "    return text_color, background_color\n",
    "\n",
    "def convert_token_array_to_list(array):\n",
    "    if isinstance(array, torch.Tensor):\n",
    "        if array.dim() == 1:\n",
    "            array = [array.tolist()]\n",
    "        elif array.dim()==2:\n",
    "            array = array.tolist()\n",
    "        else: \n",
    "            raise NotImplementedError(\"tokens must be 1 or 2 dimensional\")\n",
    "    elif isinstance(array, list):\n",
    "        # ensure it's a list of lists\n",
    "        if isinstance(array[0], int):\n",
    "            array = [array]\n",
    "    return array\n",
    "\n",
    "def tokens_and_activations_to_html(toks, activations, tokenizer, logit_diffs=None):\n",
    "    # text_spacing = \"0.07em\"\n",
    "    text_spacing = \"0.00em\"\n",
    "    toks = convert_token_array_to_list(toks)\n",
    "    activations = convert_token_array_to_list(activations)\n",
    "    # toks = [[tokenizer.decode(t).replace('Ġ', '&nbsp').replace('\\n', '↵') for t in tok] for tok in toks]\n",
    "    toks = [[tokenizer.decode(t).replace('Ġ', '&nbsp').replace('\\n', '\\\\n') for t in tok] for tok in toks]\n",
    "    highlighted_text = []\n",
    "    # Make background black\n",
    "    # highlighted_text.append('<body style=\"background-color:black; color: white;\">')\n",
    "    highlighted_text.append(\"\"\"\n",
    "<body style=\"background-color: black; color: white;\">\n",
    "\"\"\")\n",
    "    max_value = max([max(activ) for activ in activations])\n",
    "    min_value = min([min(activ) for activ in activations])\n",
    "    if(logit_diffs):\n",
    "        logit_max_value = max([max(activ) for activ in logit_diffs])\n",
    "        logit_min_value = min([min(activ) for activ in logit_diffs])\n",
    "\n",
    "    # Add color bar\n",
    "    highlighted_text.append(\"Token Activations: \" + make_colorbar(min_value, max_value))\n",
    "    if(logit_diffs):\n",
    "        highlighted_text.append('<div style=\"margin-top: 0.1em;\"></div>')\n",
    "        highlighted_text.append(\"Logit Diff: \" + make_colorbar(logit_min_value, logit_max_value))\n",
    "    \n",
    "    highlighted_text.append('<div style=\"margin-top: 0.5em;\"></div>')\n",
    "    for seq_ind, (act, tok) in enumerate(zip(activations, toks)):\n",
    "        for act_ind, (a, t) in enumerate(zip(act, tok)):\n",
    "            if(logit_diffs):\n",
    "                highlighted_text.append('<div style=\"display: inline-block;\">')\n",
    "            text_color, background_color = value_to_color(a, max_value, min_value)\n",
    "            highlighted_text.append(f'<span style=\"background-color:{background_color};margin-right: {text_spacing}; color:rgb({text_color})\">{t.replace(\" \", \"&nbsp\")}</span>')\n",
    "            if(logit_diffs):\n",
    "                logit_diffs_act = logit_diffs[seq_ind][act_ind]\n",
    "                _, logit_background_color = value_to_color(logit_diffs_act, logit_max_value, logit_min_value)\n",
    "                highlighted_text.append(f'<div style=\"display: block; margin-right: {text_spacing}; height: 10px; background-color:{logit_background_color}; text-align: center;\"></div></div>')\n",
    "        highlighted_text.append('<div style=\"margin-top: 0.2em;\"></div>')\n",
    "        # highlighted_text.append('<br><br>')\n",
    "    # highlighted_text.append('</body>')\n",
    "    highlighted_text = ''.join(highlighted_text)\n",
    "    return highlighted_text\n",
    "\n",
    "def display_tokens(tokens, activations, tokenizer, logit_diffs=None):\n",
    "    return display(HTML(tokens_and_activations_to_html(tokens, activations, tokenizer, logit_diffs)))\n",
    "\n",
    "def save_token_display(tokens, activations, tokenizer, path, logit_diffs=None):\n",
    "    html = tokens_and_activations_to_html(tokens, activations, tokenizer, logit_diffs)\n",
    "    imgkit.from_string(html, path)\n",
    "    # print(f\"Saved to {path}\")\n",
    "    return\n",
    "save_token_display(full_token_list_ablated, full_activations, model.tokenizer, path =f\"{save_path}uniform_black_{feature}.png\", logit_diffs = full_activations_ablated)\n",
    "# display_tokens(full_token_list_ablated, full_activations, model.tokenizer, logit_diffs = full_activations_ablated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Load an existing image\n",
    "image = Image.open(f\"concatenated_image.png\")\n",
    "\n",
    "# Create a drawing object\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define the position for the text to be placed (this example puts it at the top-center)\n",
    "text = \"Feature {feature}\"\n",
    "text_position = (image.width // 2, 10)\n",
    "\n",
    "# You can use a truetype or opentype font file if you want to customize\n",
    "# Otherwise, PIL provides a basic built-in font\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", size=30)\n",
    "except IOError:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "# Calculate text size and position to center-align the text\n",
    "text_width, text_height = draw.textsize(text, font=font)\n",
    "text_position = ((image.width - text_width) // 2, 100)\n",
    "\n",
    "# Add the text to image\n",
    "draw.text(text_position, text, font=font, fill=\"white\")\n",
    "\n",
    "# Save or show the image\n",
    "image.save(\"image_with_title.png\")\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font.font.getsize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_position, text, font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# The initial HTML and CSS to set the background to black\n",
    "initial_html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>My Page</title>\n",
    "</head>\n",
    "<body style=\"background-color: blue;\">\n",
    "\"\"\"\n",
    "\n",
    "# The HTML for the text spans that you'll append later\n",
    "span_text = \"\"\"\n",
    "    <span style=\"color: white;\">This is some text.</span>\n",
    "    <span style=\"color: green;\">This is some more text.</span>\n",
    "\"\"\"\n",
    "\n",
    "# Closing tags for the HTML\n",
    "closing_html = \"\"\"\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Combine everything\n",
    "full_html = initial_html + span_text + closing_html\n",
    "\n",
    "# Display the HTML\n",
    "display(HTML(full_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cfg.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = model.cfg.d_model\n",
    "assert (d_model == autoencoder.encoder.shape[-1]), f\"Model and autoencoder must have same hidden size. Model: {d_model}, Autoencoder: {autoencoder.encoder.shape[-1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use the model to get the activations\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange\n",
    "def get_dictionary_activations(model, dataset, cache_name, autoencoder, batch_size=32):\n",
    "    num_features, d_model = autoencoder.encoder.shape\n",
    "    datapoints = dataset.num_rows\n",
    "    dictionary_activations = torch.zeros((datapoints*max_seq_length, num_features))\n",
    "    token_list = torch.zeros((datapoints*max_seq_length), dtype=torch.int64)\n",
    "    with torch.no_grad(), dataset.formatted_as(\"pt\"):\n",
    "        dl = DataLoader(dataset[\"input_ids\"], batch_size=batch_size)\n",
    "        for i, batch in enumerate(tqdm(dl)):\n",
    "            token_list[i*batch_size*max_seq_length:(i+1)*batch_size*max_seq_length] = rearrange(batch, \"b s -> (b s)\")\n",
    "            _, cache = model.run_with_cache(batch.to(device))\n",
    "            batched_neuron_activations = rearrange(cache[cache_name], \"b s n -> (b s) n\" )\n",
    "            batched_dictionary_activations = autoencoder.encode(batched_neuron_activations)\n",
    "            dictionary_activations[i*batch_size*max_seq_length:(i+1)*batch_size*max_seq_length,:] = batched_dictionary_activations.cpu()\n",
    "    return dictionary_activations, token_list\n",
    "\n",
    "print(\"Getting dictionary activations\")\n",
    "dictionary_activations, tokens_for_each_datapoint = get_dictionary_activations(model, dataset, cache_name, autoencoder, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ablate_feature_direction(model, dataset, cache_name, autoencoder, feature, batch_size=32):\n",
    "    def less_than_rank_1_ablate(value, hook):\n",
    "        # Only ablate the feature direction up to the negative bias\n",
    "        # ie Only subtract when it activates above that negative bias.\n",
    "\n",
    "        # Rearrange to fit autoencoder\n",
    "        int_val = rearrange(value, 'b s h -> (b s) h')\n",
    "        # Run through the autoencoder\n",
    "        act = autoencoder.encode(int_val)\n",
    "        dictionary_for_this_autoencoder = autoencoder.get_learned_dict()\n",
    "        feature_direction = torch.outer(act[:, feature].squeeze(), dictionary_for_this_autoencoder[feature].squeeze())\n",
    "        batch, seq_len, hidden_size = value.shape\n",
    "        feature_direction = rearrange(feature_direction, '(b s) h -> b s h', b=batch, s=seq_len)\n",
    "        value -= feature_direction\n",
    "        return value\n",
    "\n",
    "    datapoints = dataset.num_rows\n",
    "    logit_diffs = torch.zeros((datapoints*max_seq_length))\n",
    "    with torch.no_grad(), dataset.formatted_as(\"pt\"):\n",
    "        dl = DataLoader(dataset[\"input_ids\"], batch_size=batch_size)\n",
    "        for i, batch in enumerate(tqdm(dl)):\n",
    "            original_logits = model(batch.to(device)).log_softmax(dim=-1)\n",
    "            ablated_logits = model.run_with_hooks(batch.to(device), fwd_hooks=[(cache_name, less_than_rank_1_ablate)]).log_softmax(dim=-1)\n",
    "            diff_logits = ablated_logits  - original_logits# ablated > original -> negative diff\n",
    "            gather_tokens = rearrange(batch[:,1:].to(device), \"b s -> b s 1\")\n",
    "            gathered = diff_logits[:, :-1].gather(-1,gather_tokens)\n",
    "            # append all 0's to the beggining of gathered\n",
    "            gathered = torch.cat([torch.zeros((gathered.shape[0],1,1)).to(device), gathered], dim=1)\n",
    "            diff = rearrange(gathered, \"b s n -> (b s n)\")\n",
    "            # Add one to the first position of logit diff, so we're always skipping over the first token (since it's not predicted)\n",
    "            logit_diffs[i*batch_size*max_seq_length:(i+1)*batch_size*max_seq_length] = diff.cpu()\n",
    "    return logit_diffs\n",
    "feature = 1\n",
    "logit_diffs = ablate_feature_direction(model, dataset, cache_name, autoencoder, feature = feature, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from interp_utils import *\n",
    "# if isinstance(features, int):\n",
    "#     features = [features]\n",
    "# for feature in features:\n",
    "#     text_list, full_text, token_list, full_token_list = get_feature_datapoints(feature, dictionary_activations, model.tokenizer, max_seq_length, dataset, setting=\"uniform\")\n",
    "#     # text_list, full_text, token_list, full_token_list = get_feature_datapoints(feature, dictionary_activations, dataset, setting=\"max\")\n",
    "#     # visualize_text(full_text, feature, model, autoencoder, layer)\n",
    "# l = visualize_text(text_list, feature, model, autoencoder, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import imgkit\n",
    "\n",
    "def make_colorbar(min_value, max_value, white = 245, red_blue_ness = 250, positive_threshold = 0.01, negative_threshold = 0.01):\n",
    "    # Add color bar\n",
    "    colorbar = \"\"\n",
    "    num_colors = 4\n",
    "    if(min_value < -negative_threshold):\n",
    "        for i in range(num_colors, 0, -1):\n",
    "            ratio = i / (num_colors)\n",
    "            value = round((min_value*ratio),1)\n",
    "            text_color = \"255,255,255\" if ratio > 0.5 else \"0,0,0\"\n",
    "            colorbar += f'<span style=\"background-color:rgba(255, {int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},1); color:rgb({text_color})\">&nbsp{value}&nbsp</span>'\n",
    "    # Do zero\n",
    "    colorbar += f'<span style=\"background-color:rgba({white},{white},{white},1);color:rgb(0,0,0)\">&nbsp0.0&nbsp</span>'\n",
    "    # Do positive\n",
    "    if(max_value > positive_threshold):\n",
    "        for i in range(1, num_colors+1):\n",
    "            ratio = i / (num_colors)\n",
    "            value = round((max_value*ratio),1)\n",
    "            text_color = \"255,255,255\" if ratio > 0.5 else \"0,0,0\"\n",
    "            colorbar += f'<span style=\"background-color:rgba({int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},255,1);color:rgb({text_color})\">&nbsp{value}&nbsp</span>'\n",
    "    return colorbar\n",
    "\n",
    "def value_to_color(activation, max_value, min_value, white = 245, red_blue_ness = 250, positive_threshold = 0.01, negative_threshold = 0.01):\n",
    "    if activation > positive_threshold:\n",
    "        ratio = activation/max_value\n",
    "        text_color = \"0,0,0\" if ratio <= 0.5 else \"255,255,255\"  \n",
    "        background_color = f'rgba({int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},255,1)'\n",
    "    elif activation < -negative_threshold:\n",
    "        ratio = activation/min_value\n",
    "        text_color = \"0,0,0\" if ratio <= 0.5 else \"255,255,255\"  \n",
    "        background_color = f'rgba(255, {int(red_blue_ness-(red_blue_ness*ratio))},{int(red_blue_ness-(red_blue_ness*ratio))},1)'\n",
    "    else:\n",
    "        text_color = \"0,0,0\"\n",
    "        background_color = f'rgba({white},{white},{white},1)'\n",
    "    return text_color, background_color\n",
    "\n",
    "def convert_token_array_to_list(array):\n",
    "    if isinstance(array, torch.Tensor):\n",
    "        if array.dim() == 1:\n",
    "            array = [array.tolist()]\n",
    "        elif array.dim()==2:\n",
    "            array = array.tolist()\n",
    "        else: \n",
    "            raise NotImplementedError(\"tokens must be 1 or 2 dimensional\")\n",
    "    elif isinstance(array, list):\n",
    "        # ensure it's a list of lists\n",
    "        if isinstance(array[0], int):\n",
    "            array = [array]\n",
    "    return array\n",
    "\n",
    "def tokens_and_activations_to_html(toks, activations, tokenizer, logit_diffs=None):\n",
    "    toks = convert_token_array_to_list(toks)\n",
    "    activations = convert_token_array_to_list(activations)\n",
    "    # toks = [[tokenizer.decode(t).replace('Ġ', '&nbsp').replace('\\n', '↵') for t in tok] for tok in toks]\n",
    "    toks = [[tokenizer.decode(t).replace('Ġ', '&nbsp').replace('\\n', '\\\\n') for t in tok] for tok in toks]\n",
    "    highlighted_text = []\n",
    "    max_value = max([max(activ) for activ in activations])\n",
    "    min_value = min([min(activ) for activ in activations])\n",
    "    if(logit_diffs):\n",
    "        logit_max_value = max([max(activ) for activ in logit_diffs])\n",
    "        logit_min_value = min([min(activ) for activ in logit_diffs])\n",
    "\n",
    "    # Add color bar\n",
    "    highlighted_text.append(\"Token Activations: \" + make_colorbar(min_value, max_value))\n",
    "    if(logit_diffs):\n",
    "        highlighted_text.append('<br><br>')\n",
    "        highlighted_text.append(\"Logit Diff: \" + make_colorbar(logit_min_value, logit_max_value))\n",
    "        \n",
    "    highlighted_text.append('<br><br>')\n",
    "    for seq_ind, (act, tok) in enumerate(zip(activations, toks)):\n",
    "        for act_ind, (a, t) in enumerate(zip(act, tok)):\n",
    "            if(logit_diffs):\n",
    "                highlighted_text.append('<div style=\"display: inline-block;\">')\n",
    "            text_color, background_color = value_to_color(a, max_value, min_value)\n",
    "            highlighted_text.append(f'<span style=\"background-color:{background_color};color:rgb({text_color})\">{t.replace(\" \", \"&nbsp\")}</span>')\n",
    "            if(logit_diffs):\n",
    "                logit_diffs_act = logit_diffs[seq_ind][act_ind]\n",
    "                _, logit_background_color = value_to_color(logit_diffs_act, logit_max_value, logit_min_value)\n",
    "                highlighted_text.append(f'<div style=\"display: block; height: 10px; background-color:{logit_background_color}; text-align: center;\"></div></div>')\n",
    "        highlighted_text.append('<br><br>')\n",
    "    highlighted_text = ''.join(highlighted_text)\n",
    "    return highlighted_text\n",
    "\n",
    "def display_tokens(tokens, activations, tokenizer, logit_diffs=None):\n",
    "    return display(HTML(tokens_and_activations_to_html(tokens, activations, tokenizer, logit_diffs)))\n",
    "\n",
    "def save_token_display(tokens, activations, tokenizer, path, logit_diffs=None):\n",
    "    html = tokens_and_activations_to_html(tokens, activations, tokenizer, logit_diffs)\n",
    "    imgkit.from_string(html, path)\n",
    "    # print(f\"Saved to {path}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_indices(feature_index, dictionary_activations, tokenizer, token_amount, dataset, k=10, setting=\"max\"):\n",
    "    best_feature_activations = dictionary_activations[:, feature_index]\n",
    "    # Sort the features by activation, get the indices\n",
    "    if setting==\"max\":\n",
    "        found_indices = torch.argsort(best_feature_activations, descending=True)[:k]\n",
    "    elif setting==\"uniform\":\n",
    "        # min_value = torch.min(best_feature_activations)\n",
    "        min_value = torch.min(best_feature_activations)\n",
    "        max_value = torch.max(best_feature_activations)\n",
    "\n",
    "        # Define the number of bins\n",
    "        num_bins = k\n",
    "\n",
    "        # Calculate the bin boundaries as linear interpolation between min and max\n",
    "        bin_boundaries = torch.linspace(min_value, max_value, num_bins + 1)\n",
    "\n",
    "        # Assign each activation to its respective bin\n",
    "        bins = torch.bucketize(best_feature_activations, bin_boundaries)\n",
    "\n",
    "        # Initialize a list to store the sampled indices\n",
    "        sampled_indices = []\n",
    "\n",
    "        # Sample from each bin\n",
    "        for bin_idx in torch.unique(bins):\n",
    "            if(bin_idx==0): # Skip the first one. This is below the median\n",
    "                continue\n",
    "            # Get the indices corresponding to the current bin\n",
    "            bin_indices = torch.nonzero(bins == bin_idx, as_tuple=False).squeeze(dim=1)\n",
    "            \n",
    "            # Randomly sample from the current bin\n",
    "            sampled_indices.extend(np.random.choice(bin_indices, size=1, replace=False))\n",
    "\n",
    "        # Convert the sampled indices to a PyTorch tensor & reverse order\n",
    "        found_indices = torch.tensor(sampled_indices).long().flip(dims=[0])\n",
    "    else: # random\n",
    "        # get nonzero indices\n",
    "        nonzero_indices = torch.nonzero(best_feature_activations)[:, 0]\n",
    "        # shuffle\n",
    "        shuffled_indices = nonzero_indices[torch.randperm(nonzero_indices.shape[0])]\n",
    "        found_indices = shuffled_indices[:k]\n",
    "    return found_indices\n",
    "def get_feature_datapoints(found_indices, best_feature_activations, tokenizer, token_amount, dataset):\n",
    "    num_datapoints = dataset.num_rows\n",
    "    datapoint_indices =[np.unravel_index(i, (num_datapoints, token_amount)) for i in found_indices]\n",
    "    all_activations = best_feature_activations.reshape(num_datapoints, token_amount).tolist()\n",
    "    full_activations = []\n",
    "    partial_activations = []\n",
    "    text_list = []\n",
    "    full_text = []\n",
    "    token_list = []\n",
    "    full_token_list = []\n",
    "    for i, (md, s_ind) in enumerate(datapoint_indices):\n",
    "        md = int(md)\n",
    "        s_ind = int(s_ind)\n",
    "        full_tok = torch.tensor(dataset[md][\"input_ids\"])\n",
    "        full_text.append(tokenizer.decode(full_tok))\n",
    "        tok = dataset[md][\"input_ids\"][:s_ind+1]\n",
    "        full_activations.append(all_activations[md])\n",
    "        partial_activations.append(all_activations[md][:s_ind+1])\n",
    "        text = tokenizer.decode(tok)\n",
    "        text_list.append(text)\n",
    "        token_list.append(tok)\n",
    "        full_token_list.append(full_tok)\n",
    "    return text_list, full_text, token_list, full_token_list, partial_activations, full_activations\n",
    "\n",
    "uniform_indices = get_feature_indices(feature, dictionary_activations, model.tokenizer, max_seq_length, dataset, k=10, setting=\"uniform\")\n",
    "text_list, full_text, token_list, full_token_list, partial_activations, full_activations = get_feature_datapoints(uniform_indices, dictionary_activations[:, feature], model.tokenizer, max_seq_length, dataset)\n",
    "display_tokens(token_list, partial_activations, model.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_token_statistics(feature, feature_activation, dataset, max_seq_length, save_location=\"\", num_unique_tokens=10, setting=\"input\", negative_threshold=-0.01):\n",
    "    if(setting==\"input\"):\n",
    "        nonzero_indices = feature_activation.nonzero()[:, 0]  # Get the nonzero indices\n",
    "    else:\n",
    "        nonzero_indices = (feature_activation < negative_threshold).nonzero()[:, 0]\n",
    "    nonzero_values = feature_activation[nonzero_indices].abs()  # Get the nonzero values\n",
    "\n",
    "    # Unravel the indices to get the token IDs\n",
    "    datapoint_indices = [np.unravel_index(i, (dataset.num_rows, max_seq_length)) for i in nonzero_indices]\n",
    "    all_tokens = [dataset[int(md)][\"input_ids\"][int(s_ind)] for md, s_ind in datapoint_indices]\n",
    "\n",
    "    # Find the max value for each unique token\n",
    "    token_value_dict = defaultdict(int)\n",
    "    for token, value in zip(all_tokens, nonzero_values):\n",
    "        token_value_dict[token] = max(token_value_dict[token], value)\n",
    "    # if(setting==\"input\"):\n",
    "    sorted_tokens = sorted(token_value_dict.keys(), key=lambda x: -token_value_dict[x])\n",
    "    # else:\n",
    "    #     sorted_tokens = sorted(token_value_dict.keys(), key=lambda x: token_value_dict[x])\n",
    "    # Take the top 10 (or fewer if there aren't 10)\n",
    "    max_tokens = sorted_tokens[:min(num_unique_tokens, len(sorted_tokens))]\n",
    "    total_sums = nonzero_values.abs().sum()\n",
    "    max_token_sums = []\n",
    "    token_activations = []\n",
    "    for max_token in max_tokens:\n",
    "        # Find ind of max token\n",
    "        max_token_indices = tokens_for_each_datapoint[nonzero_indices] == max_token\n",
    "        # Grab the values for those indices\n",
    "        max_token_values = nonzero_values[max_token_indices]\n",
    "        max_token_sum = max_token_values.abs().sum()\n",
    "        max_token_sums.append(max_token_sum)\n",
    "        token_activations.append(max_token_values)\n",
    "\n",
    "\n",
    "    if(setting==\"input\"):\n",
    "        title_text = \"Input Token Activations\"\n",
    "        save_name = \"input\"\n",
    "        y_label = \"Feature Activation\"\n",
    "    else:\n",
    "        title_text = \"Output Logit Difference\"\n",
    "        save_name = \"logit_diff\"\n",
    "        y_label = \"Logit Difference\"\n",
    "\n",
    "    # Plot a boxplot for each tensor in the list\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.set_title(f'{title_text}: feature={feature}')\n",
    "    max_text = [model.tokenizer.decode([t]).replace(\"\\n\", \"\\\\n\").replace(\" \", \"_\") for t in max_tokens]\n",
    "    # Set x-axis label\n",
    "    ax.set_xlabel('Token')\n",
    "    #rotate x labels\n",
    "    plt.xticks(rotation=30)\n",
    "    # Set y-axis label\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.boxplot(token_activations[::-1], labels=max_text[::-1])\n",
    "    #Save it\n",
    "    plt.savefig(f'{save_location}feature_{feature}_{save_name}_boxplot.png')\n",
    "\n",
    "    #Bar graph of the percentage of total activations\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.set_title(f'Weighted Percentage of {title_text}: feature={feature}')\n",
    "    max_text = [model.tokenizer.decode([t]).replace(\"\\n\", \"\\\\n\").replace(\" \", \"_\") for t in max_tokens]\n",
    "    # Set x-axis label\n",
    "    ax.set_xlabel('Token')\n",
    "    plt.xticks(rotation=30)\n",
    "\n",
    "    # Set y-axis label\n",
    "    ax.set_ylabel(f'Weighted Percentage of Total {y_label}')\n",
    "    ax.bar(max_text[::-1], [t/total_sums*100 for t in max_token_sums[::-1]])\n",
    "    plt.savefig(f'{save_location}feature_{feature}_{save_name}_bar.png')\n",
    "# get_token_statistics(feature, dictionary_activations[:, feature], dataset, max_seq_length, save_location = \"features/\", num_unique_tokens=10)\n",
    "get_token_statistics(feature, logit_diffs, dataset, max_seq_length, save_location = \"features/\", setting=\"output\", num_unique_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(logit_diffs < -0.01).nonzero()[:, 0], feature_activation.nonzero()[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, full_token_list_ablated, _, full_activations_ablated = get_feature_datapoints(uniform_indices, logit_diffs, model.tokenizer, max_seq_length, dataset)\n",
    "display_tokens(full_token_list_ablated, full_activations, model.tokenizer, logit_diffs = full_activations_ablated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_and_activations_to_html(full_token_list_ablated, full_activations, model.tokenizer, logit_diffs = full_activations_ablated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<div style=\"display: inline-block;\"><span style=\"background-color:rgba(245,245,245,1);color:rgb(0,0,0)\">About</span><div style=\"display: block; height: 10px; background-color:rgba(245,245,245,1); text-align: center;\"></div></div><div style=\"display: inline-block;\"><span style=\"background-color:rgba(245,245,245,1);color:rgb(0,0,0)\">\\\\n</span><div style=\"display: block; height: 10px; background-color:rgba(245,245,245,1); text-align: center;\"></div></div><div style=\"display: inline-block;\"><span style=\"background-color:rgba(245,245,245,1);color:rgb(0,0,0)\">\\\\n</span><div style=\"display: block; height: 10px; background-color:rgba(245,245,245,1); text-align: center;\"></div></div><div style=\"display: inline-block;\"><span style=\"background-color:rgba(245,245,245,1);color:rgb(0,0,0)\">Te</span><div style=\"display: block; height: 10px; background-color:rgba(245,245,245,1); text-align: center;\"></div></div><div style=\"display: inline-block;\"><span style=\"background-color:rgba(245,245,245,1);color:rgb(0,0,0)\">ams</span><div style=\"display: block; height: 10px; background-color:rgba(245,245,245,1); text-align: center;\"></div></div><div style=\"display: inline-block;\"><span style=\"background-color:rgba(245,245,245,1);color:rgb(0,0,0)\">&nbspare</span><div style=\"display: block; height: 10px; background-color:rgba(245,245,245,1); text-align: center;\"></div></div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def ablate_context_one_token_at_a_time(model, dataset, cache_name, autoencoder, feature, batch_size=32):\n",
    "all_changed_activations = []\n",
    "for token_ind, token_l in enumerate(token_list):\n",
    "# for token_ind, token_l in enumerate(full_token_list):\n",
    "    seq_size = len(token_l)\n",
    "    original_activation = partial_activations[token_ind][-1]\n",
    "    # Run through the model for each seq length\n",
    "    if(seq_size==1):\n",
    "        continue # Size 1 sequences don't have any context to ablate\n",
    "    # changed_activations = torch.zeros(seq_size).cpu() + original_activation\n",
    "    changed_activations = torch.zeros(seq_size).cpu() \n",
    "    for i in range(seq_size-1):\n",
    "        # ablated_tokens = token_l[:i+1] + token_l[i+1:]\n",
    "        ablated_tokens = token_l\n",
    "        ablated_tokens = torch.tensor(ablated_tokens).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            _, cache = model.run_with_cache(ablated_tokens.to(device))\n",
    "            neuron_activations = rearrange(cache[cache_name], \"b s n -> (b s) n\" )\n",
    "            dictionary_activations = autoencoder.encode(neuron_activations)\n",
    "\n",
    "            changed_activations[i] += dictionary_activations[-1,feature].item()\n",
    "    changed_activations -= original_activation\n",
    "    all_changed_activations.append(changed_activations.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_tokens(token_list, all_changed_activations, model.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_changed_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_tokens(token_list, partial_activations, model.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablate_feature_direction_display(full_text, autoencoder, model, layer, features=feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
